# Instapaper 宕机原因和恢复| Brian dono hue |制作 Instapaper | Medium

> 原文:[https://medium . com/making-instapaper/instapaper-outage-cause-recovery-3c 32 a 7 e 9 cc 5f？UTM _ source = Wanqu . co&UTM _ campaign = Wanqu+Daily&UTM _ medium = website](https://medium.com/making-instapaper/instapaper-outage-cause-recovery-3c32a7e9cc5f?utm_source=wanqu.co&utm_campaign=Wanqu+Daily&utm_medium=website)

# Instapaper 停机原因和恢复

Instapaper 服务在 2 月 9 日(星期三)下午 12:30(太平洋时间)到 2 月 10 日(星期四)下午 7:30(太平洋时间)之间经历了[长时间中断](http://blog.instapaper.com/post/157027537441)。在我们努力完全恢复服务的同时，我们恢复了 Instapaper 服务，并限制了对档案的访问。今天，2 月 14 日，我们完成了服务的全面恢复。

失败的关键系统是我们的 MySQL 数据库，我们在亚马逊的[关系数据库服务(RDS)](https://aws.amazon.com/rds/) 上将其作为托管解决方案运行。在这里，我们将介绍哪里出了问题，我们如何解决问题，以及我们正在做些什么来提高未来的可靠性。

# **根本原因**

简而言之，数据故障是由 2014 年 4 月之前创建的 RDS 实例的 [2TB 文件大小限制](http://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/CHAP_Limits.html)导致的。太平洋时间 2 月 9 日星期三中午 12:30，我们存储 Instapaper 用户保存的文章的“书签”表超过了 2TB 的文件大小限制。随后尝试向书签表中插入新条目时，开始出现以下错误:



存在这种限制的原因是因为在 2014 年 4 月之前创建的 MySQL RDS 实例使用了一个具有 2TB 文件大小限制的 [ext3 文件系统](https://en.wikipedia.org/wiki/Ext3)。2014 年 4 月之后创建的实例由一个 [ext4 文件系统](https://en.wikipedia.org/wiki/Ext4)支持，并受到 6TB 文件大小的限制。

# **Instapaper RDS 历史**

2013 年 4 月， [betaworks 从 Marco Arment 手中收购了 Instapaper](https://marco.org/2013/04/25/instapaper-next-generation) 。收购后，我们将 Instapaper 从 [Softlayer](http://www.softlayer.com/) 转移到[亚马逊网络服务](https://aws.amazon.com/)，因为所有 betaworks 公司都在 AWS 上运行，所以工程师们在该平台上拥有专业知识。为了执行迁移，betaworks 与他们的两个常规 devops 承包商合作。迁移后，运营工作移交给了新成立的 Instapaper 团队，运营责任落在了我们的工程总监身上。在我们的工程总监于 2014 年 10 月离开公司后，我接管了后端运营。

我们在 2013 年 6 月创建的原始实例在 2015 年初的备份窗口期间遇到了一些性能问题。AWS 支持部门证实，我们运行的是较旧的硬件和较旧版本的 MySQL v5.6.18。根据 AWS 的说法，如果我们升级到较新的版本(v5.6.19+)，问题就会得到解决。

2015 年 3 月，我们创建了 2013 年 6 月 RDS 实例的读取副本，升级了 MySQL 版本，并在午夜以最短的停机时间(大约 5 分钟)执行了切换。尽管此实例是在 2014 年 4 月之后创建的，但它是从 2013 年 6 月的原始 RDS 实例创建的读取复制副本，因此继承了相同的文件系统和 2TB 文件大小限制。

# **预防**

如果不知道 2014 年 4 月之前的文件大小限制，就很难预见和防止这一问题。据我们所知，RDS 控制台中没有监控、警报或日志形式的信息可以让我们知道我们正在接近 2TB 的文件大小限制，或者我们首先会受到它的影响。即使是现在，也没有任何迹象表明我们的托管数据库存在严重问题。

如果我们曾经了解文件大小限制，它可能会留给执行软层迁移的 2013 年 betaworks 承包商。据我们所知，作为 RDS 客户，只有两种方法可以避免这个问题。

首先，我们可以将数据库完全转储到磁盘，然后将数据库恢复到一个新的 RDS 实例。在这种情况下，我们可能需要直接与 Amazon 合作，将新的 RDS 实例设置为旧实例的读取副本，然后执行转换。

另一个选择是建立一个运行亚马逊 Aurora 的读取副本，这是亚马逊的托管 SQL 兼容数据库系统。我们之前考虑过迁移到 Aurora(主要是因为节省成本)，但是 Aurora 只在 VPC 上运行，Instapaper 仍然在 EC2-classic 上运行。

最终，我们不太可能在不了解限制的情况下执行这些操作。

# **备份**

RDS 的一个重要特性是数据库实例的自动每日备份。我们为 MySQL 数据库存储了 10 天的备份。但是，由于这些备份都是文件系统快照，因此它们也受到 2TB 文件大小的限制。

# **有限服务恢复**

我们没有一个很好的灾难恢复计划，以防我们的 MySQL 实例由于一个关键的文件系统问题而失败，而我们所有的备份也会遇到这个问题。

在与 AWS 支持人员通了长时间电话，并与 Pinterest 的网站可靠性工程师讨论了局限性之后，我们明白我们唯一的前进道路是使用完整的转储和恢复来重建我们的 2.5TB 数据库。Pinterest 的 SRE 团队尽快指导我们将 Instapaper 的生产数据库转储到一个 5.5TB 的 RAID-0 磁盘，该磁盘由一个 i2.8xlarge 实例提供。

当清楚转储将花费太长时间时(第一次花费 24 小时，第二次并行化花费 10 小时)，我们开始执行应急计划，以使实例处于工作状态，并限制对 Instapaper 档案的访问。这一短期解决方案在停机 31 小时后投入生产。创建该实例并将其投入生产的总时间大约是六个小时。

鉴于我们没有针对此类事件的计划，我们没有很好地了解转储和恢复数据库所需的时间。我们最初估计数据库转储需要六到八个小时。然而，我们使用行数进行了估计，后来得知 Instapaper 书签的前 25%只占总数据的 10%。如果我们知道重建数据库将是一项耗时数天的工作，并且我们需要直接启动有限的服务恢复，那么我们本可以大幅缩短最初的停机时间。

# **数据恢复**

服务备份和数据转储完成后，下一步是将所有转储导入到不受 2TB 文件大小限制的实例中。整个周末，我们与 RDS 工程师密切合作，通过两个并行的工作流程来实现这一目标:

1.  设置旧数据库的 Aurora 读取副本。我们一致认为使用 Aurora 是有风险的，因为我们还没有对 Instapaper 代码库进行彻底的测试，但它的设置摩擦非常小。读取复制在大约 24 小时内完成。
2.  创建一个新的 MySQL RDS 实例，导入所有没有二级索引的数据(8 小时)，并在数据导入后创建三个二级索引(每个二级索引大约需要 16 小时)。在本文发表时，最后一个二级索引仍在创建中。

在意识到创建二级索引花费了不可接受的长时间后，Amazon 的一名工程师将 ext4 文件系统挂载到我们失败的生产数据库，并在 ext3 文件系统和 ext4 文件系统之间执行 rsync。rsync 运行了大约 8 个小时，最终为我们提供了一个新的、受 ext4 支持的数据库实例，所有数据和索引都已恢复。

# **与临时生产数据库同步**

RDS 工程师使用临时生产数据库中的二进制日志(带有有限的归档文件)设置新的 ext4 支持的数据库，并基于行复制到临时生产数据库，以便与周四和周一之间所做的更改保持同步。这个复制的总时间大约是三个小时。

# **全业务恢复**

一旦我们有了新的 ext4 支持的数据库，并且将全部数据和索引同步到临时生产数据库，最后一步就是提升新数据库来控制和部署应用程序代码以指向新数据库。

我们执行了恢复，没有丢失任何用户的旧文章、对较新文章所做的更改或从中断中恢复后保存的文章。

# **倒影**

这是任何 web 应用程序开发人员最糟糕的噩梦。我们没有意识到也不了解的基于文件系统的限制不仅使我们的生产数据库变得无用，而且使我们的所有备份也变得无用。我们唯一的办法是将数据恢复到新文件系统上的全新实例中。这变得更加复杂，因为我们进入托管实例的唯一接口是 MySQL，如果没有 Amazon 工程师的直接帮助，像 rsync 这样的文件系统级解决方案是不可能实现的。

即使我们执行得很完美，从我们诊断出问题的那一刻到我们完全重建数据库的那一刻，总的停机时间也至少有 10 个小时。当然，这比 31 小时的总停机时间和五天的受限访问时间要少得多，但是我们想说明即使在完美的世界中这种问题的严重性。

我们坚信这个问题很难预测和预防，但是缺乏针对此类问题的灾难恢复计划导致了不必要的停机时间和恢复时间。此外，从沟通的角度来看，我们本可以采取几个步骤，无论是在 Pinterest 内部还是与亚马逊网络服务团队合作，以便更好地利用我们可以支配的资源。

# **行动项目**

作为 Pinterest 回顾流程的一部分，我们正在为系统范围的 Instapaper 中断定义一个更好的工作流程，该流程会立即将问题升级到 Pinterest 的网站可靠性工程团队。

此外，我们将更加积极地测试我们的 MySQL 备份。我们过去每三个月测试一次备份，现在我们将每个月测试一次。

上述两项措施都无法避免这一问题，但它们有助于在发生中断时加快我们的响应速度，并且是良好的实践。

# **关系数据库服务**

我们现在将继续使用亚马逊的关系数据库服务。虽然在没有警告或可见性的情况下遇到问题令人沮丧，但 RDS 多年来一直是 Instapaper 可靠而强大的服务，处理快照、故障转移、读取复制和其他任务，没有 Instapaper 团队的任何工程开销。

此外，RDS 团队在加快我们的全面恢复方面给予了极大的帮助。他们甚至接受了我们关于添加 ext3 支持的数据库的附加信息的功能请求。

# **问责**

我对事故和停工负全责。虽然我无法直接获得关于 2TB 限制的信息，但我有责任了解我在日常运营中使用的技术的限制，即使这些技术由另一家公司托管。此外，我对缺乏适当的灾难恢复计划负责，并将与 Pinterest 的网站可靠性工程团队密切合作，以确保我们有一个适当的流程，以便在此类故障再次发生时进行恢复。

