# 算法时代的媒体。自从周二的选举以来，有来自 WTF 的蒂姆·奥雷利？经济到下一个经济

> 原文:[https://medium . com/@ timore illy/media-in-the-age-of-algorithms-63 e 80 b 9 b 0a 73？UTM _ source = Wanqu . co&UTM _ campaign = Wanqu+Daily&UTM _ medium = website](https://medium.com/@timoreilly/media-in-the-age-of-algorithms-63e80b9b0a73?utm_source=wanqu.co&utm_campaign=Wanqu+Daily&utm_medium=website)



A prototype of the de Havilland Comet. An object lesson for today. [Source: Wikipedia](https://en.wikipedia.org/wiki/File:Comet_Prototype_at_Hatfield.jpg)



# 算法时代的媒体

自从周二的选举以来，有很多指责，其中许多指责指向脸书，认为他们的新闻馈送算法在传播错误信息和放大两极分化方面发挥了主要作用。一些文章在批评中深思熟虑，另一些在为脸书辩护中深思熟虑，而另一些则充满了错误的信息和两极分化，他们希望这将使他们成为每个人的头条新闻。但是在我看来，他们都犯了一个根本性的错误，在算法时代，他们是如何看待媒体的。

考虑一下杰西卡·莱辛在《信息*中的观点:*

> “我非常非常担心我听到的来自记者和朋友的呼吁，要求脸书进行干预并承担责任，确保公民知情并获得平衡的观点……
> 
> 脸书提倡诚信听起来很棒。谁不赞成承担责任并找出错误信息？但脸书方面调解好信息和坏信息的重大举措将使公司处于不得不确定“真相”的不可能境地，这似乎比它实际上要客观得多。此外，这对社会也是有害的。"

我的回答是:脸书很久以前就过了这条河。一旦他们开始管理新闻提要，而不是简单地把它当作一个时间线，他们就把自己放在了调解人们将会看到什么的位置上。他们成了看门人和向导。这不是一个不可能的位置。这是他们的工作。所以他们最好优先考虑擅长它。

但是那些强烈主张脸书有责任去芜存菁的人也错了。例如，在 *Vox，* [李提摩太](http://www.vox.com/new-money/2016/11/6/13509854/facebook-politics-news-bad)上写道:

> 这里的一个大问题是脸书编辑人员的配置方式。在传统的新闻机构中，经验丰富的编辑人员占据高级职位。相比之下，脸书将为数不多的编辑决策权交给了初级员工。例如，直到今年早些时候，脸书有一个由 15 到 18 名独立承包商组成的团队，他们负责为脸书的“趋势新闻”栏目撰写标题。
> 
> 当脸书面临这些员工压制保守报道的指控时，脸书惊慌失措，解雇了所有员工，转而将趋势报道框作为自动功能运行。但这也不是很好，因为假新闻[让](http://www.cbsnews.com/news/facebooks-trending-fail-news-section-reportedly-highlights-fake-news-on-megyn-kelly/) [在趋势新闻框中不断出现](https://www.buzzfeed.com/craigsilverman/can-facebook-trending-fight-off-fake-news)。
> 
> 这里的问题不是脸书雇佣人类编辑来评估故事和写标题。问题是，脸书的领导层并没有将此视为脸书行动的重要组成部分。
> 
> 如果脸书有一个经验丰富的资深编辑团队，它可以做很多事情来引导用户转向高质量、深度报道的新闻故事，而不是肤浅、耸人听闻或完全不准确的新闻故事。

李开复说，管理新闻提要不是初级职员和独立承包商的工作，这是对的。但他说这是“一个有经验的资深编辑团队”的工作，这是错误的。这是脸书算法团队中最聪明的人的工作！

李开复说问题不在于脸书雇佣人类编辑来评估故事和撰写标题，这是错误的。这正是问题所在。

就像司机在一座不复存在的桥上追踪全球定位系统一样，杰西卡·莱辛和蒂莫西·李都在一张过时的世界地图上工作。在旧地图中，算法由人类监督，人类在特定情况下进行干预，以弥补他们的错误。正如杰西卡正确指出的，这是一个非常滑坡。

杰西卡说:

> ……我们不应该让脸书为它制造或加剧的每一个问题开脱责任。但是我们也不能让他们每个人都为此负责。我们正在见证一个世界的影响，在这个世界里，互联网已经把你想对谁说什么就对谁说什么的成本降到了零，就像山姆经常说的那样。这是一个不可逆转的趋势，任何公司都无法阻止，我们也不应该希望他们阻止。

但是有一个很好的证据可以证明另一种方法的存在，一种脸书长期以来努力效仿的方法。

谷歌早就证明，你可以帮助引导人们获得更好的结果，而不妨碍任何人的言论自由。像脸书一样，他们每天都面临着决定 1000 个竞争声音中哪一个应该排在名单的首位。谷歌最初的观点是，一个链接就是一张选票，来自有声望的来源的链接已经存在了很长时间，比其他的更有价值，这是他们最初的去粗取精的工具。但多年来，他们开发了数百个，如果不是数千个信号，来帮助确定哪些链接是最有价值的。

在过去 20 年的大部分时间里，谷歌不知疲倦地工作，在监管任何人都可以创建的内容的算法馈送和简单地挑选赢家和输家之间穿针引线。这里有一个关键点:他们这样做并没有对页面的实际内容做出判断。“真实信号”存在于元数据中，而不是数据中。

任何想了解 21 世纪的公司如何在一个信息无限、注意力有限的世界里解决编辑监管问题的人，都应该好好研究一下谷歌搜索质量团队的历史和最佳实践，这些都有很好的记录并被广泛分享。这里有一段来自马特·卡茨(Matt Cutts)的视频，他是谷歌网络垃圾邮件团队的前负责人。谷歌告诉我们的是，改进算法以提供更好的结果是一场持续的战斗，因为总有人试图欺骗系统。但它们也告诉我们，正确的答案是不要进行人工干预来删除特定的结果。

谷歌和脸书不断设计和测试新的算法。是的，这涉及到人类的判断。但这种判断适用于系统的设计，而不是特定的结果。设计一个有效的搜索或新闻推送算法，与设计一架飞机让它飞起来，或者设计一架新飞机让它比旧飞机飞得更快，比决定飞机飞向哪里有更多的共同点。

提高文章的“真实价值”并不像这个问题的双方评论员似乎认为的那样，依靠人工干预来剔除坏结果，而是依靠发现导致好结果浮上台面的信号。

问题是如何确定“好的结果”意味着什么。

就让飞机飞起来而言，目标很简单——保持在高空，飞得更快，使用更少的燃料——设计的改变可以根据预期的结果进行严格的测试。在搜索中有许多类似的问题——找到最好的价格，或者关于某个主题的最权威的信息来源，或者某个特定的文档——还有许多远没有那么严格的问题。当用户得到他们想要的东西时，用户很高兴，一般来说，广告商也很高兴。不幸的是，与搜索不同，用户寻找答案并继续生活的愿望通常与“给他们最好的结果”一致，脸书对“参与”的优先考虑可能会将他们引向错误的方向。对脸书的收入最有利的可能并不是对用户最有利的。

即使在空气动力学和飞行工程这样的物理系统中，也经常有隐藏的假设需要测试和修正。在一个决定航空业未来的著名例子中，需要对如何处理金属疲劳有一个全新的理解。[正如德克萨斯大学教授迈克尔·马尔德](https://uteach.utexas.edu/sites/default/files/BrokenEducation2011.pdf)所描述的:

> 英国将主宰喷气式飞机时代。1952 年，德哈维兰彗星开始商业服务，成功地将伦敦与帝国最遥远的地区连接起来。这款喷气式飞机比任何竞争对手都要领先好几年，外观华丽，为空中的舒适和安静树立了新的标准。然后事情变得非常糟糕。
> 
> 1953 年，一颗彗星从天而降，坠机事件被归咎于恶劣的天气和飞行员的失误。1954 年，第二颗彗星坠落在罗马附近晴朗的天空中。在维修期间，舰队停飞了两个月。飞行随后恢复，并宣布，“虽然事故的确切原因尚未确定，但正在进行修改，以涵盖想象中作为灾难可能原因的每一种可能性。当这些修改完成并通过令人满意的飞行测试后，委员会认为没有理由不恢复客运服务。”写下这些话的四天后，第三颗彗星在那不勒斯附近晴朗的天空中坠入大海，舰队再次被无限期地搁浅。
> 
> ...当彗星事故报告在 1955 年发布时，美国西北角一个鲜为人知的军事承包商正在完成一架民用喷气式飞机的原型。波音公司过去在民用飞机上几乎没有成功。该公司知道裂缝导致了彗星的坠落，他们最好在击落波音 707 之前了解这些裂缝。
> 
> 波音公司为这个夏天带来了一位研究员保罗·帕里斯，他是一位机械工程师，刚刚完成硕士学位，正在利哈伊大学攻读研究生。…巴黎带给波音公司的断裂视图与指导彗星建造的视图截然不同。裂缝是调查的核心。他们不可能被消灭。它们无处不在，渗透到整个建筑中，小到看不见。这种结构不可能完美无缺，它本身就有缺陷，工程设计的目标不是保证机身没有裂纹，而是让它能够容忍裂纹。 【重点地雷】。]

算法设计的本质不是消除所有误差，而是使结果在误差面前具有鲁棒性。德·哈维兰兹试图设计一种材料足够坚固以抵抗所有裂纹和疲劳的飞机，但没有成功，波音公司意识到正确的方法是设计一种允许裂纹的设计，但防止裂纹蔓延到导致灾难性失败的程度。这也是脸书面临的挑战。

脸书回应蒂莫西·李的评论表明，他们明白自己面临的挑战。

> 我们重视真实的交流，经常听到那些使用脸书的人说他们不想看到错误的信息。在 News Feed 中，我们使用基于社区反馈的各种信号来确定哪些帖子可能包含不准确的信息，并减少它们的分布。在趋势分析中，我们会查看各种信号，以帮助确保所显示的主题反映了真实世界的事件，并采取额外的措施来防止虚假或误导性的内容出现。
> 
> 尽管做出了这些努力，但我们知道还有很多事情需要我们去做，这就是为什么我们不断提高发现错误信息的能力是如此重要。我们致力于继续解决这个问题，并改善我们平台上的体验。

关键问题不是脸书是否应该监管新闻，而是如何监管。他们显然有很多工作要做。我相信他们非常认真地对待这个问题。我希望他们取得突破，不要强迫他们在商业模式和为用户提供更好的结果之间做出选择。如果他们不这样做，我担心，尽管他们的意图是好的，但商业模式将会胜出。他们的目标是找到一种让飞机飞得更快，但又安全的方法。

好的一面是:在可能性空间中寻找真理和参与的交集可能会让脸书有一些非凡的发现。努力追求困难会让你变得更好。

但答案不是让脸书让记者去剔除好的和坏的。这是为了理解，就像他们如此成功地预测了导致更高参与度的特征一样，如何构建考虑到“真实”和受欢迎程度的算法。

他们需要问自己，他们是德哈维兰还是波音。