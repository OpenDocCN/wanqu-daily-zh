# 安全缺陷是如何工作的:缓冲区溢出| Ars 技术

> 原文:[https://ars technica . com/information-technology/2015/08/how-security-flaws-work-the-buffer-overflow/？UTM _ source = Wanqu . co&UTM _ campaign = Wanqu+Daily&UTM _ medium = website](https://arstechnica.com/information-technology/2015/08/how-security-flaws-work-the-buffer-overflow/?utm_source=wanqu.co&utm_campaign=Wanqu+Daily&utm_medium=website)

![How security flaws work: The buffer overflow](../Images/c1925cd5ca4f8472a446406836efc5e8.png)





缓冲区溢出长期以来一直是计算机安全领域的一个特征。事实上，第一个自我传播的互联网蠕虫——1988 年的 Morris 蠕虫——利用 Unix `finger`守护进程中的缓冲区溢出在机器间传播。27 年后，缓冲区溢出仍然是问题的根源。在 21 世纪初的两次缓冲区溢出攻击后，Windows 臭名昭著地调整了其安全重点。就在今年五月，在一个 Linux 驱动程序中发现的缓冲区溢出使得(潜在地)数百万个家庭和小型办公室路由器容易受到攻击。

从本质上来说，缓冲区溢出是一个非常简单的错误，是一种常见的做法造成的。计算机程序经常对从文件、网络甚至键盘上读取的大量数据进行操作。程序分配有限大小的内存块——缓冲区——在处理数据时存储这些数据。当向缓冲区写入或从中读取的数据超过缓冲区所能容纳的量时，就会发生缓冲区溢出。

从表面上看，这听起来像是一个相当愚蠢的错误。毕竟，程序知道缓冲区有多大，所以确保程序不会试图往缓冲区中塞入超过它所知道的容量应该是很简单的。你这么想是对的。然而，缓冲区溢出仍在继续发生，其结果常常是一场安全灾难。

为了理解为什么会发生缓冲区溢出——以及为什么它们的影响如此严重——我们需要了解一些程序如何使用内存，以及程序员如何编写代码。(注意，我们将主要关注堆栈缓冲区溢出。这不是唯一的溢出问题，但它是经典的，最著名的一种。)

## 叠起来

缓冲区溢出只会给本机代码带来问题，也就是说，程序直接使用处理器的指令集，而不是通过某种中间形式，如 Java 或 Python。溢出与处理器和本机代码程序操作内存的方式有关。不同的操作系统都有自己的怪癖，但是今天普遍使用的每个平台本质上都遵循相同的模式。为了理解这些攻击是如何工作的，以及人们为了阻止它们所做的一些事情，我们首先必须了解一点关于内存是如何使用的。

最重要的核心概念是内存地址。内存的每个字节都有相应的数字地址。当处理器从主存储器(RAM)中加载和存储数据时，它使用它想要读取和写入的位置的存储器地址。系统内存不仅仅用于存储数据；它也用于组成我们软件的可执行代码。这意味着正在运行的程序的每个函数也有一个地址。

在计算的早期，处理器和操作系统使用物理内存地址:每个内存地址直接对应一块特定的 RAM。虽然现代操作系统的某些部分仍然必须使用这些物理内存地址，但今天所有的操作系统都使用一种称为虚拟内存的方案。

有了虚拟内存，内存地址和 RAM 中物理位置之间的直接对应关系就被打破了。相反，软件和处理器使用虚拟内存地址运行。操作系统和处理器一起维护虚拟存储器地址和物理存储器地址之间的映射。

这种虚拟化支持一系列重要功能。第一个也是最重要的是*保护内存*。每个进程都有自己的*地址集。对于 32 位进程，这些地址从零(第一个字节)开始，一直到 4，294，967，295(或十六进制，`0xffff'ffff`)；2 <sup>32</sup> - 1)。对于 64 位进程，它们会一直运行到 18，446，744，073，709，551，615 ( `0xffff'ffff'ffff'ffff`，2 <sup>64</sup> - 1)。因此，每个进程都有自己的地址`0`，自己的地址`1`，自己的地址`2`，等等。*

(在本文的剩余部分，我将继续讨论 32 位系统，除非另有说明。32 位和 64 位系统的工作方式本质上是相同的，所以一切都可以很好地转换；只是坚持一点点更清晰一点。)

因为每个进程都有自己的一组地址，所以这些方案以一种非常直接的方式防止一个进程损坏任何其他进程的内存:一个进程可以使用的所有地址引用只属于那个进程的内存。流程处理起来也容易得多；物理内存地址，虽然它们大体上以相同的方式工作(它们只是从零开始的数字)，但往往有褶皱，使它们使用起来令人讨厌。例如，它们通常是不连续的；地址`0x1ff8'0000`用于处理器的系统管理模式存储器；普通软件无法使用的一小块物理内存。来自 PCIe 卡的存储器通常也占用一些这种地址空间。虚拟地址没有这些不便之处。

那么进程的地址空间里有什么呢？概括地说，有四种常见的东西，其中三种让我们感兴趣。最没意思的是，在大多数操作系统中，“操作系统内核”出于性能原因，地址空间通常分成两半，下半部分由程序使用，上半部分是内核的地址空间。内核的那一半内存对于程序的那一半是不可访问的，但是内核本身可以读取程序的内存。这是将数据传递给内核函数的方式之一。

我们首先需要关心的是组成程序的可执行文件和库。主可执行文件及其所有库都被加载到进程的地址空间中，并且它们的所有组成函数都有相应的内存地址。

第二个是程序用来存储数据的内存，通常称为堆。例如，这可能用于存储当前正在编辑的文档、正在查看的网页(及其所有 JavaScript 对象、CSS 等)或正在玩的游戏的地图。

第三个也是最重要的是调用栈，一般就叫栈。这是最复杂的方面。进程中的每个线程都有自己的堆栈。它是一块内存，用于跟踪线程当前正在运行的函数，以及所有的前一个函数——那些被调用来访问当前函数的函数。例如，如果函数`a`调用函数`b`，函数`b`调用函数`c,`，那么堆栈将依次包含关于`a`、`b`和`c`的信息。

[![Here we see the basic layout of our stack with a 64 character buffer called <code>name</code>, then the frame pointer, and then the return address. <code>esp</code> has the address of the top of the stack, <code>ebp</code> has the address of the frame pointer.](../Images/8d3c34652989858493b091bc0a7ad4c5.png)](https://cdn.arstechnica.net/wp-content/uploads/2015/08/basic-stack.png)

[Enlarge](https://cdn.arstechnica.net/wp-content/uploads/2015/08/basic-stack.png) /

这里我们看到了堆栈的基本布局，它有一个 64 字符的缓冲区，名为

`name`

，然后是帧指针，然后是返回地址。

`esp`

有栈顶的地址，

`ebp`

有帧指针的地址。





调用栈是更一般的“栈”数据结构的一个特殊版本。堆栈是存储对象的可变大小的结构。可以将新对象添加(“推入”)到堆栈的一端(通常称为堆栈的“顶部”)，并且可以从堆栈中移除(“弹出”)对象。只有栈顶可以用 push 或 pop 来修改，所以栈强制一种顺序排序:最近被推的项是最先被弹出的项。第一个被推入堆栈的项是最后一个被弹出的项。

调用栈做的最重要的事情是存储*返回地址*。大多数情况下，当程序调用一个函数时，该函数会做它应该做的任何事情(包括调用其他函数)，然后返回到调用它的函数。要返回到调用函数，必须有一个调用函数是什么的记录:在函数调用指令之后，应该从指令*继续执行。这条指令的地址称为返回地址。堆栈用于维护这些返回地址:每当调用一个函数时，返回地址就被推送到堆栈上。每当函数返回时，返回地址从堆栈中弹出，处理器开始在该地址执行指令。*

这种堆栈功能非常重要，以至于大多数处理器都内置了对这些概念的支持。考虑 x86 处理器。在 x86 定义的寄存器(处理器中处理器指令可以直接访问的小存储位置)中，最重要的两个是代表“指令指针”的`eip`和代表堆栈指针的`esp`。

`esp`总是包含栈顶的地址。每当有东西被压入堆栈时，`esp`中的值就会减少。每次从堆栈中弹出一个东西，`esp`的值就会增加。这意味着堆栈“向下”增长随着更多的东西被压入堆栈，存储在`esp`中的地址变得越来越低。尽管如此，`esp`引用的内存位置仍然被称为堆栈的“顶部”。

`eip`给出当前执行指令的地址。处理器自己维护`eip`。它从内存中读取指令流，并相应地增加`eip`,以便它总是拥有指令的地址。x86 有一条用于函数调用的指令，名为`call`，还有一条用于从函数返回的指令，名为`ret`。

`call`取一个操作数；要调用的函数的地址(尽管有几种不同的方法可以提供)。当执行一个`call`时，堆栈指针`esp`减少 4 个字节(32 位)，跟随`call`的指令的地址，即返回地址，被写入现在由`esp`引用的内存位置——换句话说，返回地址被推送到堆栈上。`eip`然后被设置为作为`call`的操作数指定的地址，并从该地址继续执行。

`ret`做相反的事。简单的`ret`没有任何操作数。处理器首先从包含在`esp`中的内存地址中读取值，然后将`esp`增加 4 个字节——它从堆栈中弹出返回地址。`eip`被设置为这个值，从这个地址继续执行。





查看`call`和`ret`的运行情况。





如果调用栈*只有*包含一系列返回地址，就不会有太多问题。真正的问题还伴随着栈上的其他东西。栈恰好是存储数据的一个快速有效的地方。在堆上存储数据相对复杂；该程序需要跟踪堆上有多少可用空间，每段数据使用了多少空间，以及其他各种簿记信息。但是堆栈也很简单；要为一些数据腾出空间，只需递减堆栈指针。为了在不再需要数据时进行整理，增加堆栈指针。

这种便利使得堆栈成为存储属于函数的变量的逻辑位置。一个函数有一个 256 字节的缓冲区来读取一些用户输入？很简单，只要从堆栈指针中减去 256，你就创建了缓冲区。在函数结束时，只需将 256 加回堆栈指针，缓冲区就会被丢弃。

[![When we use the program correctly, the keyboard input is stored in the <code>name</code> buffer, followed by a null (zero) byte. The frame pointer and return address are unaltered.](../Images/700a470a1a40445f89e9cf30233efa4e.png)](https://cdn.arstechnica.net/wp-content/uploads/2015/08/basic-stack-normal-usage.png)

[Enlarge](https://cdn.arstechnica.net/wp-content/uploads/2015/08/basic-stack-normal-usage.png) /

当我们正确使用程序时，键盘输入被存储在

`name`

缓冲区，后跟一个空(零)字节。帧指针和返回地址不变。





这是有局限性的。堆栈不是存储非常大的对象的好地方；创建线程时，可用的内存总量通常是固定的，通常在 1MB 左右。这些大对象*必须*放在堆上。对于需要存在时间超过单个函数调用跨度的对象，堆栈也是不可用的。因为当函数退出时，每个堆栈分配都被撤消，所以堆栈上存在的任何对象只能在函数运行时存在。然而，堆上的对象没有这样的限制；他们可以永远呆在一起。

这种堆栈存储不仅仅用于程序员在程序中显式创建的命名变量；它还可以用于存储程序可能需要存储的任何其他值。传统上，这在 x86 上是一个特别严重的问题。x86 处理器没有太多的寄存器(总共只有 8 个整数寄存器，其中一些，如`eip`和`esp,`已经有特殊用途)，因此函数很少能在寄存器中保存它们需要的所有值。为了释放寄存器中的空间，同时仍然确保稍后可以检索其当前值，编译器会将寄存器的值推送到堆栈上。随后可以弹出该值，将其放回寄存器中。在编译器术语中，这个保存寄存器以便可以重用的过程被称为*溢出*。

最后，堆栈通常用于向函数传递参数。调用函数将每个参数依次推送到堆栈上；被调用的函数可以弹出参数。这不是传递参数的唯一方式——例如，它们也可以在寄存器中传递——但这是最灵活的方式之一。

一个函数在堆栈上拥有的一组东西——它的局部变量、溢出的寄存器以及它准备传递给另一个函数的任何参数——被称为“堆栈帧”因为堆栈框架中的数据被广泛使用，所以有一种快速引用它的方法是很有用的。

堆栈指针*可以*做到这一点，但是有点笨拙:堆栈指针总是指向堆栈的顶部，所以当东西被推入和弹出时它会四处移动。例如，一个变量可以从地址`esp + 4`开始。另外两个值可能会被压入堆栈，这意味着现在必须在`esp + 12`访问该变量。其中一个值可以被弹出，所以变量现在在`esp + 8`。

这不是一个不可克服的困难，编译器可以轻松应对这一挑战。尽管如此，使用堆栈指针访问除“堆栈顶部”之外的任何东西还是很麻烦，尤其是对于手工编码的汇编程序。

为了使事情变得更简单，通常维护第二个指针，一个持续存储每个堆栈帧的*底部*(开始)地址的指针——一个被称为*帧指针*的值——在 x86 上，甚至有一个寄存器通常用于存储这个值`ebp`。因为这在给定的函数中不会改变，所以这提供了一种一致的方法来访问函数的变量:一个在`ebp - 4`的值将在整个函数中保持在`ebp - 4`。这不仅对人类有用；这也让调试器更容易搞清楚发生了什么。

[![This screenshot from Visual Studio shows some of this in action for a simple x86 program. On x86 processors, the register named <code>esp</code> contains the address of the top stack, in this case <code>0x0019fee0</code>, highlighted in blue (on x86, the stack actually grows downwards, toward memory address <code>0</code>, but it's still called the top of the stack anyway). This function only has one stack variable, <code>name</code>, highlighted in pink. It's a fixed size 32-byte buffer. Because it's the only variable, its address is also <code>0x0019fee0</code>, the same as the top of the stack.</p>
<p>x86 also has a register called <code>ebp</code>, highlighted in red, that's (normally) dedicated to storing the location of the frame pointer. The frame pointer is placed immediately after the stack variables. Right after the frame pointer is the return address, highlighted in green. The return address references a code fragment with address <code>0x00401048</code>. This instruction comes immediately after a <code>call</code> instruction, making clear the way the return address is used to resume execution from where the calling function left off.](../Images/e62b4dde99f1edcd4805e319de4243c3.png)](https://cdn.arstechnica.net/wp-content/uploads/2015/08/visual-studio.png)

[Enlarge](https://cdn.arstechnica.net/wp-content/uploads/2015/08/visual-studio.png) /

这个来自 Visual Studio 的屏幕截图展示了一个简单的 x86 程序的一些操作。在 x86 处理器上，名为

`esp`

包含顶层堆栈的地址，在本例中

`0x0019fee0`

以蓝色突出显示(在 x86 上，堆栈实际上是向下增长的，朝着内存地址

`0`

，不过反正还是叫栈顶)。这个函数只有一个堆栈变量，

`name`

，以粉红色突出显示。它是一个固定大小的 32 字节缓冲区。因为它是唯一的变量，所以它的地址也是

`0x0019fee0`

，与栈顶相同。

x86 还有一个名为`ebp`的寄存器，用红色突出显示，它(通常)专用于存储帧指针的位置。帧指针直接放在堆栈变量之后。紧接在帧指针之后的是返回地址，用绿色突出显示。返回地址引用了地址为`0x00401048`的代码片段。这条指令紧跟在一条`call`指令之后，明确了使用返回地址从调用函数停止的地方恢复执行的方式。





[![</p>
<p>Unfortunately <code>gets()</code> is a really stupid function. If we just hold down A on the keyboard it won't stop once it's filled the <code>name</code> buffer. It'll just keep on writing data to memory, overwriting the frame pointer, the return address, and anything and everything else it can.](../Images/65d9324309e44e59b335010da3d20bc4.png)](https://cdn.arstechnica.net/wp-content/uploads/2015/08/basic-stack-overflow-a.png)

[Enlarge](https://cdn.arstechnica.net/wp-content/uploads/2015/08/basic-stack-overflow-a.png) /

不幸的是`gets()`是一个非常愚蠢的函数。如果我们只是按住键盘上的 A，一旦它填满了`name`缓冲区，它就不会停止。它会继续向内存中写入数据，覆盖帧指针，返回地址，以及任何它能做的事情。





上面截图中的是那种经常溢出的缓冲区。它的大小固定为正好 64 个字符。在这种情况下，它填充了一串数字，并以最终的 null 结尾。从上图应该很清楚，如果超过 64 个字节被写入`name`缓冲区，那么栈上的其他值都会被破坏。如果多写了四个字节，帧指针就会被破坏。如果*八个*额外字节被写入，帧指针和返回地址都会被覆盖。

显然这将导致程序数据的损坏，但是缓冲区流的问题更严重:它们经常导致代码执行。发生这种情况是因为那些溢出的缓冲区不仅会覆盖数据。它们也可以覆盖堆栈中的另一个重要内容——返回地址。返回地址控制处理器在完成当前函数时将执行哪些指令；它应该是调用函数中的某个位置，但是如果它在缓冲区溢出中被覆盖，它可以指向任何地方。如果攻击者可以控制缓冲区溢出，他们就可以控制返回地址；如果他们能控制返回地址，他们就能选择处理器下一步执行什么代码。

该进程可能不会有一些好的、方便的“损害机器”功能供攻击者运行，但这并不重要。用于覆盖返回地址的同一个缓冲区也可用于保存一小段可执行代码，称为外壳代码，它反过来会下载恶意可执行文件，或打开网络连接，或执行攻击者喜欢的任何其他操作。

传统上，这样做是微不足道的，因为有一个特点可能看起来有点令人惊讶:一般来说，每个程序每次运行时都会使用相同的内存地址，即使在运行期间重新启动。这意味着缓冲区在堆栈上的位置每次都是相同的，因此用于覆盖返回地址的值每次都是相同的。攻击者只需要弄清楚地址是什么，就可以在任何运行有缺陷代码的电脑上进行攻击。