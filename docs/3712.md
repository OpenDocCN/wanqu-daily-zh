# 对话经济——声音和多模态计算的新时代| Sarah Guo | Greylock Perspectives

> 原文：<https://news.greylock.com/https-news-greylock-com-the-conversational-economy-voice-and-the-new-era-of-multi-modal-computing-96f535c058f6?utm_source=wanqu.co&utm_campaign=Wanqu+Daily&utm_medium=website>



Your new robot overlords come in [discount packs of six](https://www.amazon.com/b?node=15284854011)



# 对话经济——声音和多模态计算的新时代

“嘿 Siri，预测一下音频接口的未来。”如果她更聪明，她会回答说，2017 年将是一个转折点——这一年我们将一头扎进我们永远在线、支持音频的环境计算未来。

从最广泛的意义上来说，环境计算是计算的承诺，不仅限于每天打开手机 200 次。这是与现实世界进行持续的、多模态的、计算增强的交互的承诺。你家里或耳朵里越来越智能的监听设备就是朝这个方向迈出的一步。语音是环境计算的门户，语音领域现在非常令人兴奋。CES 感觉是捕捉风景快照的好时机。

妙语如下:

> 2017 年是语音成为主流“操作系统”的一年，因为我们获得了“足够好”的语音识别，因为支持语音的硬件得到了大规模部署，因为公司生态系统开始在大型语音平台(亚马逊、苹果、谷歌和微软，以及中国的百度)上认真建立。
> 
> 人们正在创造迷人的新硬件计算节点和语音原生应用。语音将减少我们在数据输入上花费的精力，支持残疾人，为更多预测性应用提供动力，并为移动设备带来新的工作流程。这些系统只受限于它们的**智能水平**，以及良好设计掩盖智能弱点的能力。
> 
> 在使能技术、设计、平台依赖性和安全性方面存在大量挑战。

# 声音砰的一声传来

亚马逊 Alexa 悄悄地从新奇发展到平台，现在拥有[7000 项技能](http://www.geekwire.com/2017/amazons-alexa-now-tops-7000-skills-a-7x-increase-in-7-months/)和超过 500 万个硬件单元，并且[企业部署开始](http://www.cnbc.com/2016/12/14/wynn-las-vegas-to-add-amazon-alexa-to-all-hotel-rooms.html)。随着 Alphabet 发布 Google Home 和以助手为中心的 Pixel 手机，个人助手之战升级为巨头之间的[多战线产品战争](https://www.cnet.com/uk/news/heres-everything-google-homes-doing-at-ces-2017/)。在过去的 18 个月里，语音识别已经成为智能手机、可穿戴设备的标准功能，并且越来越多地成为家用电器和汽车的标准功能——甚至是你的[床垫](https://www.thrillist.com/home/voice-automated-sleepnumber-bed-x12-smartbed-controlled-by-phone)。

## 输入 AirPods

美国人去年花在无线耳机上的钱比有线耳机多。苹果取消了 35mm 耳机端口，推出了他们真正的无线 [AirPods](http://www.apple.com/newsroom/2016/12/apple-airpods-are-now-available.html) (悬念！).自随身听时代以来，音频已经成为我们生活的一个重要部分[——2015 年，美国人平均每天听](http://www.independent.co.uk/arts-entertainment/music/features/the-rise-and-rise-of-headphones-why-the-set-you-buy-isn-t-just-a-question-of-sound-quality-but-a6756396.html) [3.5 小时的音乐](http://www.nielsen.com/us/en/insights/reports/2016/2015-music-us-year-end-report.html)，新一代千禧一代听得更多。我们关心音频设备的功能、声音，以及——自从 Beats 出现以来——它们的风格。我们使用耳机作为控制过度刺激环境的第一道防线。忘带耳机我就垂头丧气。它们是我的 swag 徽章，是我们开放式平面图中我处于心流模式的信号，是我用来调节情绪或集中注意力的[工具，是我接每个电话的方式，是防止婴儿啼哭的盾牌，是我不太善于交际的同伴的警告标志。](http://www.healthline.com/health-news/mental-listening-to-music-lifts-or-reinforces-mood-051713)

语音控制的一些应用已经成为主流——在 2016 年年中， [20%的 Android 搜索是基于语音的](http://www.thesempost.com/20-of-googles-mobile-search-queries-are-now-voice-queries/)，Siri 每周收到[20 亿次请求](http://www.wsj.com/articles/siri-once-a-flake-now-key-to-apples-future-1465905601)。

看似渐进的改进会导致技术使用中的阶跃函数变化。这发生在 2008 年苹果应用商店发布的时候，现在也发生在音频领域。



如果你带着 AirPods，身边有 iPhone，你可以对着周围稀薄的空气说出命令，而无需触摸手机。你甚至可以通过连续双击耳塞来跳过恼人的“嘿 Siri”唤醒词。仅仅这个功能就能显著增加我对 Siri 的使用(从现在的零开始)。AirPods 本身就是很棒的硬件。我爱他们，我使用他们，他们让 Siri 成为全新的更好的体验；已经有很多热情洋溢的评论了。



Apple product transition strategy



不幸的是，你的 Siri 查询经常会得到令人不满意的屏幕搜索结果。在可靠性、性能、智能和集成等所有重要领域，Siri 仍然远远落后于谷歌助手和 Alexa 它只与少数第三方应用程序兼容，特别是不包括苹果自己的音乐服务。

然而，从每天戴几个小时耳机，到每天多戴几个小时更轻便的无线耳机，甚至到在我们醒着的大部分时间里都戴着耳塞，这并不是一个巨大的挑战——特别是如果它们可以让我们连接到应用程序，同时允许我们继续体验世界的其他部分。

## **启用技术**

在技术方面，去年几家公司(包括百度和 T2 和微软)宣布他们已经打破了语音识别的人类障碍，通过深度学习方法达到了与人类同等的准确性。在远场和高噪声环境中也取得了令人印象深刻的进展——允许你在房间的另一端对着设备大喊大叫，或者在办公室里对着你的 AirPods 说情话。

重要的是，像 Echo 这样的产品似乎已经跨越了某种“延迟障碍”，提供足够快的响应，以至于主流用户会参与、试验和容忍失败的查询。

虽然许多这些进步始于大公司的研究实验室，但像 [PullString](https://www.pullstring.com/) 这样的全功能创作和运行时平台以及像 [Amazon Lex](https://aws.amazon.com/lex/) 这样的平台提供的工具的出现，正在降低创建对话体验所需的投资。像[高通](https://www.qualcomm.com/news/releases/2017/01/03/qualcomm-brings-active-noise-cancelling-technology-ultra-small-earbuds-and)这样的零部件制造商甚至将主动降噪这样的通用功能集成到他们的蓝牙芯片中。

## **新的计算节点**

今年到处都是监听设备；这种节点的爆炸是由一些主要参与者的举动以及随着家庭 IT 预算的扩张和更新而出现的企业家机会主义所驱动的([预读:我的合作伙伴 Josh 的帖子](/thinking-about-home-it-budgets-922f010e729f#.yls5ntn3x)来自上周)。

苹果的无耳机插孔 iPhone 7 是向真正的无线配件方向的一次有力的推动。无论我们认为这是一个勇敢的举动还是苹果的傲慢，他们已经通过这种设计选择和他们的 AirPods 的发布改变了市场。Alexa [迅速从运行良好的消费者扬声器演变为语音控制平台。它随后被越来越多的](http://www.itworld.com/article/2940651/personal-technology/and-suddenly-amazons-alexa-is-a-platform-rather-than-a-device.html)[新硬件公司](https://nucleuslife.com/)以及包括[福特和宝马](https://www.bloomberg.com/news/articles/2017-01-05/steering-wheel-shopping-arrives-as-alexa-hitches-ride-with-ford)在内的老牌公司采用，这推动了开发者的实验和消费者意识。当然，新贵硬件制造商也在分一杯羹:即将上市的 [Here One](https://hereplus.me/) 和 [Nuheara](http://www.nuheara.com/) 耳塞承诺我们可以精确控制我们的音频环境， [Waverly](http://www.waverlylabs.com/) 团队的目标是 Babelfish 梦想， [Kapture](http://kaptureaudio.com/) 希望让你回到过去再次听到任何东西， [Maven 副驾驶](http://mavenmachines.com/co-pilot/)希望确保司机的安全；以及无数其他[资金雄厚的 Kickstarter 音频硬件项目](https://www.indiegogo.com/projects/meet-the-pilot-smart-earpiece-language-translator-headphones-travel#/?src=HomepageButtonPreorder1)探索以音频为中心的帮助的界限。

演示容易，硬件难(有关于交付的众筹硬件项目的平均发货日期延迟和 NPS 的数据吗？).对于一家初创公司来说，拥有任何种类的带有设备上处理和互联网连接的大规模硬件都将是一个有价值的立足点——特别是如果你还可以建立持续的参与。硬件公司面临着两条通往成功的道路；即使一个人获得了主流的初次发行，如果没有持续参与的快速进展，市场也会残酷地对待你。尽管如此，我还是对我看到的一些令人印象深刻的原型和产品感到兴奋。

许多设备和应用程序将受益于简单的语音命令，而不是全功能的以语音为中心的设计。通过苹果电视做演示，说“下一张幻灯片”是很自然的，而不是用遥控器。我们还需要多久才能看到只需说“啪”就能开始录像的抓拍镜头？

与这些轻量级的语音应用相比，新的以语音为中心的节点的潜在巨大机会是家用机器人——从友好的桌面 [Jibo](https://www.jibo.com/) ，到 Mayfield Robotics 的类似 BB8 的 [Kuri](http://bgr.com/2017/01/03/kuri-smart-home-robot-specs-price-release-date/) ，到百度刚刚宣布的 DuerOS 驱动的[小鱼](http://www.theverge.com/circuitbreaker/2017/1/5/14178414/baidu-robot-duer-os-china)。这些家庭机器人旨在帮助家庭成员之间进行协调，拍照，娱乐，以及与外界沟通——例如通过从共享购物清单订购食品和杂货。研究人员也在研究老年人如何利用语音助手的可用性。大多数刚刚推出或尚未发货，2017 年将是这些友好的仆人能否找到市场的考验。







Meet your new family members







公司也在制造面向商业的机器人来与顾客互动。一个例子是人形软银[Pepper](http://www.softbank.jp/en/robot/)——即将在你附近的零售店工作。令人恐惧的是，配备了音频、面部识别和泰瑟枪机器人的半自动机器人已经在[部署用于人身安全。这种机器人的商业案例比家用机器人简单得多——它们可以取代人类工人，或者提高商店服务顾客或维护安全的能力。](https://www.google.com/amp/www.dailymail.co.uk/news/peoplesdaily/article-3803748/amp/Robotic-policeman-Anbot-begins-patrolling-China-trouble-makers-ruthless-TASER.html)

## **语音-本地应用**

软件人员也在手机上尝试更多的音频和语音。

我从中国获得了很多语音和信息设计的灵感。也许是受到打字困难、台式电脑向移动设备的跨越，或者是这个国家纯粹的环境噪音水平的驱动，语音输入在中国不仅在文化上被接受，而且一直占据主导地位。百度的通话式键盘[是语音优先的](https://techcrunch.com/2016/10/03/baidus-new-talktype-keyboard-app-emphasizes-voice-input-over-typing/)。我们认为 SnapChat 语音过滤器非常有趣，但中国人在 2012 年[的微信](https://www.techinasia.com/wechat-voice-app)中就有了。Papi Jiang，中国最大的网络名人(这是说了些什么)，只是在她的视频中用变声的[出现。](http://www.nytimes.com/2016/08/25/arts/international/chinas-viral-idol-papi-jiang-a-girl-next-door-with-attitude.html)

像 [Oben](http://www.oben.me/) 这样的公司正在将翻译和语音合成提升到一个新的水平，这样你就可以说另一种语言(用你自己的声音)或者用你自己的声音玩游戏。像[罗杰](https://rogertalk.com/)这样的团队正在迭代一键通范式。播客是一个长期被忽视的类别，被苹果无进展的原生应用扼杀了。但是在 Android 生态系统中，像 [CastBox](http://www.chinadaily.com.cn/business/tech/2016-12/09/content_27626656.htm) 这样的新玩家正在出现，而 [Bumpers](http://bumpers.fm/) 背后的人才正在让主流制作和分享来自你手机的音频变得更加容易。Talkitt 正在努力帮助那些语言障碍者。在 B2B 方面， [Cogito](http://www.cogitocorp.com/) 和 [BeyondVerbal](http://www.mobihealthnews.com/content/emotion-detecting-voice-analytics-company-beyond-verbal-raises-33m) 对不同用例的语音进行情感分析，例如理解医疗保健系统中的患者情绪。Nuance 长期以来一直提供基本的转录应用程序来帮助医疗制图，尽管在这方面仍有巨大的进步。[龚](https://www.gong.io/)和[三叶草智能](https://cloverintelligence.com/)会分析你的销售代表的电话。

## **数据摄取，而不是数据输入**

问某人他们讨厌办公室工作的什么，一个非常普遍的答案是数据录入。随着商业技术的采用，我们已经围绕着无意识的现代文书工作——软件工作——创造了数百万小时的劳动。如果我们可以记录我们的对话并理解它们(提取结构化数据)，我们就可以消除这些数字填表工作流。这将减轻许多人的负担，从需要总结客户互动的技术销售代表，到今天花更多时间与 EPIC 软件互动而不是与病人互动的医生。



Bao, Pierce, et al., 2011



在一个更平凡的层面上，改进手机上的文本输入将扩大我们使用的应用程序集。客观地说，在手机上打字是不好的，即使对于最习惯使用手机的青少年来说也是如此。根据加州大学圣克鲁斯分校的一项研究，在移动设备上，我们每分钟的速度[比在桌面上打字慢 2.7 倍](https://people.ucsc.edu/~swhittak/papers/MobileHCI2011_FINAL.pdf)，比说话慢 6.4 倍(每分钟 140-150 WPM)。

这种差异，加上输入凭证的痛苦、小屏幕的限制以及智能手机引起的分散注意力，意味着大多数用户仍然避免在移动设备上创建内容和其他输入密集型业务任务。

我们能否增强(消除？)记笔记？我们想吗？如果我们每个人都有一个私人的、高质量的抄写员，不仅能记住所有的事情，还能理解所有的事情，我敢打赌是的。尤其是如果这意味着我们可以专注于更吸引人的信息，或者与我们互动的人在一起。

作为对未来的一种窥视，在去年的 Greylock[hack fest](http://www.greylock.com/greylock-u/hackfest/)上，一个令人敬畏的团队( [Jenny Wang](https://www.linkedin.com/in/jwang15) 、 [Will Hang](https://www.linkedin.com/in/willhang) 、 [Guy Blanc](https://www.linkedin.com/in/guy-blanc-57371973) 和 [Kevin Yang](https://www.linkedin.com/in/kevin-yang-16546290) )在一个他们称为 GreyLockscreen 的雄心勃勃的项目上工作。他们的项目使用始终在线的环境听力、自然语言理解(NLU)和深度链接来预测和显示智能手机上的内容和动作，而不需要明确的命令。例如，如果你把手机放在桌子上，你对你的朋友说，“Jenny，我饿了，我们去买 [Sprig](https://www.sprig.com/#/) ”这种情况的一个实现可能是展示一个预先填充的 Sprig cart。研究人员正在研究相关的产品概念，如“[环境文档检索](http://www.aclweb.org/anthology/C/C16/C16-1196.pdf)”

# 挑战

## **NLU 和音频处理**

除了准确转录的要求之外，语音还面临着几乎所有与今天的通讯机器人相同的技术问题。尽管最近在语言理解和语音合成方面取得了令人印象深刻的进步，但创造一种引人注目的基于语音的体验仍然是一项艰巨的任务，并且经常涉及新的研究。
NLU 是一个非常困难的问题，开始看起来类似于人工通用智能(AGI)——不仅仅是感知，还有认知。像脸书大学这样的大型实验室正在积极研究推理、注意力和记忆等问题。例如，基于事实回答问题、计数、创建列表、共指(指同一事物的两个表达式)、理解时间、属性继承、大小和位置推理是脸书着手在有限的数据集上解决的[推理任务的一部分。我们还有很长的路要走。](https://research.fb.com/projects/babi/)

像 Ozlo 这样的小公司正在引入问题的范围，从食物和地点这样的领域开始缩小范围。但是，即使在受限的问题空间中，人们也必须做出复杂的决策。[哪些点评值得信赖](https://qz.com/843110/can-artificial-intelligence-solve-facebooks-fake-news-problem/)？即使我们能够完成脸书提出的那种推理，我们也只是触及了“知识”的表面根据定义，自然语言模型的训练数据将由用户生成——什么是事实？

在音频本身，除了转录之外，还有很多工作要做——未解决的问题，如口音、不同环境、说话人识别以及更好、更情绪化的文本到语音转换。例如，进入谷歌助手或 Siri 句子的每个声音仍然由一名[配音演员](https://www.cnet.com/news/we-chatted-with-siri-for-real-and-werent-frustrated-with-her-answers-q-a/)煞费苦心地配音，然后在一个名为“[拼接语音合成](http://www.theverge.com/2013/9/17/4596374/machine-language-how-siri-found-its-voice)的过程中进行剪切和重组这种方法很昂贵，听起来仍然断断续续，并且很难添加感情色彩或强调。然而，在这里，深度和强化学习似乎再次取得了进展，例如最近谷歌 DeepMind 的 [WaveNet 结果](https://deepmind.com/blog/wavenet-generative-model-raw-audio/)，基于对音频中的原始波形进行建模。

## **未知的 UX 领土**

因为我们的技术还没有达到我们想要的水平，我们需要用好的设计来磨平边缘。今天，不被语音机器理解，没有追索权，是令人愤怒的，这种事情经常发生。你对你的 Alexa 吼过多少次？你的助手今天有多少时间会回答“对不起，我找不到这个问题的答案”？



语音交互的设计仍处于早期阶段，平面界面有*个无限制的输入*。用户可以说的话没有自然的限制，危险的是，他们自然地将人类的特征归于语音系统。在接下来的几年里，语音系统将无法对许多查询做出正确的反应。即使没有解决 NLU 问题，我们也可以提高可用性，我们将会看到对语音界面设计的兴趣。

支持用户控制和自由，提高灵活性和效率，防止和处理错误，甚至可能使用[可共享设计](/intuitive-design-vs-shareable-design-88ff6bb184bb?source=user_profile---------1----------)都会有所帮助。当我们能够教会语音助手特定的快捷命令、名称、默认设置和热门词汇时，以及当公共设备支持独特的用户配置文件时，我们的语音助手将会好得多。

屏幕具有海量的相对信息密度，多模态语音+屏幕体验将是许多问题的正确短期解决方案(参见关于屏幕回声[的传言)。](http://fortune.com/2016/11/29/amazon-echo-touchscreen/)

像 Sayspring 和 T2 voice labs 这样的语音原型和分析工具已经开始出现。

## **计算功率和电池**

Siri 最常见的抱怨是速度慢，不能到达苹果服务器群，不能离线工作。实际上，目前主要的语音助手(亚马逊、苹果、谷歌)都不在本地工作——他们的大脑都在各自父母的云后端，这种情况不太可能很快改变。响应语音查询需要复杂的基于机器学习的模型推理，这是一项计算量非常大的任务。

永远在线收听和连接是耗电特性。因此，我们看到大多数语音控制的无线产品需要一个按钮，而不是一个热门词汇:例如，便携式 [Echo Tap](http://techcrunch.com/2016/03/03/amazon-adds-the-130-tap-and-the-90-dot-to-the-echo-family/) ，并利用单独的专用处理器，如 [DMBD4](http://news.techtime.co.il/2016/02/22/dspg-5/) 和苹果 W1。

## **隐私、安全和认证**

突然间，我家里有不下十个设备一直在听我说话——Apple TV、Samsung TV、Xbox、Google Home、an Echo、two Dots 以及我们的 iPhones 和 AirPods。

今天，我对声控设备的监控感到不安，但同样，我也对我的浏览器和搜索历史的丰富性感到不安。

然而，未来隐私论坛对这些设备的分类是值得理解的。这些公司记录并保留你声音的唯一时间是你激活它们的时候。



[Categories of Microphone-Enabled Devices](https://www.ftc.gov/system/files/documents/public_comments/2016/08/00003-128652.pdf)



这在一个没有像“Alexa”这样的热键记录音频的世界里会非常不同。这可以无害地开始，随着热键周围的时间窗口的扩大。如果谷歌在任何“好的，谷歌”请求之前记录并发送 90 秒，以便收集更多的上下文并给你一个更好的答案，会怎么样？你会允许吗？



对麦克风设备的恐惧与我们周围越来越多的摄像头的恐惧类似——尽管至少安全摄像头往往指向我们的家外，而不是室内。即使我们对联网摄像头和麦克风的预期功能感到满意，这些设备[本身也可能不安全](http://motherboard.vice.com/read/15-million-connected-cameras-ddos-botnet-brian-krebs)，或者它们可能被用于政府监控。我们能保证每个 Alexa Echo 都没有后门吗？如果不能，那么[意味着什么？如果陌生人、朋友和同事处于](http://www.stltoday.com/business/credit/could-what-your-amazon-alexa-overhears-be-used-against-you/article_dfe2e1f0-29c8-52d4-af61-6c8263e19e6b.html)[窃听模式](http://www.usatoday.com/story/tech/news/2016/11/22/here-one-earbuds-wireless-computers-your-ears/94233730/)，他们听到你的口授命令、对话和想法，你会感到舒服吗？或者你会采用[看起来令人毛骨悚然但很有灵感的 Hushme 口吻](http://www.itechpost.com/articles/72257/20170107/make-way-worlds-first-voice-mask-mobile-phones.htm)？

最后，为了让我们通过语音界面访问许多重要的服务，我们必须能够对它们进行认证。Alexa 从相关的亚马逊账户默认购买，导致有电子商务能力的儿童，办公室恶作剧和新闻播音员意外订购他的观众[玩具屋](http://m.theregister.co.uk/2017/01/07/tv_anchor_says_alexa_buy_me_a_dollhouse_and_she_does/?mt=1483826279792)。更严重的是，如果我想通过他们的 [](http://www.cnbc.com/2016/10/24/bank-of-america-launches-ai-chatbot-erica--heres-what-it-does.html) [虚拟助理 Erica](http://www.forbes.com/sites/quora/2016/10/28/meet-erica-bank-of-americas-new-voice-ai-banking-system/) 访问我的美国银行账户，她怎么会知道我是我呢？传统凭证在语音设备上似乎比在移动设备上更糟糕。一些人认为声音作为生物特征认证更有可能。不幸的是，语音生物识别解决方案作为单独的解决方案感觉不可持续。正如照片处理软件意味着眼见不再为实(不知何故，如今社交媒体上的每个 15 岁的孩子都比我那个年龄的时候更帅)，音频处理和合成技术表明，很快[听觉将不再相信](http://www.uab.edu/news/innovation/item/6532-uab-research-finds-automated-voice-imitation-can-fool-humans-and-machines)。虽然今天有各种州级规则围绕[同意录音](http://www.dmlp.org/legal-guide/california-recording-law)，远场麦克风使执法更加困难。

这些接口是对当今有缺陷的身份认证方法的又一次推动，使其转向考虑许多不同信号的行为、上下文、基于风险的身份系统。

如果我在我家所在的地理围栏区内，我的回声与我的智能手机在同一个无线网络上，我的声音与亚马逊存档的声纹进行了生物识别匹配，并且我成功通过了 Okta 的[第二因素认证](https://www.okta.com/products/adaptive-multi-factor-authentication/)，那么我是我的几率比你一般的网上银行登录高得多。

# 梦想着不久的将来

今天，我们似乎正在艰难地构建一个相对狭窄的不完善的语音应用程序和设备，但我们将看到语音命令和助手到处出现。我们想要从我们的智能助手那里得到什么，将取决于他们的智能水平，以及我们围绕智能差距的创造性设计。这个时期有许多新的计算节点和新的移动交互方式，这是一个巨大的机会。在这一点上，有用的对话服务的技术和文化障碍比以往任何时候都更容易克服——随着对[亚声通信和大脑计算接口的研究](http://www.smithsonianmag.com/innovation/why-brain-brain-communication-no-longer-unthinkable-180954948/)偷偷走出黑暗边缘，进入可能性的曙光，超越的东西引发了想象力。基于 NLU 和对话的系统将是未来十年现代机器学习的一些最重要的应用。

你在用声音造一些很酷的东西吗？我听着呢！
在此回复，推特 DM[@ saranomous](https://twitter.com/saranormous)，或者发邮件给我—莎拉(at)[greylock.com](http://greylock.com)

*格雷洛克是* [*奥克塔*](https://www.okta.com/) *、* [*奥兹洛*](https://www.ozlo.com) *、* [*拉线*](https://www.pullstring.com/) *和*T32 的投资人





