# 离开 MongoDB WiredTiger 并返回 MMAPv1 | CleverTap

> 原文:[https://blog . clever tap . com/with-MongoDB-wired tiger-and-our-return-to-MMA pv1/？UTM _ source = Wanqu . co&UTM _ campaign = Wanqu+Daily&UTM _ medium = website](https://blog.clevertap.com/sleepless-nights-with-mongodb-wiredtiger-and-our-return-to-mmapv1/?utm_source=wanqu.co&utm_campaign=Wanqu+Daily&utm_medium=website)

在过去的两年中，我们一直使用 MongoDB 2.6 和 MMAPv1 作为存储引擎。在我们升级到 3.0 并将配置了 WiredTiger 作为存储引擎的辅助服务器升级到主服务器之前，它一直是我们系统中的一个稳定组件。具体来说，我们在一台主服务器上每秒大约执行 18.07 千次操作。我们在集群中有两个碎片，因此两个主服务器每秒大约执行 36.14K 次操作。这代表了我们传入流量的一小部分，因为我们将大部分存储卸载到定制构建的内存存储引擎

## 吞吐量提高 7 到 10 倍的诱惑

WiredTiger 承诺通过文档级并发实现更快的吞吐量，这与 MMAPv1 中的集合级并发相反。在生产升级前的快速测试中，我们看到了 7 倍的性能提升。惊讶之余，我们决定在接下来的周末升级。我们将分阶段进行。将集群元数据和 Mongo 二进制文件从 2.6 升级到 3.0。睡 3 天
2。使用 WiredTiger 作为存储引擎重新同步次映像，并将其提升为主映像。睡眠
3。将配置服务器更改为 WiredTiger。睡眠
4。升级现有的 MONGODB-CR 用户使用 SCRAM-SHA-1。睡眠

考虑到这么多的睡眠，我们希望能清醒地醒来🙂

## 升级

第一阶段——二进制升级在周六早上一个小时内准时完成。与此同时，所有传入的流量在升级后都被排队和处理。周一晚上，我开始用 WiredTiger 作为存储引擎重新同步备用服务器

到目前为止一切顺利　‘

第二阶段——周二，我们关闭了主节点，让 WiredTiger 驱动的辅助节点开始为生产流量提供服务。几分钟内，我们就获得了分析数据，显示我们的吞吐量确实增加了

此时，我们可能会在不影响吞吐量的情况下在 MongoDB 上增加 7 倍的流量。WiredTiger 信守承诺。经过几个小时的生产，我们决定重新同步旧的 MMAPv1 主节点，这些节点现在是辅助节点，存储引擎设置为 WiredTiger。我们现在在副本集中运行一个功能数据节点(主节点)。

## 一小时后，天下大乱

MongoDB 的吞吐量在几分钟内下降到大约每秒 1K 次操作。感觉像是 MongoDB 停了下来。这是我们与“电线老虎”短暂而疯狂的旅程结束的开始。在匆忙找出发生了什么的时候，我们的监控系统报告说 Mongos 节点关闭了。手动启动它们带来了几分钟的轻松。Mongos 日志似乎说:

```
 2016-MM-DDT14:29:55.497+0530 I CONTROL  [signalProcessingThread] got signal 15 (Terminated), will
 terminate after current cmd ends
2016-MM-DDT14:29:55.497+0530 I SHARDING [signalProcessingThread] dbexit:  rc:0 
```

谁/什么东西发送信号还不知道。系统日志没有这方面的详细信息。几分钟后，Mongos 决定再次退出。

这时，我们都跳进了作战室——Mongod 节点和 Mongos 一起重新启动。事情看起来很稳定，我们有一些时间来重组和思考刚刚发生的事情。在几次 mongo 锁定之后，我们根据遥测数据发现，每次 WiredTiger 的缓存达到 100%时，MongoDB 都会锁定。我们的数据节点运行在 r3.4xlarge (120GB RAM)实例上。默认情况下，MongoDB 为 WiredTiger 的缓存分配了 50%的 RAM。随着时间的推移，当缓存填满 100%时，它会停止。每隔几个小时就会出现即将到来的锁定，而且在半夜还会有更多的锁定，这让我们感到不安，于是我们转向了 r3.8xlarge (240GB RAM，感谢上帝赐予我们 AWS)。对于 120G 缓存，我们了解到 WiredTiger 对于我们的工作负载和工作集稳定在 98G 缓存。我们的副本集中仍然没有辅助节点，因为启动重新同步会将缓存推到 100%并使 MongoDB 停止。又是一个不眠之夜，我们让 MongoDB 数据节点在 x1.32xlarge (2TB RAM)上运行。AWS 是不是很牛逼？凭借 1TB 的缓存，我们能够让我们的辅助节点与设置为 MMAPv1 的存储引擎完全重新同步，以便我们可以恢复并摆脱 WiredTiger 及其缓存需求。MMAPv1 的吞吐量较低，但很稳定，我们必须尽快恢复它

## 吸取的教训(艰难的道路)

### 升级时，将 MMAPv1 副本节点保留至少 10 天

我们太快开始与设置为 WiredTiger 的存储引擎重新同步，如果我们完全同步，我们就可以将 MMAPv1 作为主运行来提升辅助运行，避免所有的不眠之夜

### 根据您的工作负载正确调整您的操作日志

由于频繁的更新和插入，我们的操作日志在正常生产时间可以保存几个小时的数据。只有在晚上，我们才有足够的数据时间来重新同步和使用操作日志。这意味着我们只能在晚上重新同步

### WiredTiger 很有前途，但目前还不成熟

根据我们的经验，WiredTiger 确实实现了 7 到 10 倍的吞吐量提升，但当缓存达到 100%时就会锁定。我们已经能够用最新的版本(在撰写本文时是 3.2.9)重现这个问题，并且正在提交一份错误报告。我们致力于提供更多信息来帮助解决这个问题。目前的情况是，一旦工作集超过配置的缓存大小，WiredTiger 存储(这是 MongoDB 最新版本中的默认存储)就会不稳定。这将导致生产停止

## 配置服务器太了解数据的状态

作为结束语，如果您正在评估或使用 MongoDB，请考虑一下灾难恢复。在灭火过程中，我们意识到，如果您的数据在共享集群中，从文件系统快照备份恢复或设置新集群是多么困难。对于每个节点大约 200G 的数据集，从每个节点导出所有数据并将其导入到新的集群中是非常慢的。在我们的案例中，大约需要 36 个小时

更新#1:
我们在表示我们公布的数字时犯了一个错误。它是操作/秒(字面意思是你可能犯的最严重的错误)，而不是开头段落中所说的操作/分钟。我已经更新了这篇文章来反映这个变化

更新# 2:
–在所有条件相同的情况下，WiredTiger 至少应该具有 MMAPv1 的稳定性，因为它是 Mongo 3.2 及以后版本的默认存储引擎选项
–每次我们重新启动数据节点时，WiredTiger 都会正常工作几个小时，然后死机。深入挖掘后，我们注意到当缓存达到 95%的容量时，它会冻结。很明显，这里存在一些缓存回收问题

最后更新于 2018 年 5 月 30 日