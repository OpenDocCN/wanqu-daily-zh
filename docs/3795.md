# 大规模在线迁移

> 原文:[https://stripe.com/blog/online-migrations?UTM _ source = Wanqu . co&UTM _ campaign = Wanqu+Daily&UTM _ medium = website](https://stripe.com/blog/online-migrations?utm_source=wanqu.co&utm_campaign=Wanqu+Daily&utm_medium=website)



工程团队在构建软件时面临一个共同的挑战:他们最终需要重新设计他们用来支持清晰抽象和更复杂特性的数据模型。在生产环境中，这可能意味着迁移数百万个活动对象和重构数千行代码。

Stripe 用户期望从我们的 API 获得可用性和一致性。这意味着当我们进行迁移时，我们需要格外小心:存储在我们系统中的对象需要有准确的值，并且 Stripe 的服务需要始终可用。

在本帖中，我们将解释我们如何安全地完成数亿订阅对象的大型迁移。

## 为什么迁移很难？

### 规模

Stripe 拥有上亿个订阅对象。运行涉及所有这些对象的大型迁移对于我们的生产数据库来说是一项繁重的工作。

想象一下，迁移每个订阅对象需要一秒钟的时间:以连续的方式，迁移一亿个对象需要三年多的时间。

### 正常运行时间

企业经常在 Stripe 上进行交易。我们在线执行所有基础架构升级，而不是依赖计划维护窗口。因为我们不能在迁移期间简单地暂停订阅服务，所以我们必须在所有服务 100%运行的情况下执行迁移。

### 准确(性)

我们的 Subscriptions 表被用在我们代码库中的许多不同地方。如果我们试图一次性修改订阅服务中的数千行代码，我们几乎肯定会忽略一些边缘情况。我们需要确保每项服务都能继续依赖准确的数据。

## 在线迁移的模式

将数百万个对象从一个数据库表移动到另一个数据库表很困难，但这是许多公司需要做的事情。

有一个常见的 4 步*双重写入模式*，人们经常使用它来进行类似这样的大型在线迁移。它是这样工作的:

1.  **双重写入**到现有的和新的表格，以保持它们同步。
2.  **更改我们代码库中的所有读取路径**,以便从新表中读取。
3.  **将我们代码库中的所有写路径**更改为仅写入新表。
4.  **删除依赖过时数据模型的旧数据**。

## 我们的迁移示例:订阅

什么是订阅，为什么我们需要进行迁移？

[Stripe Billing](https://stripe.com/billing) 帮助像 [DigitalOcean](https://www.digitalocean.com/) 和 [Squarespace](https://www.squarespace.com/) 这样的用户为他们的客户建立和管理重复计费。在过去的几年里，我们稳步增加了一些功能来支持他们更复杂的计费模式，比如多重订阅、试用、优惠券和发票。

在早期，每个客户对象最多有一个订阅。我们的客户是作为个人记录存储的。因为客户到订阅的映射很简单，所以订阅与客户一起存储。

类客户认购认购结束

最终，我们意识到一些用户想要创建拥有多个订阅的客户。我们决定将`subscription`字段(对于单个订阅)转换为`subscriptions`字段&& mdash；允许我们存储多个活动订阅的数组。

类别客户数组:订阅订阅结束

随着我们添加新功能，这个数据模型变得有问题。对客户订阅的任何更改都意味着更新整个客户记录，并且与订阅相关的查询会扫描客户对象。所以我们决定单独存储活动订阅。





我们重新设计的数据模型将订阅移到它们自己的表中。





提醒一下，我们的四个迁移阶段是:

1.  **双重写入**到现有的和新的表格，以保持它们同步。
2.  **更改我们代码库中的所有读取路径**,以便从新表中读取。
3.  **将我们代码库中的所有写路径**更改为仅写入新表。
4.  **删除依赖过时数据模型的旧数据**。

让我们看一下这四个阶段在实践中的表现。

## 第 1 部分:双重写作

我们通过创建一个新的数据库表来开始迁移。第一步是开始复制新信息，以便将其写入两个存储中。然后，我们将缺失的数据回填到新的存储中，这样两个存储就保存了相同的信息。





所有新的写入都应该更新两个存储。





在我们的例子中，我们将所有新创建的订阅记录到 Customers 表和 subscriptions 表中。在我们开始对两个表进行双重写入之前，有必要考虑一下这种额外写入对生产数据库的潜在性能影响。我们可以通过慢慢提高重复对象的百分比来缓解性能问题，同时密切关注运营指标。

此时，新创建的对象存在于两个表中，而旧的对象只存在于旧的表中。我们将以一种懒惰的方式开始复制现有的订阅:每当对象被更新时，它们将被自动复制到新表中。这种方法让我们开始逐步转移我们现有的订阅。

最后，我们将把任何剩余的客户订阅填充到新的订阅表中。





我们需要将现有的订阅回填到新的订阅表中。





在动态数据库中回填新表最昂贵的部分就是找到所有需要迁移的对象。通过查询数据库来查找所有对象需要对生产数据库进行多次查询，这将花费大量时间。幸运的是，我们能够将这一任务卸载到一个对我们的生产数据库没有影响的离线过程中。我们将数据库的快照提供给 Hadoop 集群，这让我们可以使用 [MapReduce](https://en.wikipedia.org/wiki/MapReduce) 以离线、分布式的方式快速处理我们的数据。

我们使用[burning](https://github.com/twitter/scalding)来管理我们的 MapReduce 作业。burning 是一个用 Scala 编写的有用的库，它使编写 MapReduce 作业变得很容易(您可以用 10 行代码编写一个简单的作业)。在这种情况下，我们将使用 burning 来帮助我们识别所有订阅。我们将遵循以下步骤:

*   编写一个烫手的作业，提供需要复制的所有订阅 id 的列表。
*   运行一个大型的多线程迁移，通过一系列高效地并行处理我们的数据的流程来复制这些订阅。
*   迁移完成后，再次运行 burning 作业，以确保订阅表中没有丢失任何现有订阅。

## 第 2 部分:更改所有读取路径

既然新旧数据存储已经同步，下一步就是开始使用新的数据存储来读取所有数据。





现在，所有的读取都使用现有的 Customers 表:我们需要转移到 Subscriptions 表。





我们需要确保从新订阅表中读取是安全的:我们的订阅数据需要保持一致。我们将使用 GitHub 的[科学家](https://github.com/github/scientist)来帮助我们验证我们的读取路径。Scientist 是一个 Ruby 库，它允许您运行实验并比较两个不同代码路径的结果，如果两个表达式在生产中产生不同的结果，它会提醒您。借助 Scientist，我们可以实时生成不同结果的警报和指标。当一个实验性的代码路径生成一个错误时，我们应用程序的其余部分不会受到影响。

我们将运行以下实验:

*   使用 Scientist 读取订阅表和客户表。
*   如果结果不匹配，则引发一个错误，提醒我们的工程师注意不一致性。





GitHub 的科学家让我们运行从两个表中读取数据并比较结果的实验。





在我们验证了一切都匹配之后，我们开始从新表中读取数据。





我们的实验是成功的:现在所有的读取都使用新的订阅表。





## 第 3 部分:更改所有写入路径

接下来，我们需要更新写入路径以使用新的订阅存储。我们的目标是逐步推出这些变化，所以我们需要采用谨慎的策略。

到目前为止，我们一直将数据写入旧存储，然后将它们复制到新存储:

我们现在想颠倒顺序:将数据写入新存储，然后将其存档在旧存储中。通过保持这两个存储彼此一致，我们可以进行增量更新，并仔细观察每个变化。

重构我们变更订阅的所有代码路径可以说是迁移中最具挑战性的部分。Stripe 用于处理订阅操作(如更新、按比例分配、续订)的逻辑跨越多个服务的数千行代码。

成功重构的关键是我们的增量过程:我们将把尽可能多的代码路径隔离成最小的单元，这样我们就可以小心地应用每一个变化。我们的两个表需要在每一步都保持一致。

对于每一条代码路径，我们需要使用一种整体的方法来确保我们的更改是安全的。我们不能只是用旧记录代替新记录:每一条逻辑都需要仔细考虑。如果我们错过了任何案例，我们可能会以数据不一致而告终。幸运的是，我们可以运行更多的科学家实验来提醒我们在这个过程中任何潜在的不一致。

我们新的简化写入路径如下所示:

如果调用该属性，我们可以通过引发错误来确保没有代码块继续使用过时的`subscriptions`数组:

类客户定义订阅 Opus::Error.hard("访问客户上的订阅数组")end end

## 第 4 部分:删除旧数据

我们的最后一步(也是最令人满意的一步)是移除写入旧存储的代码，并最终删除它。

一旦我们确定不再有代码依赖过时数据模型的`subscriptions`字段，我们就不再需要写入旧表:

有了这一改变，我们的代码不再使用旧的存储，新的表现在成为我们的真理来源。

我们现在可以删除所有客户对象上的`subscriptions`数组，我们将以一种懒惰的方式递增地处理删除。我们首先在每次加载订阅时自动清空数组，然后运行最终的烫洗作业和迁移，以找到任何要删除的剩余对象。我们最终得到了想要的数据模型:

## 结论

在保持条带 API 一致的同时运行迁移非常复杂。以下是帮助我们安全运行迁移的因素:

*   我们制定了一个分四个阶段的迁移策略，使我们能够在不停机的情况下在生产中运行服务的同时迁移数据存储。
*   我们使用 Hadoop 离线处理数据，允许我们使用 MapReduce 以并行方式管理大量数据，而不是依赖生产数据库上昂贵的查询。
*   我们所做的所有改变都是渐进的。我们从未试图一次修改超过几百行代码。
*   我们所有的变化都是高度透明和可观察的。只要生产中有一个数据不一致，科学家的实验就会提醒我们。在前进的每一步中，我们都对安全迁移充满信心。

我们在 Stripe 执行的许多在线迁移中发现这种方法非常有效。我们希望这些实践对其他大规模执行迁移的团队有用。

