# 厨房肥皂——各有所需，但只有合在一起才足够

> 原文:[http://www . kitchen soap . com/2012/02/10/each-needly-but-only-joint-sufficient/？UTM _ source = Wanqu . co&UTM _ campaign = Wanqu+Daily&UTM _ medium = website](http://www.kitchensoap.com/2012/02/10/each-necessary-but-only-jointly-sufficient/?utm_source=wanqu.co&utm_campaign=Wanqu+Daily&utm_medium=website)

[![](../Images/07a68d5a4df14cd42f3fe088e7933c31.png "NoRootCause")T2】](http://www.kitchensoap.com/wp-content/uploads/2012/02/NoRootCause.jpg)

我认为这可能值得更深入地挖掘一下我在去年的 Velocity 大会上发表的[高级事后分析演讲](http://velocityconf.com/velocity2011/public/schedule/detail/19766 "Advanced Postmortem Fu")中提到的一些东西。

对于复杂的社会技术系统(web 工程和运营),有一个神话应该被打破，那就是关于中断和事故的假设，有一个单一的统一事件触发了导致中断的一系列事件。

这实际上是一个谬误，因为对于复杂系统来说:

**没有根本原因。**

这不完全是直觉，因为这违背了我们作为工程师的本性。我们喜欢简化复杂的问题，这样我们就可以用简化的方式来解决它们。我们*希望*事故或停机只有一个根本原因，因为如果我们能够确定这一点，我们就已经确定了需要修复的缺陷。修复这个错误，我们就防止了这个问题在未来发生，对吗？

因果分析中也有很强的趋势(尤其是在我们的领域，IMHO ),找到一个人接触某物的地方，并指出那是“根本”原因。那些肮脏愚蠢的人类。这样，我们就可以把唯一的责任归咎于“缺乏训练”，或者臭名昭著的可怕标签“人为错误”。当然，这也不是一个成功的方法。

但是，你可能会问，根本原因分析的“五个为什么”方法呢？从结果开始，沿着一条线性链向最初的触发事件回溯，感觉很直观，这就是它如此受欢迎的原因。另外，那些丰田的家伙知道他们在说什么。但是，在围绕复杂故障的假设方面，它也陷入了同样的问题。

正如《职场心理学》上的这篇精彩文章正确地指出了五个为什么的局限性:

> “五个为什么”的一个基本假设是，每个症状只有一个充分的原因。情况并非总是如此，5 个为什么分析可能无法揭示解释症状的足够多的原因。

这里概述的五个为什么方法还有一些其他的限制，比如它不是一个幂等过程，但是我想在这里指出的是，因果关系的线性心理模型不能捕捉到提高系统安全性所需要的东西。

一般来说，线性事件链方法类似于将过去视为一排多米诺骨牌，而复杂系统的现实并不是这样的。以这种方式看待事故，忽略了周围的环境，有利于精选的事件列表，它验证了[后见之明](http://youarenotsosmart.com/2010/06/14/hindsight-bias/)和[结果偏差](http://en.wikipedia.org/wiki/Outcome_bias "outcome bias")，并且过多地关注组件，而对组件的相互联系关注不够。

在压力大的时候(如停机)，参与响应、故障排除和恢复的人员也经常会在事件发生时误记事件，有时会无意识地忽略观察、假设等的关键事实和时机。这显然会影响使用线性事故调查模型(如五个为什么)的结果。

然而，这种识别单一根本原因和源于它的线性链使得事情非常容易解释、理解和记录。这有助于我们确信我们将防止问题的再次发生，因为只有一件事需要解决:根本原因。

甚至著名的认知工程专家 James Reason 的[流行病学(瑞士奶酪)模型](http://en.wikipedia.org/wiki/Swiss_cheese_model "Swiss Cheese Model")也展示了其中的一些局限性。虽然*确实*有助于捕捉多个促成原因，但该机制仍然是线性的，这可能会鼓励人们认为，如果他们只是消除其中一个原因(或修复链中某个原因的“障碍”)，那么他们将来就会受到保护。

然而，我要指出的是，拥有一个开放而成熟的调查因果关系的过程，使用**任何**模型，对一个组织来说是一件好事，五个为什么可以帮助启动所需的批判性思维。因此，我并不特别指责“五个为什么”是没有价值的实践，只是它在识别有助于为系统带来弹性的项目方面的能力有限。

同样，这种为 *[寻找单一根本原因的倾向从根本上令人惊讶的](http://csel.eng.ohio-state.edu/woods/error/fund_surp.pdf "fundamental surprise")* (通常是负面的)事件，如停机，是无处不在的，难以撼动。当我们因为技术、文化、甚至组织上的*政治*原因而感到压力时，我们会感到快速解决停机问题的压力。当有压力要快速理解和解决一个(感知的)负面事件时，我们会过于简单化。这种情况的一些典型原因是:

*   管理层想要一个答案来解释为什么它发生得这么快，他们甚至可能会找一个理由来惩罚某人。当只有一个根本原因时，很简单地归咎于“那个不注意的人”或者“不称职”
*   参与设计/建造/操作/维护与停电有关的基础设施的工程师对故障或错误的话题感到不舒服，因此反应是结束调查。这鼓励了原因和补救措施的过度简化。
*   失败太他妈复杂了，无法记在脑子里。[后见之明偏见](http://youarenotsosmart.com/2010/06/14/hindsight-bias/ "Hindsight bias")鼓励反事实思维(“..如果我们注意的话，我们会看到这一切的！”或者“…我们早该知道的！”)这促使我们认为原因很简单。

因此，如果没有单一的根本原因，那会是什么呢？

我同意理查德·库克的论断，即复杂系统中的[故障](http://www.ctlab.org/documents/Ch%2007.pdf "How Complex Systems Fail")需要**多种促成原因，每一个都是必要的，但只有共同充分。**

霍尔纳格尔、伍兹、德克尔和库克在《弹性工程导论》中指出:

> 事故产生于通常与追求成功相关的条件和事件的汇合，但在这种组合中——每个都是必要的，但只有共同充分——反而能够引发失败。

坦率地说，我认为这种寻找单一根本原因的倾向也来自于现代科学和工程对还原论原则的根深蒂固。所以我责怪牛顿和笛卡尔。但那是另一篇文章。🙂

因为复杂系统有涌现行为，而不是结果行为，所以可以换一种说法:

找到失败的根本原因就像找到成功的根本原因一样。

那么这给我们留下了什么？如果没有单一的根本原因，我们应该如何调查停机、降级和故障，以帮助我们预防、检测和应对未来的此类问题？

答案并不简单。为了真正从停机和故障中吸取教训，需要系统性的方法，下面提到了其中的一些方法。不管实现如何，大多数系统模型都认识到这些事情:

*   …复杂系统不仅涉及技术，还涉及组织(社会、文化)的影响，在调查中这些因素应该得到同等(如果不是更多)的关注
*   …从根本上说，令人惊讶的结果来自于自发的行为。这意味着它们可能并且确实来自于以不可预测的方式相互作用的组件。
*   …应该预料到非线性行为。一个小小的扰动就可能导致灾难性的大规模连锁故障。
*   …人的表现和可变性与原因没有内在联系。像“情景意识”和“机组资源管理”这样的术语是生硬的概念，可以掩盖为什么有人以他们对故障促成原因的方式行动是有意义的原因。
*   …系统中组件的多样性和复杂性可以 ***增强*** 系统的弹性，而不仅仅是带来漏洞。

对于真正的书呆子细节，Zahid H. Qureshi 的[对复杂社会技术系统的事故建模方法的回顾](https://www.researchgate.net/publication/228683461_A_review_of_accident_modelling_approaches_for_complex_socio-technical_systems)涵盖了当前对系统事故模型的思考的基础:Hollnagel 的 FRAM、Leveson 的 STAMP 和 Rassmussen 的框架都值得一读。

也适合进一步研究失败和学习:

Hollnagel 的演讲，[关于如何(不)从事故中吸取教训](http://www.uis.no/getfile.php/Konferanser/Presentasjoner/Ulykkesgransking%202010/EH_AcciLearn_short.pdf)

德克尔的精彩[理解人为错误的现场指南](http://www.amazon.com/Field-Guide-Understanding-Human-Error/dp/0754648265/)

因此，下次你读到或听到一个单一根本原因的报告时，你的头脑中应该会响起警报。同样，你不应该有根本原因“人为错误”，如果你只有一个根本原因，你还没有挖得足够深。🙂