# 再见 Mongo，你好 Postgres |信息|卫报

> 原文:[https://www . the guardian . com/info/2018/nov/30/bye-bye-mongo-hello-postgres？UTM _ source = Wanqu . co&UTM _ campaign = Wanqu+Daily&UTM _ medium = website](https://www.theguardian.com/info/2018/nov/30/bye-bye-mongo-hello-postgres?utm_source=wanqu.co&utm_campaign=Wanqu+Daily&utm_medium=website)

《卫报》的大部分内容——包括文章、实时博客、图库和视频内容——都是由我们的内部 CMS 工具 Composer 生成的。直到最近，它还由运行在 AWS 上的 Mongo DB 数据库支持。这个数据库实质上是《卫报》所有在线发布内容的“真相来源”——大约有 230 万条内容。我们刚刚完成了从 Mongo 到 Postgres SQL 的迁移。

Composer 及其数据库最初诞生于 Guardian Cloud，这是一个数据中心，位于我们办公室的地下室，靠近国王十字车站，并在伦敦的其他地方进行故障转移。2015 年 7 月一个炎热的日子，我们的故障转移程序经受了相当严峻的考验

<gu-island name="SignInGateSelector" props="{&quot;format&quot;:{&quot;display&quot;:0,&quot;theme&quot;:0,&quot;design&quot;:0},&quot;contentType&quot;:&quot;Article&quot;,&quot;sectionName&quot;:&quot;info&quot;,&quot;tags&quot;:[{&quot;id&quot;:&quot;info/series/engineering-blog&quot;,&quot;type&quot;:&quot;Series&quot;,&quot;title&quot;:&quot;Engineering blog&quot;},{&quot;id&quot;:&quot;info/info&quot;,&quot;type&quot;:&quot;Keyword&quot;,&quot;title&quot;:&quot;Information&quot;},{&quot;id&quot;:&quot;technology/technology&quot;,&quot;type&quot;:&quot;Keyword&quot;,&quot;title&quot;:&quot;Technology&quot;},{&quot;id&quot;:&quot;type/article&quot;,&quot;type&quot;:&quot;Type&quot;,&quot;title&quot;:&quot;Article&quot;},{&quot;id&quot;:&quot;profile/philip-mcmahon&quot;,&quot;type&quot;:&quot;Contributor&quot;,&quot;title&quot;:&quot;Philip McMahon&quot;,&quot;bylineImageUrl&quot;:&quot;https://i.guim.co.uk/img/static/sys-images/Guardian/Pix/pictures/2015/1/29/1422531426034/phil.jpg?width=300&amp;quality=85&amp;auto=format&amp;fit=max&amp;s=dc3d05bb70148999e58e102b8306d551&quot;},{&quot;id&quot;:&quot;profile/maria-livia-chiorean&quot;,&quot;type&quot;:&quot;Contributor&quot;,&quot;title&quot;:&quot;Maria-Livia Chiorean&quot;,&quot;twitterHandle&quot;:&quot;MariaLiviaCh&quot;},{&quot;id&quot;:&quot;profile/susie-coleman&quot;,&quot;type&quot;:&quot;Contributor&quot;,&quot;title&quot;:&quot;Susie Coleman&quot;},{&quot;id&quot;:&quot;profile/akash-askoolum&quot;,&quot;type&quot;:&quot;Contributor&quot;,&quot;title&quot;:&quot;Akash Askoolum&quot;,&quot;twitterHandle&quot;:&quot;akash1810&quot;}],&quot;isPaidContent&quot;:false,&quot;isPreview&quot;:false,&quot;host&quot;:&quot;https://www.theguardian.com&quot;,&quot;pageId&quot;:&quot;info/2018/nov/30/bye-bye-mongo-hello-postgres&quot;,&quot;idUrl&quot;:&quot;https://profile.theguardian.com&quot;}" clientonly="true"></gu-island>



Hot weather: good for fountain dancing, bad for data centres. Photograph: Sarah Lee/Guardian



此后,《卫报》向 AWS 的迁移变得更加紧迫。我们决定购买[ops manager](https://www.mongodb.com/products/ops-manager)——Mongo 的数据库管理软件——以及一份 Mongo 支持合同——来帮助进行云迁移。我们使用 OpsManager 来管理备份、处理流程编排并为我们的数据库集群提供监控。

由于编辑需求，我们需要在 AWS 中自己的基础设施上运行数据库集群和 OpsManager，而不是使用 Mongo 的托管数据库产品。这不是小事，因为 Mongo 没有提供任何工具来轻松地在 AWS 上进行设置——我们需要手写 cloudformation 来定义所有的基础设施，在此之上[我们编写了数百行 ruby 脚本](https://github.com/guardian/machine-images/tree/master/packer/resources/features/mongo24)来处理监控/自动化代理的安装和新 DB 实例的编排。我们最终不得不在团队中运行关于数据库管理的知识共享会议——这是我们希望 OpsManager 能够简化的事情。

<gu-island name="GuideAtomWrapper" deferuntil="visible" props="{&quot;id&quot;:&quot;cfee56d3-053e-46e7-9d03-ec0704b3d476&quot;,&quot;title&quot;:&quot;How do I join The Guardian Product &amp; Engineering?&quot;,&quot;html&quot;:&quot;<p><details data-atom-id="cfee56d3-053e-46e7-9d03-ec0704b3d476" data-snippet-type="guide" class="dcr-nglds4"><summary>Quick Guide

#### 我如何加入卫报产品与工程？

Show</summary>

我在哪里可以找到空缺职位？

在此申请我们的空缺职位[。](https://workforus.theguardian.com/index.php/careers/product-engineering/)

我能从面试过程中得到什么？

我们的目标是在招聘过程中尽可能做到公平和透明。与其他组织类似，有简历筛选、电话面试、编码练习和面对面面试。点击此处阅读更多关于期待和申请的信息[。](https://www.theguardian.com/info/2019/apr/26/applying-to-the-guardians-digital-department)

-</details><strong>Where can I find open positions?</strong></p><p>Apply for one of our open positions <a href=\&quot;https://workforus.theguardian.com/index.php/careers/product-engineering/\&quot;>here</a>.</p><p><strong>What can I expect from the interview process?</strong></p><p>We aim to be as fair and transparent as possible in our hiring process. Similar to other organisations, there is a CV screening, phone interview, coding exercise and a face to face interview. Read more about what to expect and apply now <a href=\&quot;https://www.theguardian.com/info/2019/apr/26/applying-to-the-guardians-digital-department\&quot;>here</a>.</p><p>-</p>&quot;,&quot;credit&quot;:&quot;&quot;,&quot;pillar&quot;:0}"></gu-island> 

自从迁移到 AWS 以来，我们已经因为数据库问题经历了两次严重的停机，每次都导致《theguardian.com》杂志无法发表文章至少一个小时。在这两种情况下，OpsManager 和 Mongo 的支持代理都无法帮助我们，我们最终自己解决了问题——有一次多亏了团队的一名[成员从阿布扎比郊区的一个沙漠中拿起了电话。每一个问题都有理由在自己的博客上发表一篇完整的文章，但总的要点是:](https://github.com/sihil)

*   时钟很重要——不要把 VPC 锁得太紧，以免 NTP 停止工作。

*   在应用程序启动时自动生成数据库索引可能不是一个好主意。

*   数据库管理既重要又困难——我们不希望自己去做。



When clocks get out of sync, networking becomes a nightmare. Photograph: Alamy Stock Photo



OpsManager 并没有真正兑现其无忧数据库管理的承诺。例如，实际管理 OpsManager 本身——特别是从 OpsManager 1 升级到 OpsManager 2——非常耗时，并且需要关于 ops manager 设置的专业知识。由于不同版本的 Mongo DB 之间身份验证模式的变化，它也没有兑现“一键升级”的承诺。我们一年至少损失了两个月的工程时间来做这项数据库管理工作。

所有这些问题，再加上我们为支持合同和 OpsManager 支付的高额年费，迫使我们寻找一种具有以下要求的替代数据库选项:

*   需要最少的数据库管理。

*   支持静态加密。

*   一条可行的从 Mongo 迁移的路径。

由于我们所有的其他服务都在 AWS 上运行，显而易见的选择是 dynamo db——亚马逊的 NoSQL 数据库产品。不幸的是，当时 Dynamo 不支持静态加密。在等了大约九个月来添加这个功能之后，我们最终放弃了并寻找其他东西，最终选择在 AWS RDS 上使用 Postgres。

"但是 postgres 不是一个文档商店！"我听到你哭泣。不，它不是，但是它有一个 JSONB 列类型，支持 JSON blob 中的字段索引。我们希望通过使用 JSONB 类型，我们可以从 Mongo 迁移到 Postgres，只需对我们的数据模型做最小的改动。此外，如果我们想在未来转移到一个更加关系化的模型，我们有这个选项。Postgres 的另一个优点是它的成熟程度:我们想问的每个问题在大多数情况下都已经在堆栈溢出中得到了回答。

从性能角度来看，我们相信 Postgres 可以应付——而 Composer 是一个写负载很重的工具(每当记者停止输入时，它就会写入数据库)—通常只有几百个并发用户——不完全是高性能计算！

 ## 第二部分—二十年的内容迁移，没有宕机 



Postgres takes a bite out of mongo. Photograph: Bernd Thissen/AFP/Getty Images



 ## 计划 

大多数数据库迁移都涉及相同的步骤，我们的也不例外。以下是我们迁移数据库的步骤:

*   创建新数据库。

*   创建写入新数据库的方法(新 API)。

*   创建一个代理，使用旧数据库作为主数据库，向旧数据库和新数据库发送流量。

*   将记录从旧数据库迁移到新数据库。

*   将新数据库作为主数据库。

*   删除旧数据库。

考虑到我们正在迁移的数据库为我们的 CMS 提供支持，迁移对我们的记者造成尽可能小的干扰是很重要的。毕竟新闻从来没有停止过。

 ## 新 API 

2017 年 7 月底，新的 Postgres 支持的 API 开始工作。于是我们的旅程开始了。但是为了理解这个旅程，我们需要首先理解我们从哪里开始。

我们简化的 CMS 架构是这样的:一个数据库、一个 API 和几个与之对话的应用程序(比如 web 前端)。这个堆栈过去是，现在仍然是，使用 [Scala](https://www.scala-lang.org/) 、 [Scalatra 框架](http://scalatra.org/)和 [Angular.js](https://angularjs.org/) 构建的，它已经有四年的历史了。

经过一些调查后，我们得出结论，在我们可以迁移现有内容之前，我们需要一种方法来与新的 PostgreSQL 数据库对话，并且仍然让旧的 API 照常运行。毕竟，蒙哥数据库是我们的真理之源。在试验新的 API 时，它为我们提供了一张安全毯。

这就是为什么在旧的 API 之上构建不是一个选项的原因之一。在最初的 API 和 MongoDB 细节中几乎没有关注点的分离，甚至可以在控制器级别找到。因此，在现有 API 中添加另一种数据库类型的任务风险太大。

我们选择了不同的路线，复制了旧的 API。APIV2 就是这样诞生的。它或多或少是 Mongo one 的精确复制品，包括相同的端点和功能。我们使用了 [doobie](https://tpolecat.github.io/doobie/) ，Scala 的纯功能 JDBC 层，添加了 [Docker](https://www.docker.com/) 用于本地运行和测试，并改进了日志记录和关注点分离。APIV2 将会是一个快速而现代的 API。

到 2017 年 8 月底，我们部署了一个新的 API，使用 PostgreSQL 作为其数据库。但这仅仅是开始。Mongo 数据库中有一些文章是二十多年前首次创建的，所有这些都需要转移到 Postgres 数据库中。



Migrating to postgres for the winter. Photograph: Anna-Maria Fjellström



 ## 移民 

我们需要能够编辑网站上的任何文章，不管它们是什么时候发表的，所以所有的文章都作为单一的“真实来源”存在于我们的数据库中。

尽管所有的文章都存在于《卫报》的内容 API (CAPI)中，这为应用程序和网站提供了动力，但正确的迁移是关键，因为我们的数据库是“事实的来源”。如果 CAPI 的弹性搜索集群发生了什么事，那么我们会从 Composer 的数据库中重新索引它。

因此，在关闭 Mongo 之前，我们必须确信 Postgres 支持的 API 和 Mongo 支持的 API 上的相同请求将返回相同的响应。

为此，我们需要将所有内容复制到新的 Postgres 数据库中。这是使用一个直接与新旧 API 对话的脚本完成的。这样做的好处是，API 已经提供了一个经过良好测试的接口，可以在数据库中读写文章，而不是编写直接访问相关数据库的东西。

迁移的基本流程是:

*   从 Mongo 获取内容。

*   向 Postgres 发布内容。

*   从 Postgres 获取内容。

*   检查第一个和第三个的回答是否相同

只有当您的最终用户完全不知道数据库迁移已经发生，并且一个好的迁移脚本始终是这一过程中必不可少的一部分时，数据库迁移才会真正顺利进行。

考虑到这一点，我们需要一个能够:

*   发出 HTTP 请求。

*   确保在迁移一段内容后，来自两个 API 的响应匹配。

*   如果有错误就停止。

*   生成详细的日志来帮助诊断问题。

*   出错后从正确的点重新开始。

我们开始使用菊石。菊石允许你用 Scala 写脚本，这是我们团队的主要语言。这是一个很好的机会来试验一些我们以前没有用过的东西，看看它是否对我们有用。虽然菊石允许我们使用熟悉的语言，但也有不利的一面。虽然 Intellij 现在[支持菊石](https://blog.jetbrains.com/scala/2017/11/28/intellij-idea-scala-plugin-2017-3-lightbend-project-starter-ammonite-support-parallel-indexing-and-more/)，但当时它不支持，这意味着我们失去了自动完成和自动导入功能。也不可能长时间运行菊石脚本。

最终，菊石并不是这项工作的合适工具，我们使用了一个 sbt 项目来执行迁移。我们采用的方法允许我们使用我们有信心的语言工作，并执行多次“测试迁移”,直到我们有信心在生产中运行它。

出乎意料的是，这在测试 Postgres API 时会非常有用。我们在新的 API 中发现了几个以前没有发现的细微错误和边缘情况。

时间快进到 2018 年 1 月，是时候在我们的预生产环境中测试代码的完整迁移了。

与我们的大多数系统相似，代码和产品之间唯一的相似之处是它们运行的应用程序的版本。支持代码环境的 AWS 基础设施远不如 PROD 强大，这仅仅是因为它的使用率低得多。

运行代码迁移将有助于我们:

*   估计生产上的迁移需要多长时间。

*   评估迁移对性能的影响(如果有)。

为了准确测量这些指标，我们必须匹配这两种环境。这包括将 PROD mongo 数据库的备份恢复成代码，并更新 AWS 支持的基础设施。

迁移超过 200 万条内容需要很长时间，肯定超过办公时间。所以我们连夜在屏幕上运行了这个脚本。

为了测量迁移的进度，我们将结构化日志(使用标记)发送到 ELK 堆栈。从这里，我们可以创建详细的仪表板，跟踪成功迁移的文章数量、失败的数量和整体进度。此外，这些都显示在团队附近的大屏幕上，以提供更大的可视性。



Dashboard showing progress of the migration Photograph: Editorial Tools/Guardian



迁移完成后，我们使用相同的技术检查 Postgres 中的每个文档是否与 Mongo 匹配。

 ## 第三部分-代理和生产中的运行 



Mongo to Postgres migration: the proxy. Photograph: Maria Livia Chiorean



 ## 代理人 

既然新的 Postgres 支持的 API 已经运行，我们需要用现实生活中的流量和数据访问模式来测试它，以确保它是可靠和稳定的。有两种可能的方法可以实现这一点:更新每个与 Mongo API 对话的客户机，使其与两个 API 都对话；或者运行一个代理来做这件事。我们使用 [Akka 流](https://doc.akka.io/docs/akka/2.5/stream/index.html)在 Scala 中编写了一个代理。

该代理的操作相当简单:

*   接受来自负载平衡器的流量。

*   将流量转发到主 api 并返回。

*   将相同的流量异步转发到辅助 api。

*   计算两个响应之间的任何差异并记录下来。

开始时，代理记录了两个 API 的响应之间的许多差异，暴露了 API 中一些非常微妙但重要的行为差异，需要进行修复。

 ## 结构化日志记录 

我们在卫报做日志记录的方法是使用一个 [ELK](https://www.elastic.co/elk-stack) 栈。使用 Kibana 给了我们灵活性，以一种对我们最有用的方式显示日志。Kibana 使用非常容易学习的 [lucene 查询语法](https://www.elastic.co/guide/en/elasticsearch/reference/6.x/query-dsl-query-string-query.html#query-string-syntax)。但是我们很快意识到，在当前的设置下，过滤掉日志或者将它们分组是不可能的。例如，我们无法过滤掉由于 GET 请求而发送的日志。

我们的解决方案是向 Kibana 发送更多的结构化日志，而不是只发送一条消息。一个日志条目包含多个字段，如时间戳、发送日志或堆栈的应用程序的名称。以编程方式添加新字段非常容易。这些结构化字段被称为标记，它们可以使用 [logstash-logback-encoder](https://github.com/logstash/logstash-logback-encoder) 库来实现。对于每个请求，我们提取有用的信息(例如路径、方法、状态代码),并用我们需要记录的附加信息创建一个映射。看看下面的例子。

```
 import akka . http . Scala DSL . model . http request import ch . QoS . logback . classic . { Logger = > logback Logger } import net . log stash . logback . marker . markers import org . slf4j . { Logger factory，Logger = > SLFLogger } import Scala . collection . Java converters . _ object Logging { val root Logger:logback Logger = Logger factory . get Logger(SLFLogger。ROOT_LOGGER_NAME)。asInstanceOf[LogbackLogger]private def set markers(request:http request)= { val markers = Map(" path "-> request . uri . path . tostring()，" method "-> request . method . value)markers . appendentries(markers . as Java)} def infoWithMarkers(message:String，akkaRequest:http request)= root logger . info(set markers(akkaRequest)，message) } 
```

日志中的额外结构允许我们构建有用的仪表板，并围绕我们的差异添加更多的上下文，这有助于我们识别 API 之间的一些较小的不一致。

 ## 复制流量和代理重构 

将内容迁移到代码数据库后，我们最终得到了一个几乎完全相同的 PROD 数据库副本。主要的区别是代码没有流量。为了将真实的流量复制到代码环境中，我们使用了一个名为 [GoReplay](https://goreplay.org/) (gor)的开源工具。它非常容易设置，并且可以根据您的需求进行定制。

由于所有进入我们 API 的流量都首先到达代理服务器，所以在代理服务器上安装 gor 是有意义的。参见下面如何在您的机器上下载 gor，以及如何开始捕获端口 80 上的流量并将其发送到另一台服务器。

```
 wget https://github . com/buger/gore play/releases/download/v 0 . 16 . 0 . 2/gor _ 0 . 16 . 0 _ x64 . tar . gz tar-xzf gor _ 0 . 16 . 0 _ x64 . tar . gz gor sudo gor-input-raw:80-output-http http://apiv2.code.co.uk 
```

在一段时间内，一切都运行良好，但是很快我们就经历了一次生产中断，代理在几分钟内变得不可用。经过调查，我们发现代理运行的所有三个机器同时循环。我们怀疑 gor 使用了太多的资源，导致代理崩溃。在进一步的调查中，我们在 AWS 控制台中发现，这些盒子一直在有规律地循环，但不是在同一时间。

在进一步深入之前，我们试图找到一种仍然运行 gor 的方法，但这一次不要给代理增加任何压力。该解决方案来自我们的 Composer 二级堆栈。该堆栈仅在紧急情况下使用，它让我们的[生产监控工具](https://www.theguardian.com/info/developer-blog/2016/dec/05/testing-in-production-how-we-combined-tests-with-monitoring)不断对其进行测试。这一次，以两倍的速度从这个堆栈向代码重放流量没有出现任何问题。

新的发现提出了许多问题。代理的设计理念是它只会暂时存在，所以它可能没有像其他应用程序那样精心设计。此外，它是使用 Akka Http 构建的，团队成员之前都没有使用过。代码很乱，充满了快速修复。我们决定开始一项大的重构工作来提高可读性，包括使用 for comprehensions 来代替我们以前使用的越来越多的嵌套逻辑，并添加更多的日志标记。

我们希望通过花时间了解一切是如何工作的，并通过简化逻辑，我们将能够阻止盒子循环。但这并没有奏效。在努力使代理更加可靠的大约两个星期后，我们开始感觉自己像掉进了一个越来越深的兔子洞。必须做出决定。我们同意冒这个险，因为把时间花在实际的迁移上比试图修复一个一个月后就要消失的软件要好。我们为这个决定付出了代价，经历了两次以上的生产中断，每次持续大约两分钟，但总的来说这是正确的做法。

时间快进到 2018 年 3 月，我们现在已经完成了代码迁移，对 CMS 中的 API 性能或用户体验没有任何不利影响。我们现在可以开始考虑在代码中解除代理。

第一步是改变 API 的优先级，以便代理首先与 Postgres 对话。如前所述，这是基于配置的。然而，有一个复杂性。

当文档被更新时，Composer 在 Kinesis 流上发送消息。为了避免消息重复，应该只有一个 API 发送这些消息。API 在配置中为此提供了一个标志；对于 Mongo 支持的 API，该值为 true 对于 Postgres 支持的 API，该值为 false。简单地改变代理先与 Postgres 对话是不够的，因为消息不会在 Kinesis 流上发送，直到请求也到达 Mongo。这太晚了。

为了解决这个问题，我们创建了 HTTP 端点来即时更改负载平衡器中所有实例的内存配置。这使我们能够非常快速地切换哪个 API 是主要的，而不需要编辑配置文件和重新部署。此外，这可以编写脚本，减少人工干预和错误。

现在，所有的请求都首先被发送到 Postgres，API2 正在与 Kinesis 进行对话，通过配置和重新部署，这一更改将成为永久性的。

下一步是完全移除代理，让客户端单独与 Postgres API 对话。由于有许多客户端，单独更新每个客户端实际上是不可行的。因此，我们把这个推给了 DNS。也就是说，我们在 DNS 中创建了一个 CNAME，它起初指向代理的 ELB，然后将改为指向 API ELB。这允许进行单个更改，而不是更新 API 的每个单独的客户端。

现在是迁移产品的时候了。虽然有点可怕，因为，嗯，这是生产。该过程相对简单，因为一切都基于配置。此外，当我们向日志中添加一个阶段标记时，还可以通过更新 Kibana 过滤器来改变之前构建的仪表板的用途。

 ## 关闭代理和 MongoDB 

十个月和 240 万篇迁移文章之后，我们终于能够关闭所有与 Mongo 相关的基础设施了。但首先，我们期待已久的时刻到了:杀死代理人。



Logs showing the scaling down of the Flexible API Proxy. Photograph: Editorial Tools/Guardian



这个小软件给我们带来了这么多问题，我们迫不及待地想关掉它！我们需要做的只是更新 CNAME 记录，使其直接指向 APIV2 负载平衡器。

团队聚集在一台电脑周围。开关就在一键之外。没有人再呼吸了。完全沉默。咔嚓！零钱已经用完了。什么都没坏！我们都放松了。

出乎意料的是，删除旧的 MongoDB API 是另一个挑战。在疯狂地删除旧代码的同时，我们发现我们的集成测试从未被改变以使用新的 API。一切迅速变红。幸运的是，大多数问题都与配置有关，因此很容易修复。但是测试发现了 PostgreSQL 查询中的一些问题。试着想想我们可以做些什么来避免这种错误，我们意识到当开始一项大的工作时，你也必须接受你会犯错误。

之后的一切都很顺利。我们从 OpsManager 中分离出所有的 Mongo 实例，然后终止它们。唯一能做的就是庆祝。好好睡一觉。