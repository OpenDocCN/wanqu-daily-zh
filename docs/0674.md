# 使用服务来打破巨石

> 原文：<https://engineeringblog.yelp.com/2015/03/using-services-to-break-down-monoliths.html?utm_source=wanqu.co&utm_campaign=Wanqu+Daily&utm_medium=website>

## 介绍

在 Yelp，我们重视快速发布代码的能力。我们不断地将变化推向生产，我们甚至鼓励我们的实习生在第一天就发布代码。即使工程团队已经发展到超过 300 人，我们的代码库已经达到几百万行 Python 代码，我们还是设法保持了这个速度(另外还有 Java 的帮助)。

保持迭代速度的一个关键因素是我们转向了服务

面向架构。最初，我们的大部分开发工作都发生在一个单一的、整体的 web 应用程序中，这个应用程序被创造性地命名为“yelp-main”。随着公司的发展，我们的开发人员花费越来越多的时间试图在 yelp-main 中发布代码。在认识到这个痛点之后，我们开始尝试一种面向服务的架构来扩展开发过程，到目前为止，它取得了巨大的成功。在过去三年的过程中，我们已经从编写第一个服务发展到拥有超过 70 个产品服务。

我们在 Yelp 上写的是什么样的服务？举个例子，假设你想[点一份墨西哥卷饼](http://www.yelp.com/search?find_desc=burrito&find_loc=San+Francisco%2C+CA&ns=1&attrs=PlatformDelivery&ytp_st=pickup)外卖。首先，当你输入你要找的东西时，你可能会使用我们的自动完成服务。然后，当你点击“搜索”时，你的查询会找到六个后端服务，我们会努力让[理解](http://engineeringblog.yelp.com/2015/02/reading-between-the-lines-how-we-make-sense-of-users-searches.html)你的查询，为你选择最好的商家。一旦你找到了你理想的 taqueria，并从菜单中做出选择，你的订单细节将点击许多服务来处理支付，与合作伙伴沟通等。

yelp-main 怎么样？这里有大量的代码，而且绝对不会很快消失(如果有的话)。然而，我们确实看到 yelp-main 越来越成为一个前端应用程序，负责从我们越来越多的后端服务中聚合和呈现数据。我们也在积极尝试创建前端服务，以便我们可以进一步模块化 yelp-main 开发流程。

这篇博文的其余部分大致分为两类:一般开发实践和基础设施。对于前者，我们讨论如何帮助开发人员编写健壮的服务，然后详细介绍我们如何解决设计良好的界面和测试服务的问题。然后，我们将焦点转移到我们的基础架构，并讨论我们为服务堆栈选择的特定技术。接下来是关于数据存储和服务发现的讨论。我们以未来发展方向的细节作为结论。

## 教育

面向服务的架构迫使开发人员面对分布式系统的[现实](http://en.wikipedia.org/wiki/Fallacies_of_distributed_computing),比如部分失败(哎呀，你刚才提到的那个服务崩溃了)和分布式所有权(在所有其他团队更新他们的代码开始使用你喜欢的 REST 接口的 v2 之前，需要几个星期)。当然，在开发一个单一的 web 应用程序时，所有这些挑战仍然存在，只是程度较轻。

我们努力通过基础设施来缓解这些问题(稍后将详细介绍！)，但是我们发现没有什么可以替代帮助开发人员真正理解他们正在构建的系统的现实。我们采取的一种方法是每周举行一次“服务办公时间”，任何开发人员都可以自由进入并询问有关服务的问题。这些问题涵盖了所有领域，从性能(“缓存这些数据的最佳方式是什么？”)到架构(“我们已经意识到，我们应该真正地将这两个独立的服务实现为一个单一的服务——将它们结合起来的最佳方式是什么？”).

我们还创建了一套用于编写和维护服务的基本原则。这些原则包括架构指南，例如如何确定某个特性是否更适合库，或者某项服务的开销是否合理。它们还包含一组操作指南，以便服务作者知道一旦他们的服务在生产中启动并运行，他们可以期待什么。我们发现，在代码审查或设计讨论期间，以及在开发人员入职期间，参考这些原则通常是有用的。

最后，我们认识到我们有时会犯错误，对我们的客户或其他开发人员造成负面影响。在这种情况下，我们写下[事后分析](https://codeascraft.com/2012/05/22/blameless-postmortems/)来帮助工程团队从这些错误中吸取教训。我们努力消除事后检查过程中的任何指责，这样工程师就不会对参与过程感到气馁。

## 接口

大多数服务公开 HTTP 接口，并使用 JSON 传递任何结构化数据。许多服务作者还提供了一个 Python 客户端库，它封装了原始 HTTP 接口，以便其他团队更容易使用他们的服务。

在我们选择使用 HTTP 和 JSON 时，肯定会有一些权衡。在 HTTP 上标准化的一个巨大好处是有很好的工具来帮助调试、缓存和负载平衡。一个更大的缺点是没有独立于实现定义服务接口的标准解决方案(与 Thrift 等技术相反)。这使得精确地指定和检查接口变得困难，这可能导致令人讨厌的错误(“我以为您的服务返回了‘用户名’字段？”).

我们已经通过使用 [Swagger](http://swagger.io/) 解决了这个问题。Swagger 建立在 [JSON 模式标准](http://json-schema.org/)的基础上，提供了一种记录 HTTP/JSON 服务接口的语言。我们发现，在不改变任何接口的情况下，将 Swagger 规范改进到我们的大多数服务中是可能的。给定一个服务的 Swagger 规范，我们使用 [swagger-py](https://github.com/Yelp/swagger-py) 为该服务自动创建一个 Python 客户端。我们还使用 [Swagger UI](https://github.com/swagger-api/swagger-ui) 来提供所有服务接口的集中目录。这使得整个工程团队的开发人员能够轻松地发现哪些服务是可用的，并有助于防止重复工作。

## 测试

在服务中测试*是相当标准的。我们用模拟替换任何外部服务调用，并对调用进行断言。当我们希望执行跨服务的测试时，复杂性就出现了。这是面向服务的架构带来额外成本的领域之一。我们在这方面的第一次尝试包括维护服务的规范“测试”实例。这种方法会导致有状态服务测试污染、由于远程服务调用而导致的一般问题以及开发人员维护负担的增加。*

为了应对这个问题，我们现在使用 [Docker 容器](https://www.docker.com/)来构建服务的私有测试实例(包括数据库)。这里的关键思想是服务作者负责发布他们服务的 Docker 图像。然后，其他服务作者可以将这些图像作为依赖项拉进来，对他们的服务进行验收测试。

## 服务堆栈

我们的大部分服务都是建立在 Python 服务栈之上的，这个服务栈是由几个不同的开源组件组装而成的。我们使用[金字塔](http://www.pylonsproject.org/)作为我们的 web 框架，使用 [SQLAlchemy](http://www.sqlalchemy.org/) 作为我们的数据库访问层，一切都在 [uWSGI](https://uwsgi-docs.readthedocs.org/en/latest/) 之上运行。我们发现这些组件是稳定的、有据可查的，并且几乎拥有我们需要的所有特性。我们还成功地使用 [gevent](http://www.gevent.org/) 在需要的地方从 Python 服务中获得了额外的性能。我们的 [Elasticsearch 代理](http://engineeringblog.yelp.com/2014/11/scaling-elasticsearch-to-hundreds-of-developers.html)使用这种方法扩展到每个工作进程每秒数千个请求。

我们使用金字塔[补间](http://docs.pylonsproject.org/docs/pyramid/en/latest/narr/hooks.html#registering-tweens)来挂钩请求生命周期，以便我们可以记录查询和响应数据，用于监控和历史分析。每个服务实例还运行 [uwsgi_metrics](https://github.com/Yelp/uwsgi_metrics) 来捕获和本地聚合性能指标。然后，这些指标在标准的 HTTP 端点上发布，以供我们基于 Graphite 的指标系统接收。

另一个主题是服务如何访问第三方库。最初，我们使用系统安装包，这些包在所有服务实例之间共享。然而，我们很快发现推广核心包的升级几乎是不可能的任务，因为大量的服务可能会受到影响。为了应对这种情况，所有 Python 服务现在都运行在 [virtualenvs](https://virtualenv.pypa.io/en/latest/) 中，并从私有 PyPI 服务器获取它们的依赖项。我们的 PyPI 服务器既托管我们所依赖的开源库，也托管我们内部发布的库(使用 Jenkins 连续部署管道构建)。

最后，需要注意的是，我们的底层基础设施与编写服务的语言无关。搜索团队利用这种灵活性，用 Java 编写了几个性能更关键的服务。

## 数据存储

我们的服务中有很大一部分需要持久化数据。在这种情况下，我们试图让服务作者能够灵活地选择最符合其需求的数据存储。例如，一些服务使用 MySQL 数据库，而另一些则使用 Cassandra 或 ElasticSearch。我们还有一些利用预先计算的只读数据文件的服务。不管选择什么样的数据存储，我们都尽量将实现细节保密给拥有它的服务。这为服务作者提供了更改底层数据表示甚至数据存储的长期灵活性。

我们大部分核心数据的规范版本，比如企业、用户和评论，仍然保存在 yelp-main 数据库中。我们发现将这种高度相关的数据提取到服务中很困难，我们仍在寻找正确的方法。那么服务如何访问这些数据呢？除了公开熟悉的 web 前端，yelp-main 还提供了一个内部 API，供我们数据中心的后端服务使用。这个 API 是使用 Swagger 规范定义的，在大多数情况下，它可以被看作是另一个服务接口。

## 发现

面向服务架构中的一个核心问题是发现其他服务实例的位置。我们最初的方法是在每个数据中心手动配置一对集中的 [HAProxy](http://www.haproxy.org/) 负载平衡器，并将这些负载平衡器的虚拟 IP 地址嵌入到配置文件中。我们很快发现这种方法无法扩展。部署新服务和在机器之间移动现有服务都是劳动密集型的，而且容易出错。我们也开始看到由于负载平衡器过载而导致的性能问题。

我们通过切换到围绕 [SmartStack](http://nerds.airbnb.com/smartstack-service-discovery-cloud/) 构建的服务发现系统来解决这些问题。简而言之，每个客户端主机现在运行一个绑定到本地主机的 HAProxy 实例。负载均衡器是根据存储在 [ZooKeeper](http://zookeeper.apache.org/) 中的服务注册信息动态配置的。然后，客户端可以通过连接到其本地主机负载平衡器来联系服务，负载平衡器随后会将请求代理到健康的服务实例。事实证明，该设施高度可靠，我们的大部分生产服务现在都在使用它。

## 未来方向

我们目前正在开发名为 [Paasta](https://vimeo.com/121183491#t=9m51s) 的下一代服务平台。它使用[马拉松](http://mesosphere.github.io/marathon/)框架(运行在 [Apache Mesos](http://mesos.apache.org/) 之上)在机器集群之间分配容器化的服务实例，并与 SmartStack 集成用于服务发现。这个平台将允许我们把我们的服务器当作一个更可替代的资源，把我们从静态地分配服务给主机的问题中解放出来。我们将在今年晚些时候公布关于这个项目的更多细节。

## 承认

这篇博文中描述的工作已经由 Yelp 工程团队的众多成员完成并提供支持。特别值得一提的是 Prateek Agarwal，Ben Chess，Sam Eaton，Julian Krause，Reed Lipman，Joey Lynch，Daniel Nephin 和 Semir Patel。

[回到博客](/)