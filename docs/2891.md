# 一个数学 BS 探测器可以提升群体的智慧

> 原文:[https://aeon . co/essays/a-mathematical-bs-detector-can-boost-the-wisdom-of-crowds？UTM _ source = Wanqu . co&UTM _ campaign = Wanqu+Daily&UTM _ medium = website](https://aeon.co/essays/a-mathematical-bs-detector-can-boost-the-wisdom-of-crowds?utm_source=wanqu.co&utm_campaign=Wanqu+Daily&utm_medium=website)

几周前，我想展示一下群体的智慧。我参加了一个犹太成年礼招待会，作为一个游戏，主持人让每张桌子猜一个大特百惠碗里的彩虹糖的数量。我让我们桌子上的每个人写下一个猜测，然后平均结果。基于社会科学家所说的，我们的集体答案应该是正确的。我们每个人都有一个模糊的直觉，知道如何把小物件装进大盒子里，这有很大的不确定性。然而，总的来说，当个人的错误被抵消时，我们的知识碎片应该积累起来。但是我的实验彻底失败了。我们的估计误差了两倍。另一桌赢得了炫酷的闪烁项链。

群体智慧是一个古老的概念。这可以追溯到古希腊，以及后来的启蒙思想家，他们认为民主不仅是一个好主意，而且是一种经过数学证明的做出好决策的方式。根据这一观点，即使是一群无赖也比最精明的君主表现更好。无赖们在个人知识上的不足，可以通过多样性来弥补。20 世纪 90 年代，群体智慧成为流行文化的困扰，为维基、众包、预测市场和基于流行度的搜索算法提供了理论基础。

然而，这种认可伴随着一个很大的警告:即使是支持者也承认，群众既有智慧也有愚蠢。雅典的好民主主义者与斯巴达进行了毁灭性的战争。法国革命暴徒扼杀了启蒙运动。在 2008 年之前的几年里，华尔街的羊群忘记了最基本的风险管理原则。然后是我的小彩虹糖比赛。这正是群体应该擅长解决的问题类型:各种独立评估的安静汇集，没有任何个人可能主导的小组讨论。然而，我的团队失败了。

麻省理工学院(MIT)的行为经济学家 Draž en Prelec 正在研究一种让蜂群思维变聪明的方法。他指出，人群混乱的一个原因是常识的霸权。即使当人们做出独立的判断时，他们可能也是基于同样的信息。当你平均每个人的判断时，所有人都知道的信息被重复计算，每个人一次，这赋予了它更多的意义，淹没了不同的知识来源。最终，最小公分母占主导地位。这在社交场合是一个常见的祸害:想想晚餐对话，人们互相重复他们在《纽约时报》上读到的内容。

在许多科学争论中，一致的观点也是建立在一个比看起来要薄弱得多的知识基础上。例如，在 20 世纪 20 年代和 30 年代，物理学家就如何解释量子力学进行了激烈的辩论，此后的几十年里，教科书将这场争论记录为阿尔伯特·爱因斯坦(Albert Einstein)和其他所有人之间的一边倒的战斗，他独自一人对新理论进行了后卫战。事实上，“其他所有人”都在重复尼尔斯·玻尔和沃纳·海森堡的观点，而爱因斯坦得到了埃尔温·薛定谔的支持。看似一对多，实际上是二对二。直到 20 世纪 60 年代，鲜有新知识进入讨论。即使在今天，玻尔和海森堡的观点(所谓的哥本哈根解释)仍被认为是标准的观点，一种它从未应得的特权地位。

Prelec 的出发点是，一些人的判断应该比其他人的判断更重要。通过不再平均每个人的判断，你可以避免过多计算多余的或无关的信息。你已经一直这样做了，每当你相信那些自信地表达的意见，而拒绝那些听起来缺乏自信的意见。这种信任是有道理的。在心理学实验中，在一项任务中更准确的人——比如说，记住一系列单词——往往表现出更大的自信。不幸的是，反过来就不对了:自信的人不一定更准确。正如 W B .叶芝所写的:“最优秀的人缺乏信念，而最差的人却充满激情。”此外，人们系统地高估了他们知识的价值。一条经验法则是，100%的信心意味着你在 70%到 85%的时间里是正确的。我们需要的是一种更好的方法来衡量一个人的知识价值，然后再把它放入群体智慧的混合体中。

Prelec 建议，解决方法不是通过信心而是通过 T2 元知识来衡量答案:关于知识的知识。元知识意味着你意识到自己知道什么或不知道什么，以及你的知识水平相对于其他人的水平。这是衡量你对大众价值的一个有用的标准，因为知识和元知识通常是相辅相成的。纽约城市大学研究生中心(City University of New York Graduate Center)研究社会认知的研究生亚伦·本特利(Aaron Bentley)说:“专业技能不仅意味着对某个主题的知识，还意味着对这个主题的知识是如何产生的。”。

尽管你可能没有独立的方法来验证人们的知识，但你可以确认他们的元知识。在一篇即将发表的论文中，Prelec、他的研究生 John McCoy 和普林斯顿大学的神经科学家 Sebastian Seung 详细说明了这一过程。当你进行调查时，问人们两个数字:他们自己对答案的最佳猜测(“回答”)，以及他们对有多少人会同意他们观点的评估(“预测”)。回答代表他们的知识，预测代表他们的元知识。收集每个人的回答后，您可以将他们的元知识预测与小组的平均知识进行比较。这提供了一个具体的衡量标准:提供最准确预测的人——表现出最强的自我意识和对他人最准确的感知的人——是值得信任的人。

元知识就像一个强大的废话检测器。它可以将真正知道一些事情的人群成员与胡乱猜测或只是鹦鹉学舌的人区分开来。Prelec 说，大众社区在试图从大众身上获取什么方面不够雄心勃勃。人群*是*明智的，但不是以纠错直觉假设的方式。那里有更多的信息。扯淡检测器并不完美，但是当你自己都不知道答案，不得不依靠别人的意见时，这是你能做的最好的了。你相信哪个目击者？电视上哪个会说话的脑袋？哪位科学家在评论一些有争议的话题？如果他们表现出卓越的元知识，你可以把这看作是他们卓越知识的标志。

元知识可以通过三种不同的方式提高群体智慧。首先，它对调查数据提供了强大的一致性检查。社会学家长期以来依赖于这种方法的一个版本，不仅询问人们他们知道什么，还询问他们认为其他人知道什么。通过这样做，研究人员可以衡量人们不会承认的信仰和活动的流行程度，甚至对他们自己也不会承认。每当人们说某项活动很平常，但声称他们从来没有——从来没有——这是很可疑的！–自己动手。例如，如果人们否认喜欢巴瑞·马尼洛，但说他们的同龄人会对他表现出极大的热情，你可以得出结论，马尼洛比人们表现出来的更受欢迎。同样，你应该提防那些抱怨腐败猖獗的政客；他们抗议得太多了。真正无辜的人倾向于把别人往好的方面想。

这种策略之所以有效，是因为我们的元知识是倾斜的。当我们被要求预测其他人的反应时，我们的预测很大程度上基于我们自己的反应，从而泄露了如果我们被直接要求时我们可能会隐藏的信息。人们倾向于假设其他人和他们想的一样，这是一种基本的心理偏见，被称为虚假共识效应。作为一项测试，今年春天，我和加州大学圣克鲁斯分校的物理学家安东尼·阿吉雷对变星预测市场做了一个实验。我们问人们他们认为伯尼·桑德斯成为民主党总统候选人的可能性有多大；与此同时，我们还征求了他们对其他受访者会说些什么的预测。当我们将人们自己的反应与他们的预测进行对比时，这些点大致沿着一条直线下降。那些认为概率为 10%的人认为人群会说 10%左右；那些说 20%的人认为人群会说 20%左右；诸如此类。这两种反应相互追踪，正如你对虚假共识效应的预期。

像许多认知偏见一样，这一条也不一定不合逻辑。当评估别人习惯做的事情时，从我们自己开始作为参考点是合理的，只要它不成为我们唯一的参考点。不管潜在的心理机制是什么，让人们预测其他人会如何反应，对于提高调查的准确性来说是一个奇迹。因为错误共识效应是我们元知识的一个败笔，它让拥有良好元知识的人更加突出。

元知识有价值的第二种方式不是作为测谎仪，而是作为真理血清。通过探索元知识，民意测验者可以为调查回答者创造一个坦率回答问题的强大激励。2012 年，Prelec 与哈佛大学的心理学家莱斯利·约翰(Leslie John)和卡内基·梅隆大学的经济学家乔治·洛温斯坦(George Loewenstein)一起，应用了一种基于元知识的真理算法，对 2000 多名学术心理学家进行了关于研究渎职的调查。这显然是一个难以研究的话题:谁会自愿承认捏造数据？Prelec 和他的同事试图打破这种不情愿。他们提出代表受访者进行慈善捐赠，作为完成调查的奖励。他们告诉三分之一的回答者——对照组——捐款将是固定的数额。他们告诉另外三分之二的人，贡献将取决于回答者回答的真实程度，根据对元知识问题的回答来判断。

魔鬼有更好的元知识:他们比天使更了解他们社区里发生的事情

Prelec 和他的同事们无法判断是否有任何特定的受访者说了实话，但他们组织了这次调查，以便受访者能够通过诚实回答来集体最大化慈善贡献。效果是戏剧性的。接受这种激励的受访者承认伪造数据的比例是对照组的近三倍，分别为 1.7%和 0.6%。这只是少数人，这可能会让你担心这种差异的统计意义，但类似的模式出现在几个更广泛的，如果不太严重的罪行中。还有一个明显的虚假共识效应在起作用。自认造假的人认为他们的同伴中有 26%的人同样犯了错误，而自称清白的人认为这一数字为 9.5%。

接下来，Prelec 和他的团队更进一步，试图了解数据伪造的真实流行程度。他们没有独立的方法知道，但可以基于元知识进行猜测。他们问这两个小组有多少有罪的人会承认他们的罪行。自称无辜的人认为 4%的人会。鉴于他们对流行率的估计(9.5%)，这意味着他们预计共有 0.38%的调查受访者会承认造假。相比之下，那些承认有罪的人预计认罪率为 8.9%。考虑到他们估计的造假率(26%)，这意味着总体录取率为 2.4%，远接近完全激励组报告的 1.7%。

所以魔鬼有更好的元知识。他们比天使们更了解他们社区发生的事情，他们 1.7%的数字可能是更准确的。当有罪的一方告诉我们科学不端行为普遍存在时，我们理应倾听。

hat 给我们带来了元知识的第三个也是最令人印象深刻的应用:它可以筛选出不知道自己在说什么的人，让那些拥有真实信息的人做出贡献。作为一个简单的受控测试，Prelec 和 Seung 给 51 名麻省理工学院和 32 名普林斯顿大学本科生做了一个[测验](http://www.eecs.harvard.edu/cs286r/courses/fall10/papers/Prelec10.pdf)。对于美国 50 个州中的每一个，研究人员列出了该州最大的城市，并问学生它是否是首都。他们还询问学生，有多少比例的同学会同意他们的选择。麻省理工学院的回答者平均答对了 30 个州；普通的普林斯顿人 31 岁。(你可以自己试试[这里](https://www.classmarker.com/online-test/start/?quiz=mem575a22de81cb7)。)由于正确答案是已知的，这种实验很容易评估元知识的效果。

正如假设的那样，那些得到正确答案的学生在预测其他回答者会说什么方面也做得更好。例如，60%的学生认为芝加哥是伊利诺伊州的首府，他们认为 89%的学生会同意。其余的人意识到芝加哥是错误的答案，但只有 30%的人知道答案。第二组的预测比例为 70:30，实际比例为 60:40。显然，大多数认为芝加哥是伊利诺伊州首府的人很难想象任何其他的可能性，而那些知道斯普林菲尔德是真正的首府的人意识到他们是少数——也许是因为他们自己曾经犯过同样的错误，也许是因为他们是习惯于无知的外州人的当地人。不管怎样，他们卓越的元知识证明他们也有更高质量的知识。Prelec 说，他们知道更多的事实，也知道有些人忽略了这些事实。

当大多数人是对的时候，这种技巧也是有效的。想想南卡罗来纳州。哥伦比亚是它的首都吗？约 64%的受访者表示同意，该小组预测 64%的人会同意。其余的人说不，他们预测 36%的人会同意他们的观点。这一次，两组在预测选票分裂方面做得一样好，所以没有理由怀疑多数人的意见。

大多数人总是对的。强烈的共识是我们所拥有的最接近真理的代理人

当你对测验答案进行平均，剔除那些元知识水平低的回答者时，麻省理工学院小组答对了 41 个州，普林斯顿小组答对了 44 个州——这比未加权的答案有了相当大的进步。这项技术并不完美:它将几个正确的答案换成了错误的答案，但这种逆转比纠正更罕见。元知识调整也将专家从纯粹的反向投资者中筛选出来。那些倾向于默认投反对票的人总体上更准确，因为只有 17 个州的首府是最大的城市，但他们较差的元知识暴露了他们是反射性的反对者，而不是地理爱好者。

有趣的是，只有当大多数人的投票率低于 70%时，元知识修正才会影响结果。大多数人总是对的。这对现实世界的争端是一个有益的教训。强烈的共识是我们所拥有的最接近真理的代理人。比被误导的大众知道得更多的独狼比好莱坞电影让你相信的要少得多。

元知识对提高群体智慧的有用性启发了北卡罗莱纳州杜克大学的心理学家杰克·索尔和他的研究生阿萨·帕利，他们提出了一种类似于 Prelec 的[技术，但更容易应用。它的不同之处在于要求人们预测群体的平均反应，而不是要求他们预测同意他们的人的百分比，从而简化了过程，特别是当答案不是多项选择而是连续的时候。](http://papers.ssrn.com/sol3/papers.cfm?abstract_id=2636376)

举一个有点人为的例子，假设你问你的朋友美国经济今年将增长多少。小组中的每个人都阅读《纽约时报》*，该报报道的价值为 4%。那些只读《T4 时报》的人通常会预测其他人也会采用这种猜测。但是有一半的人也阅读《经济学人》及其更悲观的零增长预测。该小组将两种信息来源的差异分开，估计增长率为 2%。但是，意识到阅读《经济学人》的人越来越少，消息更灵通的人预测，整个群体将会猜测 3%。*

 *那么，总体而言，人们平均估计 3%的增长率，并预测会猜测 3.5%。这两个值之间的差异告诉你，这个群体受到了共享信息偏差的影响，这种偏差将增长估计值拉高了至少半个百分点。你可以把它“转向”反应的另一边，猜测增长率为 2.5%，这个数字似乎更能反映信息输入总量。

专家更有可能意识到其他人会不同意他们的观点。新手因为无法理解除自己之外的任何位置而背叛了自己

帕利和索尔的技术有助于理解我和阿吉雷在桑德斯实验中得出的结果。我们发现，受访者系统性地高估了小组对桑德斯获得提名机会的平均评估。在上面的*时代经济学家*的例子中，小组认为真实的(平均)和小组认为其他人会说的不匹配，这种差异表明了共享信息的偏见。显然，大多数人的答案基于广泛传播的信息，而勤奋的少数人则从更多样的来源获得答案，这让他们对桑德斯的前景更加怀疑。我们在 T2 对英国退出欧盟进行的第二次民意调查中观察到了类似的模式。

在这些结果的鼓舞下，Prelec、Soll 和其他研究人员希望将元知识纳入各种政治和经济预测，利用过去常常过于偏颇而没有意义的群体智慧。要自己利用这些原则，你不必做正式的调查；只需关注周围人展现出来的元知识。专家更有可能认识到其他人会不同意他们的观点，即使他们不同意，他们也应该能够表达其他观点。新手因为无法理解除自己之外的任何位置而背叛了自己。同样，当你发现持有某种信念的人比你预期的多时，你可以通过记录来监控你自己的元知识。Prelec 说，如果你发现自己对与你意见相左的人的数量感到惊讶，相对于你之前承诺的意见相左的预测，这表明你在这个领域是个新手。这不会自动让你犯错，但确实建议你应该重新审视你的信仰。

将元知识用作废话检测器也为气候变化等有争议的问题提供了指导。根据我的经验，怀疑气候变化及其人为原因的人往往对自己非常自信(尽管他们的批评之一是气候系统太复杂，无法准确建模)。另一方面，主流气候科学家承认，他们可能是错的，因为他们在最佳猜测上加了误差线。例如，在 20 世纪 90 年代中期的一次调查中，16 位气候科学家对给定二氧化碳水平下的温度上升进行了估计。其中 15 个给出了相当宽的误差线，反映了他们科学的不确定性。一名研究人员站在一边，给出一个几乎没有任何误差的估计，表明几乎绝对确定。那个人后来被认定为最直言不讳的气候怀疑论者之一。

如果你碰巧是一个气候怀疑论者，你可能会被最后一段激怒。现在停下来问问自己，是什么让你对自己的观点如此确定？如果你认为气候变暖是人类活动的结果，也不要沾沾自喜。你也应该停下来反思你确定性的来源——你真的比怀疑论者更了解科学吗？换句话说，你的元知识是什么状态？如果“我确信”这句话从公共话语中被禁止，我们都会过得更好，我们会更多地听取那些公开承认自己知识局限性的人的意见。

好的元知识是珍贵的。它不仅要求你了解一门学科，还要求你了解自己。而自知是所有知识中最难的知识。*