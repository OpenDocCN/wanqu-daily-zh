# 来自 2016:为什么深度学习突然改变你的生活|财富

> 原文:[http://fortune . com/ai-artificial-intelligence-deep-machine-learning/？UTM _ source = Wanqu . co&UTM _ campaign = Wanqu+Daily&UTM _ medium = website](http://fortune.com/ai-artificial-intelligence-deep-machine-learning/?utm_source=wanqu.co&utm_campaign=Wanqu+Daily&utm_medium=website)

在过去的四年里，读者无疑已经注意到了广泛的日常技术质量的巨大飞跃。

最明显的是，我们智能手机上的语音识别功能比过去好得多。当我们用语音指令呼叫我们的配偶时，我们现在就能联系到他们。我们和美国国家铁路客运公司或愤怒的前任没有关系。

事实上，我们越来越多地通过与电脑对话来与电脑互动，无论是亚马逊的 Alexa，苹果的 Siri，微软的 Cortana，还是谷歌的许多语音响应功能。中国搜索巨头百度表示，在过去的 18 个月里，用户对其语音界面的使用增加了两倍。

机器翻译和其他形式的语言处理也变得越来越有说服力，谷歌(Google)、[、微软(Microsoft)](https://fortune.com/company/microsoft)、[、](https://fortune.com/company/facebook)、百度(Baidu)每个月都会推出新的技巧。Google Translate 现在可以将一种语言的口语句子翻译成 32 种语言的另一种口语句子，同时提供 103 种语言的文本翻译，包括宿务语、伊博语和祖鲁语。谷歌的收件箱应用程序为许多收到的电子邮件提供了三个现成的回复。

然后是图像识别方面的进步。这四家公司都有让你搜索或自动组织没有识别标签的照片集的功能。你可以要求展示，比如说，所有里面有狗的东西，或者雪，甚至是一些相当抽象的东西，比如拥抱。这些公司都有原型，可以在几秒钟内为照片生成一个句子长的描述。

想想吧。为了收集狗狗的照片，这款应用程序必须能够识别从吉娃娃到德国牧羊犬的任何东西，并且不会在狗狗颠倒或部分模糊的情况下被绊倒，无论是在画面的右侧还是左侧，是在雾中还是雪中，是在阳光下还是阴影下。同时，它需要排除狼和猫。单独使用像素。这怎么可能呢？

[![](../Images/b9a31d3949b1882a09ed2f8508d538f3.png)

<noscript><img sizes="100vw" srcset="https://content.fortune.com/wp-content/uploads/2016/09/lrn-10-01-16-neural-networks-e1474990995824.png?w=320&amp;q=75 320w, https://content.fortune.com/wp-content/uploads/2016/09/lrn-10-01-16-neural-networks-e1474990995824.png?w=480&amp;q=75 480w, https://content.fortune.com/wp-content/uploads/2016/09/lrn-10-01-16-neural-networks-e1474990995824.png?w=576&amp;q=75 576w, https://content.fortune.com/wp-content/uploads/2016/09/lrn-10-01-16-neural-networks-e1474990995824.png?w=768&amp;q=75 768w, https://content.fortune.com/wp-content/uploads/2016/09/lrn-10-01-16-neural-networks-e1474990995824.png?w=1024&amp;q=75 1024w, https://content.fortune.com/wp-content/uploads/2016/09/lrn-10-01-16-neural-networks-e1474990995824.png?w=1280&amp;q=75 1280w, https://content.fortune.com/wp-content/uploads/2016/09/lrn-10-01-16-neural-networks-e1474990995824.png?w=1440&amp;q=75 1440w" src="../Images/052d6924d9917ea24c8f61a501278ec0.png" decoding="async" data-nimg="responsive" loading="lazy" data-original-src="https://content.fortune.com/wp-content/uploads/2016/09/lrn-10-01-16-neural-networks-e1474990995824.png?w=1440&amp;q=75"/></noscript>](https://content.fortune.com/wp-content/uploads/2016/09/lrn-10-01-16-neural-networks-e1474990995824.png) 

图像识别的进步远远超出了酷的社交应用。医疗创业公司声称，他们很快就能使用计算机比放射科医生更快、更准确地阅读 X 射线、核磁共振成像和 CT 扫描，更早、更少侵入地诊断癌症，并加快救生药物的研发。更好的图像识别对于释放机器人技术、无人驾驶飞机，当然还有自动驾驶汽车的进步至关重要——这一发展如此重要，以至于我们在 6 月份将其作为封面故事。福特、[、特斯拉、](https://fortune.com/company/tesla)、[、](https://fortune.com/company/uber-technologies)、百度和谷歌母公司 Alphabet 今天都在公共道路上测试自动驾驶车辆的原型。

但大多数人没有意识到的是，所有这些突破，本质上都是同一个突破。它们都是由一系列人工智能(AI)技术(俗称深度学习)实现的，尽管大多数科学家仍然喜欢用它们最初的学术名称来称呼它们:深度神经网络。

神经网络最值得注意的一点是，没有人给计算机编程来完成上述任何一项特技。事实上，没有人能做到。相反，程序员给计算机输入了一种学习算法，让它接触万亿字节的数据——数十万幅图像或数年的语音样本——来训练它，然后让计算机自己找出如何识别想要的对象、单词或句子。

简而言之，这种计算机现在可以自学。图形处理领军企业 Nvidia(NVDA)的首席执行官黄仁勋(Jen-Hsun Huang)表示:“你实际上是在编写软件。”Nvidia 大约五年前开始在深度学习上下大赌注。*(更多信息，请阅读[《财富》杂志对英伟达首席执行官黄仁勋](http://fortune.com/2016/03/22/artificial-intelligence-nvidia/)的采访。)*

神经网络并不新鲜。这个概念可以追溯到 20 世纪 50 年代，许多关键的算法突破发生在 20 世纪 80 年代和 90 年代。发生变化的是，今天计算机科学家终于利用了巨大的计算能力和巨大的数据仓库——散布在互联网上的图像、视频、音频和文本文件——事实证明，这对神经网络的良好工作至关重要。“这是深度学习的寒武纪大爆发，”Andreessen Horowitz 风险投资公司的合伙人 Frank Chen 说，他暗指大多数高等动物物种突然出现的地质时代。

这一巨大的进步引发了一连串的活动。根据研究公司 [CB Insights](https://www.cbinsights.com/blog/artificial-intelligence-funding-trends-q216/) 的数据，上个季度，专注于人工智能的初创公司的股权融资达到了历史最高水平，超过 10 亿美元。该组织表示，2016 年第二季度，此类初创企业获得了 121 轮融资，而 2011 年同期只有 21 轮。在此期间，投资总额超过 75 亿美元，其中超过 60 亿美元来自 2014 年。(9 月下旬，五家企业人工智能领导者——亚马逊、脸书、谷歌、IBM 和微软——成立了非营利的人工智能合作伙伴关系，以促进公众对这一主题的理解，并进行道德和最佳实践的研究。)

谷歌在 2012 年有两个深度学习项目正在进行中。据一位发言人表示，今天它正在所有主要产品领域寻求超过 1000 个，包括搜索、Android、Gmail、翻译、地图、 [YouTube](https://fortune.com/company/youtube) 和无人驾驶汽车。IBM 的沃森系统在 2011 年击败了两个 *Jeopardy* 冠军时使用了人工智能，但没有使用深度学习。然而，根据沃森首席技术官 Rob High 的说法，现在沃森的 30 个组件服务几乎都通过深度学习得到了增强。

五年前甚至不知道什么是深度学习的风险投资家，今天对没有深度学习的创业公司很警惕。“我们现在生活在一个时代，”陈评论道，“在这个时代，人们必须构建复杂的软件应用程序。”他说，人们很快就会问，“你的自然语言处理版本在哪里？”我如何与你的应用程序对话？因为我不想点击菜单。' "

想了解更多关于人工智能的信息，请观看《财富》视频:

[fortune-bright cove videoid = 5035430911001]

一些公司已经在将深度学习整合到自己的日常流程中。微软研究院的联席主管李家杰说:“我们的销售团队正在使用神经网络来推荐接下来应该联系哪些潜在客户，或者应该推荐哪种产品。”

硬件世界感受到了震动。增强的计算能力使这一切成为可能，这不仅源于摩尔定律，还源于 21 世纪初英伟达(Nvidia)制造的图形处理单元(GPU)的效率是传统中央处理器(CPU)的 20 至 50 倍，这是一种强大的芯片，最初旨在为游戏玩家提供丰富的 3D 视觉体验。今年 8 月，Nvidia 宣布其数据中心部门的季度收入同比增长了一倍多，达到 1.51 亿美元。其首席财务官告诉投资者，“迄今为止，绝大多数增长来自深度学习。”在 83 分钟的财报电话会议中，“深度学习”一词出现了 81 次。

芯片巨头英特尔(INTC)并没有停滞不前。在过去的两个月里，它已经收购了 [Nervana Systems(价值超过 4 亿美元)](http://fortune.com/2016/08/09/intel-machine-learning-nervana/)和 [Movidius(价格未披露)](http://fortune.com/2016/09/06/intel-movidius-vision/)，这两家初创公司为深度学习计算的不同阶段定制技术。

谷歌方面在 5 月份透露，一年多来，它一直在秘密使用自己定制的芯片，称为张量处理单元(tensor processing units，简称 TPUs)，来实现通过深度学习训练的应用程序。(张量是像矩阵一样的数字阵列，在深度学习计算中经常彼此相乘。)

事实上，企业可能已经到达了另一个拐点。“过去，”百度研究院首席科学家吴恩达说，“许多标准普尔 500 的首席执行官希望他们能早些开始思考他们的互联网战略。我认为五年后，会有很多标准普尔 500 的首席执行官希望他们能早点开始思考他们的人工智能战略。”

在 ng 看来，即使是互联网的比喻也没有公正地解释具有深度学习的人工智能将意味着什么。“人工智能是新的电力，”他说。“就像 100 年前电力改变了一个又一个行业一样，人工智能现在也将这样做。”

把深度学习想象成子集的子集。“人工智能”包含大量技术，如传统逻辑和基于规则的系统，使计算机和机器人能够以至少表面上类似思维的方式解决问题。在这个领域中有一个较小的类别，称为机器学习，这是一整套神秘但重要的数学技术的名称，这些技术使计算机能够根据经验提高执行任务的能力。最后，机器学习中还有一个更小的子类，叫做深度学习。

百度的 ng 说，一种理解深度学习的方式是“A 到 B 的映射”。“您可以输入音频片段并输出文字记录。那就是语音识别。”他坚持认为，只要你有数据来训练软件，可能性是无限的。"你可以输入电子邮件，输出可能是:这是不是垃圾邮件？"他说，输入贷款申请，输出可能是客户偿还贷款的可能性。输入车队的使用模式，输出可以建议下一步把车送到哪里。

<aside>

## 人工智能术语词汇表

*   机器学习
*   人工智能的子集，包括深奥的统计技术，使机器能够根据经验改进任务。该类别包括深度学习。

*   深度学习
*   机器学习的子集，由算法组成，允许软件通过将多层神经网络暴露于大量数据来训练自己执行任务，如语音和图像识别。

</aside>

从这个角度来看，深度学习可以改变几乎所有行业。“既然计算机视觉真的起作用了，将会发生根本性的变化，”领导谷歌大脑项目的杰夫·迪恩说。或者，正如他令人不安地重新表述自己的句子，“既然计算机已经睁开了眼睛。”

这是否意味着是时候迎接“奇点”了——这是一个假设的时刻，超级智能机器在没有人类参与的情况下开始自我改进，引发失控的循环，将低级人类远远甩在身后，带来可怕的后果？

还没有。神经网络擅长识别模式——有时和我们一样好，甚至更好。但是他们不会推理。

这场迫在眉睫的革命的最初火花在 2009 年开始闪烁。那年夏天，微软的首席研究员邓梨邀请多伦多大学的神经网络先驱 Geoffrey Hinton 来访。邓的小组对他的研究印象深刻，于是试验用神经网络进行语音识别。“我们对结果感到震惊，”李说。“我们在第一批原型机上实现了超过 30%的精度提升。

据 Lee 介绍，2011 年，微软在其商业语音识别产品中引入了深度学习技术。谷歌于 2012 年 8 月跟进。

但真正的转折点出现在 2012 年 10 月。在意大利佛罗伦萨的一个研讨会上，斯坦福人工智能实验室的负责人、著名的年度 ImageNet 计算机视觉竞赛的创始人费-李非宣布，辛顿的两名学生发明了一种识别物体的软件，其准确率几乎是最接近的竞争对手的两倍。“这是一个惊人的结果，”辛顿回忆道，“说服了很多很多之前持怀疑态度的人。”(在去年的比赛中，一名深度学习参赛者超过了人类的表现。)

破解图像识别是发令枪，它开启了一场招聘竞赛。谷歌找到了辛顿和那场比赛的两名获胜者。脸书签约了法国深度学习创新者 Yann LeCun，他在 20 世纪 80 年代和 90 年代开创了赢得 ImageNet 竞赛的算法类型。百度还挖来了斯坦福人工智能实验室(Stanford AI Lab)前负责人 Ng，他曾在 2010 年帮助发起并领导以深度学习为重点的谷歌大脑项目(Google Brain project)。

自那以后，招聘热潮愈演愈烈。今天，微软的李说，在这个领域有一场“血腥的人才争夺战”他说，顶级头脑司令部提供“沿着 NFL 足球运动员的路线。”

68 岁的 Geoffrey Hinton 第一次听说神经网络是在 1972 年，当时他在爱丁堡大学开始了人工智能的研究生工作。辛顿在剑桥大学(Cambridge)本科时学习过实验心理学，他对神经网络充满热情，神经网络是一种软件结构，其灵感来自大脑神经元网络的工作方式。当时，神经网络不受欢迎。“每个人都认为他们疯了，”他回忆道。但是辛顿坚持了下来。

神经网络提供了计算机像儿童一样学习的前景——从经验中——而不是通过人类定制的程序的费力指导。“当时大部分人工智能都是受逻辑启发的，”他回忆道。“但逻辑是人们在晚年才会做的事情。2 岁和 3 岁的孩子不学逻辑。因此，在我看来，神经网络是一个比逻辑更好的智能运作模式。”(逻辑，碰巧是辛顿家族的行当之一。他来自一个杰出科学家的大家庭，是 19 世纪数学家乔治·布尔的玄孙，布尔搜索、逻辑和代数都是以他的名字命名的。)

在 20 世纪 50 年代和 60 年代，神经网络在计算机科学家中很流行。1958 年，康奈尔研究心理学家弗兰克·罗森布拉特在一个海军支持的项目中，在布法罗的一个实验室里建立了一个原型神经网络，他称之为感知器。它使用一台穿孔卡片计算机，装满了整个房间。经过 50 次尝试，它学会了区分标记在左边的卡片和标记在右边的卡片。《纽约时报》在报道这一事件时写道:“海军今天展示了一台电子计算机的雏形，它预计将能够行走、说话、看、写、自我复制并意识到自己的存在。”

感知器的软件只有一层类似神经元的节点，这被证明是有局限性的。但研究人员认为，多层或深层神经网络可以完成更多工作。

Hinton 是这样解释基本思想的。假设一个神经网络正在解释摄影图像，其中一些显示了鸟类。“所以输入会以像素为单位，然后第一层单元会检测到微小的边缘。黑暗一面，光明另一面。”他说，下一级神经元分析第一层发送的数据，将学会检测“像拐角这样的东西，两条边以一个角度连接在一起”。例如，其中一个神经元可能会对鸟喙的角度做出强烈反应。

下一级“可能会发现更复杂的结构，比如一堆排列成圆形的边。”这个级别的神经元可能会对鸟的头部做出反应。在更高的层次上，一个神经元可能察觉到喙状角在头状圆附近反复出现的并置。“这是一个很好的线索，表明它可能是一只鸟的头，”辛顿说。每个更高层的神经元对更复杂和抽象的概念做出反应，直到顶层的一个对应于我们的“鸟”的概念。

然而，为了学习，深度神经网络需要做的不仅仅是以这种方式通过各层发送消息。它还需要一种方法来查看它是否在顶层获得了正确的结果，如果没有，就向下发送消息，以便所有较低的神经元样单元可以重新调整它们的激活以改善结果。那是学习发生的地方。

20 世纪 80 年代初，辛顿就在研究这个问题。一位名叫 Yann LeCun 的法国研究员也是如此，他刚刚在巴黎开始他的研究生工作。LeCun 偶然发现了 hint on 1983 年的一篇论文，其中谈到了多层神经网络。“它不是用那些术语来表述的，”LeCun 回忆道，“因为在那个时候，如果你提到‘神经元’或‘神经网络’这个词，实际上很难发表一篇论文。”所以他以一种模糊的方式写了这篇论文，这样它就能通过审查。但是我认为这篇论文非常有趣。“两年后两人相遇，一拍即合。

1986 年，辛顿和两位同事写了一篇开创性的论文，提供了一个纠错问题的算法解决方案。“他的论文基本上是第二波神经网络的基础，”LeCun 说。它重新点燃了人们对这一领域的兴趣。

在 Hinton 完成博士后工作后，LeCun 于 1988 年转到美国电话电报公司的贝尔实验室，在接下来的十年里，他做了一些基础工作，这些工作至今仍被用于大多数图像识别任务。据 LeCun 称，在 20 世纪 90 年代，当时还是贝尔实验室子公司的 NCR 公司(NCR)将一种由神经网络驱动的设备商业化，该设备被银行广泛使用，可以读取支票上的手写数字。与此同时，两位德国研究人员——现就职于林茨大学的 Sepp Hochreiter 和卢加诺瑞士人工智能实验室副主任 jürgen schmid Huber——正在独立开发一种不同类型的算法，20 年后的今天，这种算法已成为自然语言处理应用的关键。

尽管取得了长足的进步，但在 20 世纪 90 年代中期，神经网络再次失宠，鉴于当时的计算能力，它被更有效的机器学习工具所取代。这种情况持续了近十年，直到计算能力又增加了三到四个数量级，研究人员发现了 GPU 加速。

但是仍然缺少一部分:数据。尽管互联网上充斥着大量数据，但大多数数据——尤其是涉及到图像的数据——并没有被标注，而这正是你训练神经网络所需要的。这就是斯坦福大学人工智能教授费-李非介入的地方。“我们的愿景是大数据将改变机器学习的工作方式，”她在一次采访中解释道。“数据驱动学习。”

2007 年，她推出了 ImageNet，汇集了超过 1400 万张标签图片的免费数据库。它于 2009 年上线，次年她设立了一个年度竞赛，以激励和发布计算机视觉突破。

2012 年 10 月，当 Hinton 的两名学生赢得比赛时，所有人都清楚地知道，深度学习已经到来。

到那时，普通大众也听说过深度学习，尽管是由于一个不同的事件。2012 年 6 月，谷歌大脑公布了一个古怪项目的结果，现在俗称为“[猫实验](https://googleblog.blogspot.com/2012/06/using-large-scale-brain-simulations-for.html)”它引起了滑稽的共鸣，并在社交网络上迅速传播。

该项目实际上探索了深度学习中一个重要的未解决问题，称为“无监督学习”。如今几乎所有商业使用的深度学习产品都使用“监督学习”，这意味着神经网络是用带标签的数据(如 ImageNet 组装的图像)训练的。相比之下，在“无监督学习”中，向神经网络显示未标记的数据，并简单地要求其寻找重复出现的模式。研究人员希望有一天能够掌握无监督学习，因为这样机器就可以从今天无法使用的海量数据中自学世界——像婴儿一样，几乎完全靠自己理解世界。

在 cat 实验中，研究人员将一个巨大的神经网络——分布在 1000 台计算机上——暴露在从 YouTube 视频中随机拍摄的 1000 万张未标记的图像中，然后让软件做它自己的事情。灰尘散去后，他们检查了最高层的神经元，果然发现其中一个对猫的图像有强烈的反应。“我们还发现了一种对人脸有强烈反应的神经元，”在谷歌大脑(Google Brain)领导该项目的 Ng 说。

然而结果也令人困惑。例如，“我们没有发现一个对汽车有强烈反应的神经元”，以及“有许多其他神经元，我们无法给它们分配一个英语单词。所以很难。”

这项实验引起了轰动。但是无监督学习仍然没有被破解——这是未来的挑战。

毫不奇怪，到目前为止，大多数商业部署的深度学习应用都涉及谷歌、微软、脸书、百度和亚马逊等公司——这些公司拥有深度学习计算所需的大量数据。许多公司正试图开发更现实、更有帮助的“聊天机器人”——自动化客服代表。

IBM 和微软等公司也在帮助企业客户为自己的业务调整深度学习驱动的应用程序，如语音识别界面和翻译服务，而亚马逊网络服务等云服务为那些想开发自己的软件的人提供廉价的 GPU 驱动的深度学习计算服务。丰富的开源软件——如 Caffe、谷歌的 TensorFlow 和亚马逊的 dsst ne——润滑了创新过程，正如开放出版伦理一样，许多研究人员立即在一个数据库上发布他们的成果，而无需等待同行审查的批准。

许多最令人兴奋的应用深度学习的新尝试都是在医学领域(见侧栏)。安德森·霍洛维茨生物投资部门的负责人、斯坦福大学教授维杰·潘德说，我们已经知道神经网络在图像识别方面非常有效，“医生做的很多事情都是图像识别，不管我们是在谈论放射学、皮肤病学、眼科还是其他许多学科。” "

<aside>

## 深度学习和医学

初创公司 [**Enlitic**](http://www.enlitic.com/) 使用深度学习来分析 x 光照片以及 CT 和 MRI 扫描。首席执行官伊戈尔·巴拉尼(Igor Barani)曾是旧金山加州大学的放射肿瘤学教授，他说 Enlitic 的算法在检测和分类肺结节为良性或恶性方面胜过了四名放射科医生。(该工作尚未经过同行评审，该技术尚未获得 FDA 批准。)

**[默克](https://fortune.com/company/merck)** 正试图利用深度学习来加速药物[的发现](https://fortune.com/company/discovery-insurance)，旧金山一家名为 [**Atomwise**](https://www.atomwise.com/) 的初创公司也是如此。神经网络检查 3D 图像——数以千计的可能作为候选药物的分子——并预测它们是否适合阻断病原体的机制。这些公司正在使用神经网络来尝试改善人类已经做的事情；还有人在尝试做人类根本做不到的事情。27 岁的加布里埃尔·奥特(Gabriel Otte)拥有计算生物学博士学位，他创办了 [**Freenome**](http://www.freenome.com/) ，旨在从血液样本中诊断癌症。它检测血液中细胞死亡时喷出的 DNA 片段。利用深度学习，他要求计算机找到无细胞 DNA 和一些癌症之间的相关性。“我们看到了癌症生物学家还没有描述过的新特征，”奥特说。

当安德森·霍洛维茨考虑投资 Freenome 时，AH 的潘德给奥特发了五份盲样——两份正常的，三份癌变的。潘德说，奥特五项都答对了，他的公司决定投资。

</aside>

虽然一个放射科医生一生中可能会看到成千上万张图像，但一台计算机可以显示数百万张。“想象计算机可以更好地解决这个图像问题并不疯狂，”潘德说，“只是因为它们可以处理比人类多得多的数据。”

潜在的优势不仅仅是更高的准确性和更快的分析，而是服务的民主化。随着这项技术成为标准，最终每个病人都会受益。

当深度学习以尚未想到的方式集成到其他人工智能技术的整个工具箱中时，它的最大影响可能会被感受到。例如，谷歌的 DeepMind 已经通过将深度学习与一种名为强化学习的相关技术相结合，取得了令人震惊的成就。利用这两种技术，它创造了 [AlphaGo](https://googleblog.blogspot.com/2016/01/alphago-machine-learning-game-go.html) ，该系统在今年 3 月击败了中国古代围棋的冠军选手——这被广泛认为是具有里程碑意义的人工智能成就。与 1997 年击败国际象棋冠军加里·卡斯帕罗夫的 IBM 深蓝不同，AlphaGo 没有编写决策树、如何评估棋盘位置的方程或 if-then 规则。DeepMind 首席执行官戴密斯·哈萨比斯表示:“AlphaGo 基本上是通过自我对弈和观察大型职业比赛来学习如何下围棋的。”。(训练时，AlphaGo 和自己下了一百万局围棋。)

一个游戏可能看起来像一个人工设置。但是哈萨比斯认为同样的技术可以应用于现实世界的问题。事实上，谷歌在 7 月份报告称，通过使用与 AlphaGo 类似的方法，DeepMind 能够将谷歌数据中心的能效提高 15%。“在数据中心，可能有 120 种不同的变量，”哈萨比斯说。“你可以换风扇，打开窗户，改变电脑系统，改变电源的流向。你已经从传感器、温度计等等那里得到了数据。就像围棋棋盘一样。通过反复试验，你学会了什么是正确的行动。

“所以这很棒，”他继续说道。“比方说，你每年可以节省数千万美元，而且这对环境也有好处。世界各地的数据中心都消耗大量电力。我们现在想在更大的范围内推广它。甚至国家电网级别。”

聊天机器人都很好。但那会是一个很酷的应用。

这篇文章的一个版本出现在 2016 年 10 月 1 日的《财富》杂志上，标题是“深度学习革命”该版本包含 CB Insights 研究公司的最新数据。