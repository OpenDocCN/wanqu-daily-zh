# 快速部署:钻机的故事|作者 Matt Reiferson | BuzzFeed Tech

> 原文:[https://tech . BuzzFeed . com/deploy-with-haste-the-story-of-rig-ca 9 a 58 b 5719 a？UTM _ source = Wanqu . co&UTM _ campaign = Wanqu+Daily&UTM _ medium = website](https://tech.buzzfeed.com/deploy-with-haste-the-story-of-rig-ca9a58b5719a?utm_source=wanqu.co&utm_campaign=Wanqu+Daily&utm_medium=website)

# 快速部署:钻机的故事

## 这是一个基础设施发展的故事。在 12 个月的时间里，我们从面向发布的大型部署转变为一种架构和方法，支持每天 **150 次以上的部署**。到达那里并不容易，但一路上我们学到了很多…



# 组织债务

BuzzFeed 是在十多年前由一个小型工程团队推出的，该团队支持为 buzzfeed.com 提供动力的单一应用程序。这非常有效，而且从当时的需求来看，绝对是正确的选择！

快进到 2015 年，这一年工程团队几乎增加了一倍。以前有效的工具和交互不能随着我们不断扩大的团队、基础设施和产品而扩展。

我们部署 monolith 的发布驱动方法开始真正显示出它的年龄。发布的规模和范围都在增长，直到他们需要一个指定的[“经理”](https://www.programmableweb.com/wp-content/Screen-Shot-2013-12-05-at-10.31.35-AM1-600x361.png)来负责指导它进入生产。我们很快发现[大型、不频繁的部署](https://blog.skyliner.io/ship-small-diffs-741308bec0d1%23.pdcg41u9d&sa=D&ust=1487808492269000&usg=AFQjCNFXWKYPtuQkPf0MZPyEI6SGqu00yg)，加上普遍缺乏可观察性，通过使生产问题难以调试和解决，极大地增加了每次部署的风险。最糟糕的时候，部署和验证一个版本需要花费我们数天时间。

与此同时，我们的公司焦点和产品套件也在不断发展。我们的视频内容越来越受欢迎，并普遍转向分布式优先的内容策略，这意味着我们正在 buzzfeed.com 之外构建系统(以及支持这些系统的工程团队),它们具有完全不同的需求。

我们觉得我们需要一个面向服务的架构，更好地反映我们成熟的分布式组织结构和期望的工作流。

# 工程经验

在这一点上，我们生活在一个构建新系统涉及一系列高摩擦协调点的世界中，这些协调点以 JIRA 票队列、手动资源供应和少量“实时操作”的形式出现。这个过程非常不一致，缺乏透明度，而且很难预测。这是一个经典的烫手山芋游戏，中间有一堵巨大的墙。

开发和部署管道会影响你做的每一件事——当它变得繁琐和低效时，它会让你难以试验和迭代，并且会让你陷入技术债务。团队被迫*只完成*，消除了一致性、惯例和标准的机会。

我们还需要更好的抽象。最重要的是，我们想为应用程序定义一个“标准接口”,作为回报，提供一个保证，如果它满足这些要求，它就会*正常工作*。**我们不想为了部署** *而要求团队去接触拜占庭式的配置管理代码或说出神奇的词语。*

最后，我们希望团队在部署后*，当系统投入生产时，更加投入。我们希望培养一种工程文化，在这种文化中，我们在调试和解决生产问题上进行合作，而这种责任并不完全落在现场可靠性上。为了做好这一点，我们需要对所有服务进行检测和监控——并且需要工具能够被广泛访问和易于使用。可观察性应该是以标准方式构建应用程序的自然副作用。*

因此，我们开始了改善“工程体验”的旅程——但这究竟是什么呢？

用于开发、验证、部署和操作软件系统的工具和方法的可用性、人机工程学、可靠性和有效性。

基本上，我们是在回答这个问题:**在尝试构建一个产品的过程中，你有多频繁地想要扔笔记本电脑？**我们希望这个数字是**零**。

# 概念证明

这一切都始于 2016 年 1 月的一个黑客周。我们基础设施组中的一些人决定构建一个概念验证的 PaaS。

是的，地球上的每个人目前都在构建自己的 PaaS。 [见*为什么不用 X？*](#d546) *为什麽我们也要造一个！*)

只有五天的时间让事情运转起来，我们需要走一些捷径。显然，这五天的大部分时间我们都在为这个名字而苦恼。最后，我们想出了**钻机**:

搭建(设备或装置或结构)，通常是仓促或临时搭建的



似乎很合适，对吧？我们对几个关键属性和要求有强烈的感受:

*   **自治**:提供标准和工具来加速产品工程团队。
*   **自由**:创建和部署新服务不需要任何协调。让做正确的事情变得容易，默认信任用户。
*   **效率**:将应用部署到同构计算资源集群。
*   实用主义:建立在 AWS 的经过战斗考验的平台 EC2(ELB)和他们的集装箱调度服务 ECS 之上。
*   **完整性**:从开发、CI、生产，包括机密管理，规范和控制管道。
*   **可观察性**:对系统和应用程序分布式日志记录、检测和监控的现成支持。

从 PaaSTA 中的高级应用程序抽象中获得灵感，我们开始用 Python 构建一个 CLI 作为用户的入口点。

我们很快采用了一组基本的约定，例如，服务是 [mono repo](/5-amazing-reasons-to-choose-monolithic-version-control-3215a29daecf#.epv8i6heu) 中的顶级目录，包含:

*   **service.yml** —服务的固有属性，例如 CPU/MEM 预留、实例计数、网络接口和组织元数据。
*   **Dockerfile** —将由 CI 构建的容器定义。

**config.yml** —纯文本应用配置。

*   **秘密。<集群>。gpg** —基于环境的 gpg 加密应用程序秘密(灵感来自[黑盒](https://github.com/StackExchange/blackbox))。

此外，我们建立了一些运行时要求:

我们创建了一个基于 VM 的开发工作流，以提供一个一致的、可重复的、短暂的环境来运行我们的工具和基础设施。在虚拟机内部，CLI 充当主要界面。运行服务就像 **rig run foo** 一样简单，包括管理 mysql、redis 和其他服务之类的依赖项。这是可能的，因为上面列出的惯例和 Docker 提供的方便的包装和工具。



Running deploy_ui locally in the rig VM



此外，rig 支持在运行服务时实时重新加载代码，以在开发过程中保持快速反馈循环。这是可行的，因为我们将回购装载到虚拟机*中，并将*装载到容器中。运行测试同样是微不足道的(**钻机测试 foo** )。

当您将提交推送到您的分支时， **builder** (一个基于 [Jenkins](https://jenkins.io/) 的捆绑绑定服务)集成您的代码，执行全局健全性检查，构建容器映像，运行测试，并将映像推送到容器注册表。

最后，部署是从 web UI 启动的，您可以在其中选择服务、版本化的容器映像和目标集群。然后，ECS 根据服务的配置(例如，其 CPU 和 MEM 预留以及所需的实例数量)，将服务“调度”到在该集群中注册的 EC2 实例上。对于新的 HTTP 服务，该过程还提供负载平衡器(带有 TLS)和 DNS 条目。



A screenshot of rig’s deploy_ui



根据容器映像和测试套件的大小，这个过程通常不超过几分钟，即使对于全新的服务也是如此！*您可以想象这对一个正在为长达数周的配置和部署而苦苦挣扎的组织会产生怎样的影响！*

不幸的是，概念验证并不一定会使系统具有生产价值。

# 生产推广和迁移

过渡到钻机有重要的原因，但它不是没有风险。首先，我们担心运营风险。例如，我们以前没有在生产环境中使用过 Docker(一种相对不成熟的技术)或 ECS(一种相当新的 AWS 托管服务)。

尽管 ECS 还不成熟，但它最吸引人的特性之一是支持“自带基础设施”。这意味着我们可以利用现有的坚如磐石的 AWS 服务，如 EC2、ELBs、RDS、ElastiCache 等。并使我们能够保持对主机的严密控制，包括充分理解的拓扑和生命周期原语(VPC、SGs 和 ASG)以及它们运行的基本操作系统和软件。这有助于我们更快地获得信心，只要我们信任“黑匣子”，即 ECS 管理的调度程序。

尽管如此，我们对稳定性、可操作性、可观察性和安全性仍有疑问，比如:

*   ECS 群集如何处理主机故障？
*   当 ECS 代理或 Docker 守护程序出现故障时会发生什么情况？
*   我们应该以什么样的粒度来监控容器化的服务？
*   Docker 网桥联网对网络性能有什么影响？

我们之前已经试验过用 [Terraform](https://www.terraform.io/) 来管理我们的云资源。我们认为，它的声明性质将使基础设施变更中的同行评审透明并得到支持。我们加倍投资 Terraform for rig，用它来配置所有底层基础设施。这提供了一种自动化且可重复的集群配置方法，我们使用这种方法在基础架构级别快速建立并测试假设。

我们用三种方法解决了可观测性问题:

*   **分布式日志**:我们将所有日志运送到 [Papertrail](https://papertrailapp.com/) ，按照服务、版本和集群进行标记和搜索。
*   **仪器**:我们集成了 [DataDog](https://www.datadoghq.com/) ，它对 Docker 有很深的支持，但也作为一个标准的 statsd 接收器，从仪器服务中聚合指标。
*   **监控**:我们构建了**监控器**(另一个捆绑的 rig 服务，基于 Nagios)，它自动发现集群中运行的主机、服务和其他资源，配置警报，并基于服务元数据将通知路由到 Slack、PagerDuty 等。

在这一点上，我们觉得我们有很好的监控覆盖，并且正在收集调试故障所需的见解。在运行了所有的操作练习之后，我们选择了低风险、工作量最小的系统进行第一次迁移。这使我们能够在生产中获得经验*，而不影响关键工作负载。*

# 影响

先说一些数字。

钻机于 2016 年 4 月“正式上市”。从那以后，我们观察到生产服务的数量每月都有两位数的百分比增长。到 2017 年 2 月，我们已经有 **227 项服务**投入生产！自 2016 年 6 月(我们开始跟踪他们)以来，我们还执行了 **18，228 次部署**。**平均每天 150 英镑！**服务和部署的绝对数量证明了它对我们交付率的影响。



A week’s worth of deploys



从文化上来说，它是一个游戏规则的改变者。作为运营商，由于服务配置、部署和运行的一致性，我们拥有巨大的优势。我们在 rig 上的投资具有巨大的乘数效应，例如，我们增加了服务自动扩展，rig 上的所有服务都可以立即受益于该功能。产品工程团队感受到所有权和授权来高效和有效地完成他们的工作，有更多的时间关注手头任务的“业务领域”。如果你降低了构建和部署新服务的成本和开销，你就鼓励了低风险的试验和迭代——这是 BuzzFeed 成功的要素。





最后，随着我们以类似俄罗斯方块的方式安排服务，我们基础设施的效率和利用率显著提高，极大地降低了成本，并使我们能够战略性地投资同质预留容量。



# 你为什么不用 X？

简而言之，因为 ECS、Kubernetes、Docker Swarm 等只是构建模块，我们希望向我们的用户公开一组自以为是的、更高级别的抽象。

这一领域的工具很少提供健壮的开发环境，也没有解决 CI、秘密管理或监控问题的答案，这意味着，无论如何，您都只能将拼图拼在一起。**钻机*是*胶水，并提供所有这些问题的解决方案！**

我们没有构建容器调度器(ECS)，也没有 CI 系统(Jenkins)，甚至没有可观察性工具(Nagios、DataDog、paper trail)——我们只是围绕一组健壮的 AWS 服务开发了一个内聚的 UX，建立了开源项目*，并给它起了一个该死的好名字*。

# 未来

我们的工作还没完成！

要了解一个系统的痛点，没有比有条不紊地操作并在生产中长时间使用它更好的方法了。为了获得内部用户的反馈，我们在 Slack 中建立了支持渠道，在正常办公时间运行，举办技术讲座，并通过采访和调查进行用户研究。将基础设施视为内部产品有助于我们更好地了解每个人的需求，并建立一个路线图，将我们的愿景与不断变化的需求融合在一起。

从操作上来说，我们已经知道大规模使用 Terraform 是很困难的。我们将在以后的文章中讨论这一点，但可以说，尽管它有许多好处，我们还没有解决它的一些痛苦的工作流程问题。例如，尽管它是自动化的和可重复的，但我们希望从零开始大大简化装备集群的供应(我们深受 [kops](https://github.com/kubernetes/kops) 的启发——也许我们应该只使用 Kubernetes？).

从用户的角度来看，使用 GPG 加密的秘密不是一个非常友好或直观的过程，鉴于这是第一步，我们希望简化或消除这种摩擦。此外，尽管我们处理秘密的方法很有效，但我们希望能够更容易地审计和轮换它们，这仍然太困难和耗时。

向 rig 的转变极大地加速了我们向面向服务架构的转变。在未来的帖子中，我们将讨论我们构建的其他工具和系统，它们帮助我们观察和控制这个不断增长的分布式系统的复杂交互，即我们的 [API 网关](https://www.youtube.com/watch?v=MSYrpMxUVaM)。



最后，我们打算在不久的将来对所有这些进行开源！我们没有忘记虚伪(见[你为什么不用 X？](#d546))。我们有*很多*关于开源钻机的目的和价值的问题——采纳我们所有愚蠢的意见似乎是一个巨大的要求。尽管如此，你可能碰巧同意我们的方法，在这种情况下，我们希望你也能从 rig 中受益！至少，分享我们的实现可能会启发你构建自己的实现(再次感谢 PaasTA)。

义务“如果这听起来像是你想做的那种事情”，我们将雇佣！

附注:如果不首先感谢威尔伯·麦克卢辰，任何博客都是不完整的。说实话，rig 是一项重要的团队工作。**非常感谢站点可靠性和平台基础设施团队提供、扩展和支持所有这一切！**











