# “伪人工智能”的崛起:科技公司如何悄悄使用人类来做机器人的工作|人工智能(AI) |卫报

> 原文:[https://www . the guardian . com/technology/2018/jul/06/人工智能-ai-humans-bots-tech-companies？UTM _ source = Wanqu . co&UTM _ campaign = Wanqu+Daily&UTM _ medium = website](https://www.theguardian.com/technology/2018/jul/06/artificial-intelligence-ai-humans-bots-tech-companies?utm_source=wanqu.co&utm_campaign=Wanqu+Daily&utm_medium=website)

很难建立一个由人工智能驱动的服务。事实上，很难，一些创业公司已经发现让人类像机器人一样比让机器像人类一样更便宜更容易。

“用人来做这项工作可以让你跳过大量的技术和业务开发挑战。ReadMe 的首席执行官 Gregory Koberger 说:“显然，它不能扩展，但它允许你在早期构建一些东西并跳过困难的部分，”他说他遇到过很多“伪人工智能”。

<gu-island name="SignInGateSelector" props="{&quot;format&quot;:{&quot;display&quot;:0,&quot;theme&quot;:0,&quot;design&quot;:0},&quot;contentType&quot;:&quot;Article&quot;,&quot;sectionName&quot;:&quot;technology&quot;,&quot;tags&quot;:[{&quot;id&quot;:&quot;technology/artificialintelligenceai&quot;,&quot;type&quot;:&quot;Keyword&quot;,&quot;title&quot;:&quot;Artificial intelligence (AI)&quot;},{&quot;id&quot;:&quot;technology/technology&quot;,&quot;type&quot;:&quot;Keyword&quot;,&quot;title&quot;:&quot;Technology&quot;},{&quot;id&quot;:&quot;technology/silicon-valley&quot;,&quot;type&quot;:&quot;Keyword&quot;,&quot;title&quot;:&quot;Silicon Valley&quot;},{&quot;id&quot;:&quot;business/business&quot;,&quot;type&quot;:&quot;Keyword&quot;,&quot;title&quot;:&quot;Business&quot;},{&quot;id&quot;:&quot;type/article&quot;,&quot;type&quot;:&quot;Type&quot;,&quot;title&quot;:&quot;Article&quot;},{&quot;id&quot;:&quot;tone/news&quot;,&quot;type&quot;:&quot;Tone&quot;,&quot;title&quot;:&quot;News&quot;},{&quot;id&quot;:&quot;profile/olivia-solon&quot;,&quot;type&quot;:&quot;Contributor&quot;,&quot;title&quot;:&quot;Olivia Solon&quot;,&quot;twitterHandle&quot;:&quot;oliviasolon&quot;},{&quot;id&quot;:&quot;tracking/commissioningdesk/west-coast-news&quot;,&quot;type&quot;:&quot;Tracking&quot;,&quot;title&quot;:&quot;West Coast News&quot;}],&quot;isPaidContent&quot;:false,&quot;isPreview&quot;:false,&quot;host&quot;:&quot;https://www.theguardian.com&quot;,&quot;pageId&quot;:&quot;technology/2018/jul/06/artificial-intelligence-ai-humans-bots-tech-companies&quot;,&quot;idUrl&quot;:&quot;https://profile.theguardian.com&quot;}" clientonly="true"></gu-island>

“这本质上是用人类构建人工智能的原型，”他说。

这种做法在本周《华尔街日报》的一篇文章中引起了关注，这篇文章强调了谷歌允许数百名第三方应用程序开发者访问人们的收件箱。

在圣何塞的爱迪生软件公司的案例中，人工智能工程师检查了数百名用户的个人电子邮件信息——他们的身份被编辑——以改进“智能回复”功能。该公司在其隐私政策中没有提到人类会查看用户的电子邮件。

<gu-island name="RichLinkComponent" deferuntil="idle" props="{&quot;richLinkIndex&quot;:5,&quot;element&quot;:{&quot;_type&quot;:&quot;model.dotcomrendering.pageElements.RichLinkBlockElement&quot;,&quot;url&quot;:&quot;https://www.theguardian.com/technology/2018/jun/27/being-human-realistic-robots-google-assistant-androids&quot;,&quot;text&quot;:&quot;Being human: how realistic do we want robots to be?&quot;,&quot;prefix&quot;:&quot;Related: &quot;,&quot;role&quot;:&quot;richLink&quot;,&quot;elementId&quot;:&quot;dbaa5c35-3b49-4137-bb55-7f2ff4e73d27&quot;},&quot;ajaxUrl&quot;:&quot;https://api.nextgen.guardianapps.co.uk&quot;,&quot;format&quot;:{&quot;display&quot;:0,&quot;theme&quot;:0,&quot;design&quot;:0}}"></gu-island>

《华尔街日报》文章中强调的第三方远非第一批这样做的人。2008 年，Spinvox，一家将语音邮件转换成短信的公司，被指控在海外呼叫中心使用人工而不是机器来完成工作。

2016 年，彭博强调了人类每天花 12 个小时假装为 X.ai 和 Clara 等日历调度服务的聊天机器人的困境。这项工作令人麻木，人类员工表示他们期待被机器人取代。

2017 年，商业费用管理应用 Expensify 承认，它一直在使用人类转录至少一些它声称使用其“智能扫描技术”处理的收据。收据的扫描件被发布到亚马逊的机械土耳其人众包劳动工具上，低薪工人在那里阅读和抄录它们。

“我想知道 Expensify SmartScan 用户是否知道 MTurk 工人输入他们的收据，”Rochelle LaPlante 说，她是 Twitter 上的“Turker”和零工经济工人的倡导者。“我正在看某人的优步收据，上面有他们的全名、上车和下车地址。”

即使是在人工智能方面投入巨资的脸书，也依赖人类为信使提供虚拟助手 M 。

在某些情况下，人类被用来训练 AI 系统并提高其准确性。一家名为 [Scale](https://www.scaleapi.com/) 的公司提供了一批人类工人，为自动驾驶汽车和其他人工智能系统提供训练数据。例如,“定标员”会查看摄像头或传感器的反馈，并在画面中标记汽车、行人和骑自行车的人。有了足够多的这种人类校准，人工智能将学会自己识别这些物体。

在其他情况下，公司伪造它，直到他们成功，告诉投资者和用户他们已经开发了一种可扩展的人工智能技术，同时秘密地依靠人类的智能。

<gu-island name="TweetBlockComponent" deferuntil="visible" props="{&quot;element&quot;:{&quot;_type&quot;:&quot;model.dotcomrendering.pageElements.TweetBlockElement&quot;,&quot;html&quot;:&quot;<blockquote class=\&quot;nojs-tweet\&quot;><p lang=\&quot;en\&quot; dir=\&quot;ltr\&quot;>How to start an AI startup<br><br>1\. Hire a bunch of minimum wage humans to pretend to be AI pretending to be human<br><br>2\. Wait for AI to be invented</p>&amp;mdash; Gregory Koberger (@gkoberger) <a href=\&quot;https://twitter.com/gkoberger/status/704745266901966848?ref_src=twsrc%5Etfw\&quot;>March 1, 2016</a></blockquote>\n&quot;,&quot;url&quot;:&quot;https://twitter.com/gkoberger/status/704745266901966848&quot;,&quot;id&quot;:&quot;704745266901966848&quot;,&quot;hasMedia&quot;:false,&quot;role&quot;:&quot;inline&quot;,&quot;isThirdPartyTracking&quot;:false,&quot;source&quot;:&quot;Twitter&quot;,&quot;elementId&quot;:&quot;01a388dd-45c9-4920-8952-a6e18cfc1880&quot;}}"></gu-island>

心理学家艾丽森·达茜是心理健康支持聊天机器人 Woebot 的创始人，他将这种方法描述为“奥兹设计技巧的向导”。

“你模拟某样东西的终极体验将会是什么样的。很多时候，当涉及到人工智能时，幕后是一个人，而不是一个算法，”她说，并补充说，建立一个好的人工智能系统需要“大量的数据”，有时设计师想知道在投资之前是否有足够的服务需求。

她说，这种方法不适合像 Woebot 这样的心理支持服务。

“作为心理学家，我们受道德准则的指导。不骗人显然是这些伦理原则之一。”

研究表明，当人们认为他们在和一台机器而不是一个人交谈时，他们倾向于透露更多，因为寻求心理健康帮助会带来耻辱。

南加州大学的一个小组用一个叫埃莉的虚拟治疗师对此进行了测试。他们发现，当患有创伤后应激障碍的退伍军人知道埃莉是一个人工智能系统时，他们更有可能泄露自己的症状，而不是当他们被告知有一个人在操作机器时。

<gu-island name="RichLinkComponent" deferuntil="idle" props="{&quot;richLinkIndex&quot;:20,&quot;element&quot;:{&quot;_type&quot;:&quot;model.dotcomrendering.pageElements.RichLinkBlockElement&quot;,&quot;url&quot;:&quot;https://www.theguardian.com/technology/2018/jun/18/artificial-intelligence-ibm-debate-project-debater&quot;,&quot;text&quot;:&quot;Man 1, machine 1: landmark debate between AI and humans ends in draw&quot;,&quot;prefix&quot;:&quot;Related: &quot;,&quot;role&quot;:&quot;richLink&quot;,&quot;elementId&quot;:&quot;63dd8018-c5a1-4c8e-ad5d-d9daea80817d&quot;},&quot;ajaxUrl&quot;:&quot;https://api.nextgen.guardianapps.co.uk&quot;,&quot;format&quot;:{&quot;display&quot;:0,&quot;theme&quot;:0,&quot;design&quot;:0}}"></gu-island>

其他人认为公司应该总是对他们的服务如何运作保持透明。

“我不喜欢它，”拉普兰特说，一些公司假装提供人工智能服务，但实际上却雇用了人类。“我觉得这是不诚实和欺骗性的，这两者都不是我想从我正在使用的业务中得到的。

“从员工的角度来看，我们似乎被推到了幕后。我不喜欢我的劳动成果被一家公司利用，这家公司会转过身来，向客户隐瞒真实情况。”

这种伦理困境也随着假装人类的人工智能系统而浮出水面。最近的一个例子是 [Google Duplex，这是一个机器人助手，它可以发出怪异逼真的电话，用“嗯”和“呃”来预约和预订。](https://www.theguardian.com/technology/2018/may/08/google-duplex-assistant-phone-calls-robot-human)

在最初的强烈反对之后，谷歌表示，它的人工智能将向它与之对话的人类表明自己的身份。

“在他们的演示版本中，在低影响力的对话中，感觉有点欺骗性，”达西说。尽管在餐馆预定一张桌子可能看起来像是一个低风险的交互，但同样的技术在错误的人手中可能更容易被操纵。

例如，如果你能模拟名人或政治家的声音发出逼真的叫声，会发生什么？

“围绕人工智能已经有了很大的恐惧，当缺乏透明度时，它并没有真正帮助对话，”达西说。

*联系作者:olivia.solon@theguardian.com*