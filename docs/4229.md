# 在 Reddit - Upvoted 查看计数

> 原文:[https://redditblog.com/2017/05/24/view-counting-at-reddit/?UTM _ source = Wanqu . co&UTM _ campaign = Wanqu+Daily&UTM _ medium = website](https://redditblog.com/2017/05/24/view-counting-at-reddit/?utm_source=wanqu.co&utm_campaign=Wanqu+Daily&utm_medium=website)

****克里希南·钱德拉(u/shrink _ and _ an _ arch)** *高级软件工程师***

我们想更好地将 Reddit 的 **规模** **传达给我们的用户。到目前为止，[投票分数](https://www.reddit.com/r/announcements/comments/5gvd6b/scores_on_posts_are_about_to_start_going_up/)和评论数量是给定帖子活动的主要指标。然而，Reddit 有许多访问者在没有投票或评论的情况下消费内容。我们想建立一个系统，通过统计一篇文章的浏览量来捕捉这种活动。然后，这个数字会显示给内容创建者和版主，让他们更好地了解特定帖子的活动。**

在这篇文章中，我们将谈论我们是如何实现大规模计数的。

## 计数方法

我们对视图计数有四个主要要求:

*   计数必须是实时或接近实时的。没有每日或每小时的总量。
*   在短时间窗口内，每个用户只能被计数一次。
*   显示的计数必须在实际计数的几个百分点之内。
*   该系统必须能够以生产规模运行，并在事件发生后的几秒钟内处理事件。

满足所有这四个要求比听起来更难。为了实时维护一个精确的计数，我们需要知道一个特定的用户以前是否访问过这个帖子。为了了解这些信息，我们需要存储以前访问过每个帖子的用户集合，然后在每次处理一个帖子的新视图时检查该集合。这个解决方案的一个简单实现是将惟一的用户集作为散列表存储在内存中，用 post ID 作为键。

这种方法适用于流量较小的帖子，但一旦帖子变得受欢迎并且查看者数量迅速增加，就很难扩展。几个受欢迎的帖子有超过一百万的独特观众！在这样的帖子上，存储所有的 id 并频繁地查找集合以查看是否有人已经访问过，这对内存和 CPU 来说都是极其繁重的。

由于我们无法提供准确的计数，我们研究了几种不同的[基数估计](https://en.wikipedia.org/wiki/Count-distinct_problem)算法。我们考虑了两个非常符合我们期望实现的目标的选项:

1.  一种线性概率计数方法，非常精确，但是随着被计数的集合变大，需要线性更多的内存。
2.  一种基于[超对数](http://algo.inria.fr/flajolet/Publications/FlFuGaMe07.pdf) (HLL)的计数方法。hll 随集合大小呈亚线性增长，但不提供与线性计数器相同的精确度。

为了理解 hll 真正节省了多少空间，考虑一下这篇博客文章顶部的 r/pics 文章。它获得了超过 100 万的独立用户。如果我们必须存储 100 万个唯一的用户 ID，并且每个用户 ID 都是 8 字节长，那么我们将需要 8 兆字节的内存来计算一篇帖子的唯一用户数！相比之下，使用 HLL 计数将占用更少的内存。每个实现的内存量不同，但是在这个实现的[中，我们可以使用仅仅 12 千字节的空间来计数超过 100 万个 id，这将是初始空间使用量的 **0.15%！**](http://antirez.com/news/75)

([这篇关于高可伸缩性的文章](http://highscalability.com/blog/2012/4/5/big-data-counting-how-to-count-a-billion-distinct-objects-us.html)很好地概述了上述两种算法。)

许多 HLL 实现使用上述两种方法的组合，首先对小集合进行线性计数，一旦规模达到某一点就切换到 HLL。前者经常被称为“稀疏”HLL 表示，而后者被称为“密集”HLL 表示。混合方法是非常有利的，因为它可以为小集合和大集合提供准确的结果，同时保持适度的内存占用。这种方法在谷歌的 HyperLogLog++论文中有更详细的描述。

虽然 HLL 算法相当标准，但我们考虑在实现中使用三种变体。注意，对于内存中的 HLL 实现，我们只研究了 Java 和 Scala 实现，因为我们在数据工程团队中主要使用 Java 和 Scala。

Reddit 的数据管道主要面向阿帕奇卡夫卡。当用户查看帖子时，一个事件被触发并发送到事件收集器服务器，该服务器对事件进行批处理，并将它们保存到 Kafka 中。

从这里开始，视图计数系统有两个按顺序运行的组件。我们计数架构的第一部分是一个名为 [Nazar](https://en.wikipedia.org/wiki/Nazar_(amulet)) 的 Kafka 消费者，它将从 Kafka 读取每个事件，并通过我们制定的一套规则来确定某个事件是否应该计数。我们给它起了这个名字，因为就像纳扎尔是一个眼睛形状的护身符保护你远离邪恶一样，纳扎尔系统是一个“眼睛”,保护我们免受试图玩弄这个系统的坏演员的伤害。Nazar 使用 Redis 来维护状态，并跟踪一个视图不应该被计数的潜在原因。我们可能不计算事件的一个原因是，如果它是同一用户在短时间内重复查看的结果。Nazar 随后会更改该事件，在将该事件发送回 Kafka 之前，添加一个布尔标志来指示它是否应该被计数。

这是项目的第二部分。我们还有第二个 Kafka 消费者，名为 [Abacus](https://en.wikipedia.org/wiki/Abacus) ，它负责实际的浏览量统计，并将统计结果提供给网站或客户显示。Abacus 从 Kafka 读取 Nazar 输出的事件；然后，根据 Nazar 的决定，它要么计数，要么跳过视图。如果事件被标记为计数，那么 Abacus 首先检查 Redis 中是否已经存在与事件对应的帖子的 HLL 计数器。如果该计数器已经在 Redis 中，那么 Abacus 向 Redis 发出一个 [PFADD](https://redis.io/commands/pfadd) 请求来获取该帖子。如果 Redis 中没有计数器，那么 Abacus 向 Cassandra 集群发出请求，我们用它来保存 HLL 计数器和原始计数，并向 Redis 发出一个 [SET](https://redis.io/commands/set) 请求来添加过滤器。这通常发生在人们查看那些计数器已经被逐出 Redis 的旧帖子时。

为了保持对可能已经被逐出 Redis 的旧帖子的计数，Abacus 定期将 Redis 的完整 HLL 过滤器以及每个帖子的计数写出到 Cassandra 集群。对 Cassandra 的写入在每次发布时以 10 秒为一组进行批处理，以避免集群过载。下图概括了这一事件的高级流程。

## 结论

我们希望视图计数将更好地使内容创建者了解他们帖子的全部范围，并帮助版主快速确定哪些帖子在他们的社区中获得了大量流量。未来，我们计划利用数据管道的实时潜力，向 redditors 提供更多有用的反馈。

如果你对大规模解决这类问题感兴趣，[请查看我们的职业页面](https://about.reddit.com/careers/)。

特别感谢 u/d3fect、u/powerlanguage 和 u/gooeyblob 对本项目的贡献，并感谢 u/Kaitaan、u/bsimpson、u/spladug、u/mart2d2 和 u/KeyserSosa 审阅和编辑本文。