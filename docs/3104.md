# 深度学习的基础设施

> 原文:[https://openai.com/blog/infrastructure-for-deep-learning/?UTM _ source = Wanqu . co&UTM _ campaign = Wanqu+Daily&UTM _ medium = website](https://openai.com/blog/infrastructure-for-deep-learning/?utm_source=wanqu.co&utm_campaign=Wanqu+Daily&utm_medium=website)

在这篇文章中，我们将分享深度学习研究通常是如何进行的，描述我们为支持它所做的基础设施选择，以及开源的 kubernetes-ec2-autoscaler ，这是一个针对 kubernetes 的批量优化缩放管理器。我们希望这篇文章对你构建自己的深度学习基础设施有用。

* * *

## 使用案例

典型的深度学习进步始于一个想法，你可以在一个小问题上测试它。在这个阶段，您希望快速运行许多特别的实验。理想情况下，你只需 SSH 到一台机器上，在屏幕上运行一个脚本，不到一个小时就能得到结果。

让模型真正起作用通常需要看到它以各种可能的方式失败，并找到修复这些限制的方法。(这类似于构建任何新的软件系统，您将多次运行您的代码，以建立对其行为的直觉。)

<aside class="aside">

 <video loop="loop" src="https://cdn.openai.com/infrastructure-for-deep-learning/pong.mp4" autoplay="" muted="">You need to inspect your models from many angles to gain intuition for what they're actually learning. This [reinforcement learning](http://karpathy.github.io/2016/05/31/rl/) agent (controlling the right paddle) from [Dario Amodei](https://www.linkedin.com/in/dario-amodei-3934934) achieves a high Pong score, but when you watch it play you'll notice it just sits in one place.</video> 

</aside>

所以深度学习基础设施必须允许用户灵活地自省模型，仅仅暴露汇总统计数据是不够的。

一旦模型显示出足够的前景，您就可以将其扩展到更大的数据集和更多的 GPU。这需要消耗许多周期并持续多天的长时间作业。您需要仔细的实验管理，并对您选择的超参数范围非常慎重。

早期的研究过程是非结构化和快速的；后者是有条不紊的，有点痛苦，但这是获得一个好结果绝对必要的。

* * *

## 一个例子

论文[改进训练甘斯的技术](https://arxiv.org/abs/1606.03498)从[蒂姆·萨利曼斯](http://timsalimans.com/)设计几个改进[生成对抗网络](https://openai.com/blog/generative-models/#gan)训练的想法开始。我们将描述这些想法中最简单的一个(碰巧产生了最好看的样本，尽管不是最好的半监督学习)。

gan 由一个发生器和一个鉴别器网络组成。生成器试图欺骗鉴别器，鉴别器试图区分生成的数据和真实的数据。直观上，一个能骗过每个鉴别器的生成器就相当不错了。但是有一种很难修复的故障模式:生成器可以通过总是输出完全相同的内容而“崩溃”(看起来很真实！)样本。

Tim 的想法是给 discriminator 一整批[小批量](https://www.coursera.org/learn/machine-learning/lecture/9zJUs/mini-batch-gradient-descent)的样本作为输入，而不仅仅是一个样本。因此，鉴别器可以判断发生器是否只是不断地产生单个图像。发现塌陷后，梯度将被发送到生成器以纠正问题。

下一步是在 [MNIST](http://yann.lecun.com/exdb/mnist/) 和 [CIFAR-10](https://www.cs.toronto.edu/~kriz/cifar.html) 上制作这个想法的原型。这需要尽快制作一个小模型的原型，在真实数据上运行它，并检查结果。经过一些快速迭代，蒂姆得到了非常令人鼓舞的 [CIFAR-10 样本](https://cdn.openai.com/infrastructure-for-deep-learning/cifar10samples-2.jpg)——几乎是我们在这个数据集上看到的最好的样本。

然而，深度学习(以及一般的人工智能算法)必须得到扩展，才能真正令人印象深刻——小型神经网络是概念的证明，但大型神经网络实际上解决了问题，并且是有用的。所以伊恩·古德菲勒开始放大这个模型，在 T2 的 ImageNet 上工作。

![](../Images/1d0a07e292a84b8501e6307cc8ba5362.png)

[Our model](https://openai.com/blog/generative-models#improving-gans) learning to generate ImageNet images



对于更大的模型和数据集，Ian 需要在多个 GPU 上并行化模型。每个作业都会将多台机器的 CPU 和 GPU 利用率提高到 90%，但即使这样，模型也需要花很多天来训练。在这种制度下，每个实验都变得弥足珍贵，他会一丝不苟地记录每个实验的结果。

最终，虽然结果不错，但不如我们希望的那么好。我们已经测试了许多关于原因的假设，但是仍然没有解决。这就是科学的本质。

* * *

## 基础设施

### 软件

![](../Images/4ff3338e7d2e4e58ca5138dc26316540.png)

A [sample](https://github.com/openai/iaf/blob/master/tf_train.py#L51-L93) of our TensorFlow code



我们绝大部分的研究代码都是用 Python 写的，正如[我们的](https://github.com/openai/improved-gan) [开放](https://github.com/openai/vime) - [来源](https://github.com/openai/iaf) [项目](https://github.com/openai/imitation)所反映的那样。我们大多使用 [TensorFlow](https://www.tensorflow.org/) (或者特殊情况下使用[the no](http://deeplearning.net/software/theano/))进行 GPU 计算；对于 CPU，我们使用这些数字或数字。研究人员有时也会在 TensorFlow 之上使用更高级别的框架，如 [Keras](https://keras.io/) 。

像许多深度学习社区一样，我们使用 Python 2.7。我们一般使用 [Anaconda](https://www.continuum.io/anaconda-overview) ，它对一些科学图书馆的 [OpenCV](http://opencv.org/) 和[性能优化](https://docs.continuum.io/anaconda/#high-performance)等原本困难的包进行了方便的打包。

* * *

### 五金器具

对于理想的批处理作业，将集群中的节点数量增加一倍将会使作业的运行时间减半。不幸的是，在深度学习中，人们通常会从许多 GPU 中看到非常[次线性](https://research.googleblog.com/2016/04/announcing-tensorflow-08-now-with.html)的加速。因此，顶级性能需要顶级的 GPU。我们还为[模拟器](https://gym.openai.com/envs#box2d)、[强化学习环境](https://gym.openai.com/envs#atari)或小规模模型(在 GPU 上运行不快)使用了相当多的 CPU。

![](../Images/f9d93ecbc2931e1f26ba524a43bb3d69.png)

[nvidia-smi](https://developer.nvidia.com/nvidia-system-management-interface) showing fully-loaded Titan Xs



AWS 慷慨地同意向我们捐赠大量计算机。我们将它们用于 CPU 实例和横向扩展 GPU 作业。我们也运行自己的物理服务器，主要运行[泰坦 X](http://www.geforce.com/hardware/10series/titan-x-pascal)GPU。我们希望有一个长期的混合云:尝试不同的 GPU、互连和其他可能对深度学习的未来变得重要的技术是有价值的。

![](../Images/befac6973f90fa139432738294090708.png)

[htop](http://hisham.hm/htop/) on the same physical box showing plenty of spare CPU. We generally run our CPU-intensive workloads separately from our GPU-intensive ones.



* * *

### 准备金提取

我们对待基础设施就像许多公司对待产品一样:它必须呈现一个简单的界面，可用性和功能性一样重要。我们使用一套一致的工具来管理我们所有的服务器，并尽可能一致地配置它们。

![](../Images/7e537014ea984501353a5a863524fa58.png)

Snippet of our Terraform config for managing Auto Scaling groups. Terraform creates, modifies, or destroys your running cloud resources to match your configuration files.



我们使用 [Terraform](https://www.terraform.io/) 来设置我们的 AWS 云资源(实例、网络路由、DNS 记录等)。我们的云和物理节点运行 [Ubuntu](http://www.ubuntu.com/) ，配置 [Chef](https://www.chef.io/chef/) 。为了加快启动速度，我们使用[打包器](https://www.packer.io/)预烘焙集群 ami。我们所有的集群都使用非重叠的 IP 范围，并通过公共互联网与用户笔记本电脑上的 [OpenVPN](https://openvpn.net/) 和物理节点上的 [strongSwan](https://www.strongswan.org/) (充当 AWS [客户网关](http://docs.aws.amazon.com/AmazonVPC/latest/NetworkAdminGuide/Introduction.html))互连。

我们在 [NFS](https://en.wikipedia.org/wiki/Network_File_System) (在物理硬件上)和 [EFS](https://aws.amazon.com/efs/) / [S3](https://aws.amazon.com/s3/) (在 AWS 上)上存储人们的主目录、数据集和结果。

* * *

### 管弦乐编曲

可扩展的基础设施往往会让简单的案例变得更加困难。我们为小规模和大规模工作投入了同等的努力，并且我们正在积极地巩固我们的工具包，使分布式用例与本地用例一样容易访问。

我们提供了一个 SSH 节点集群(有和没有 GPU)进行专门实验，并运行 [Kubernetes](http://kubernetes.io/) 作为物理和 AWS 节点的集群调度程序。我们的集群跨越 3 个 AWS 区域，我们的工作具有足够的突发性，有时我们会在单个区域达到饱和。

Kubernetes 要求每个作业都是 Docker 容器，这为我们提供了依赖隔离和代码快照。然而，构建一个新的 Docker 容器会给研究人员的迭代周期增加宝贵的额外时间，因此我们还提供了工具来透明地将代码从研究人员的笔记本电脑传送到标准映像中。

![](../Images/cadb6c1dcc567806ba8910e58a721bcc.png)

Model [learning curves](https://en.wikipedia.org/wiki/Learning_curve) in TensorBoard



我们将 Kubernetes 的[法兰绒](https://coreos.com/flannel/docs/latest/)网络直接暴露在研究人员的笔记本电脑上，允许用户无缝网络访问他们正在运行的工作。这对于访问 [TensorBoard](https://www.tensorflow.org/versions/r0.10/how_tos/summaries_and_tensorboard/index.html) 等监控服务尤其有用。(我们最初的方法——从严格隔离的角度来看更干净——要求人们为他们想要公开的每个端口创建一个 Kubernetes [服务](http://kubernetes.io/docs/user-guide/services/),但是我们发现这增加了太多的摩擦。)

* * *

## kubernetes-ec2-自动缩放器

我们的工作负载具有突发性和不可预测性:一个研究系列可以从单机实验快速发展到需要 1，000 个内核。例如，在几周的时间里，一个实验从单个 Titan X 上的交互阶段，到 60 个 Titan X 上的实验阶段，再到需要近 1600 个 AWS GPUs。因此，我们的云基础设施需要动态供应 Kubernetes 节点。

在[自动缩放](https://aws.amazon.com/autoscaling/)组中运行 Kubernetes 节点很容易，但是正确管理这些组的大小就比较困难了。在提交批处理作业之后，集群确切地知道它需要什么资源，并且应该直接分配这些资源。(相比之下，AWS 的[扩展策略](http://docs.aws.amazon.com/autoscaling/latest/userguide/policy_creating.html)将逐步增加新节点，直到资源不再耗尽，这可能需要多次迭代。)此外，集群需要在终止节点之前[耗尽](http://kubernetes.io/docs/user-guide/kubectl/kubectl_drain/)节点，以避免丢失运行中的作业。

在大批量作业中使用原始 EC2 是很诱人的，事实上这就是我们开始的地方。然而，Kubernetes 生态系统增加了相当多的价值:低摩擦工具、日志记录、监控、独立于运行实例管理物理节点的能力等等。正确制作 Kubernetes autoscale 比在原始 EC2 上重建这个生态系统更容易。

我们正在发布[kubernetes-ec2-auto scaler](https://github.com/openai/kubernetes-ec2-autoscaler)，这是一个针对 Kubernetes 的批量优化缩放管理器。它在 Kubernetes 上像普通的 [Pod](http://kubernetes.io/docs/user-guide/pods/) 一样运行，并且只要求你的工人节点在自动扩展组中。

![](../Images/70554685089fac89feac157e7bcf822f.png)

The Launch Configurations for our Kubernetes cluster



autoscaler 通过轮询 Kubernetes 主服务器的状态来工作，该状态包含计算集群资源请求和容量所需的一切。如果容量过剩，它会耗尽相关节点并最终终止它们。如果需要更多资源，它会计算应该创建哪些服务器，并适当增加自动扩展组的大小(或者只需[取消](http://kubernetes.io/docs/user-guide/kubectl/kubectl_uncordon/)耗尽的节点，从而避免新节点启动时间)。

kubernetes-ec2-autoscaler 处理多个自动伸缩组、CPU 之外的资源(内存和 GPU)以及对作业的细粒度约束，如 AWS 区域和实例大小。此外，突发工作负载可能会导致自动扩展组超时和错误，因为(令人惊讶的是！)就算是 AWS 也没有无限容量。在这些情况下，kubernetes-ec2-autoscaler 会检测到错误并溢出到辅助 AWS 区域。

* * *

我们的基础设施旨在最大限度地提高深度学习研究人员的生产力，让他们专注于科学。我们正在构建工具来进一步改进我们的基础架构和工作流程，并将在未来几周和几个月内分享这些工具。我们[欢迎帮助](https://jobs.lever.co/openai/f7801a92-1e2f-4656-a572-962b53ec34f6)让这一切进行得更快！