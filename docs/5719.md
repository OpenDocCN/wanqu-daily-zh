# 分布式系统中的健康检查和适度降级

> 原文：<https://medium.com/@copyconstruct/health-checks-in-distributed-systems-aa8a0e8c1672?utm_source=wanqu.co&utm_campaign=Wanqu+Daily&utm_medium=website>

# 分布式系统中的健康检查和适度降级

*一如既往地感谢* [*弗雷德·赫伯特*](https://twitter.com/mononcqc?lang=en) *和* [*萨尔贡·迪隆*](https://twitter.com/sargun) *阅读了这篇文章的草稿并提供了一些宝贵的建议。*

在她的 [Velocity 主题演讲](https://www.safaribooksonline.com/videos/velocity-conference/9781492026051/9781492026051-video320766)中，Box 的 [Tamar Bercovici](https://twitter.com/tamarbercovici?lang=en) 强调了在自动化数据库故障转移时健康检查的重要性。她特别强调了监控端到端查询时间是比简单的 pings 更好的确定数据库健康状况的方法。

> …将流量转移到另一端，从而补救中断。我们必须建立一些安全措施来防止翻转和其他奇怪的边缘情况，因为你不希望你的自动化从你身边跑掉，但这真的很简单。然而，成功完成这项工作的诀窍是首先知道**何时**翻转数据库，这意味着您需要能够正确地评估数据库的健康状况。现在，我们习惯于关注的许多指标，如 CPU 负载、锁超时、错误率，都是次要信号。实际上，这些都不能告诉您数据库是否能够为客户端流量提供服务。所以如果你用这些来做决定，你可能会得到假阳性和假阴性。相反，我们的健康检查器实际上对我们的数据库主机执行简单的查询，并使用**那些**的成功和失败来更准确地评估数据库健康。

这引发了我与一位朋友的讨论，他建议健康检查必须尽可能简单，实时流量是理解进程健康状况的更好标准。

通常，围绕运行状况检查实施的讨论都围绕着两个极端的选项，即简单的 pings 信号或全面的端到端测试。在这篇文章中，我的目的是强调使用上述形式的健康检查来进行某些类型的负载平衡决策背后的问题，以及需要一种更细粒度的方法来测量进程的健康。

## 两种类型的健康检查

即使在许多现代系统中，运行状况检查通常也分为两类——主机级运行状况检查和服务级运行状况检查。

例如，Kubernetes 使用*准备状态*和*活性状态*探针来实现健康检查。一个*就绪*探测器用于确定一个 Pod 是否可以服务流量。准备就绪探测的失败将导致 Pod 从组成[服务](https://kubernetes.io/docs/concepts/services-networking/service/)的端点移除，导致 Pod 不被路由任何流量，直到*准备就绪*探测成功。另一方面，*活跃度*探测器用于指示服务是否*响应*或者是否挂起或死锁。*活性*探针的故障导致 [kubelet](https://kubernetes.io/docs/admin/kubelet/) 重启单个容器。 [Consul](https://www.consul.io/docs/agent/checks.html) 类似地允许多种形式的`checks`，可以是基于`script`的检查，或者是基于 HTTP 的检查，点击指定的 URL，或者是基于 TTL 的检查，甚至是别名检查。

实现*服务*级健康检查的最常见方式是定义健康检查端点。例如，在 gRPC 中，健康检查本身就是一个 RPC 调用。gRPC 还允许对每个*服务*进行健康检查，以及对整个 *gRPC* *服务器*进行健康检查。

过去，主机级运行状况检查被用作发出警报的信号。一个例子是关于 CPU 平均负载的警报(最近被认为是一种反模式)。即使不直接用于警报，健康检查仍然构成了其他几个自动化基础设施决策的基础，如负载平衡和(偶尔)电路中断。例如，在确定是否将流量路由到实例时，像 Envoy 这样的服务网格数据平面将*健康检查*信息置于服务发现数据之上。

## 健康是一个光谱，而不是二元分类法



ping 只能传达服务是*启动*还是关闭，而端到端测试则代表系统是否可以执行某个单位的*工作*，其中工作可能是类似于*执行数据库查询*或*执行某个计算。*无论运行状况检查可能采取何种形式，运行状况检查的*结果*都被视为严格的二元结果，要么运行状况检查“通过”，要么“失败”。

在现代的、动态的并且经常是“自动扩展”的基础设施中，如果单个进程不能完成给定的工作单元，那么该进程仅仅是“启动”并不重要，这使得像 pings 这样的简单检查几乎没有用。

虽然判断一项服务何时完全关闭很容易，但确定一项服务的健康程度(T2)却要困难得多。一个进程极有可能“启动”(即通过健康检查)并被路由流量，只是因为它无法在服务的 p99 延迟内完成给定的工作单元。

无法完成工作通常是流程超负荷的结果。在高度并发的服务中，“过载”巧妙地映射到只能由单个进程服务的并发请求的数量，这种过多的排队会导致 RPC 调用的延迟增加(尽管更常见的是，下游服务会简单地使请求超时，并在配置好的`timeout`之后重试)。如果健康检查端点被配置为盲目返回 HTTP 200 状态代码，而服务正在进行的实际工作涉及网络 I/O 或计算，则情况尤其如此。



进程的“健康”是一个谱。我们真正感兴趣的是*服务质量—* 比如流程返回给定工作单元的结果需要多长时间，以及结果的准确性。

一个进程在它的生命周期中很可能在不同的健康程度之间波动，从完全*健康*(例如，能够在预期的并发水平上运行)到接近不健康(当队列开始填满时)再到完全进入不健康区域(此时请求的服务质量下降)。只有最琐碎的服务才能在假设任何时候都不存在某种程度的部分失败的情况下构建，其中部分失败意味着一些功能正常，而其他功能正常，而不仅仅是“一些请求失败，一些请求成功”。如果服务架构不能优雅地处理部分失败，那么处理错误管理复杂性的责任就自动落在了*客户端*身上。

自适应、自我修复的基础设施应该建立在这种波动完全正常的现实基础上。同样重要的是要记住，这种区别只在负载平衡方面有意义——例如，对于 orchestrator 来说，仅仅因为进程处于过载的边缘就重启该进程是没有意义的。

换句话说，编排层将流程的健康状况视为二进制状态，并且仅在流程崩溃或挂起时重启流程，这是完全合理的。然而，极其重要的是，*负载平衡*层(无论是进程外代理，如 Envoy，还是客户端进程内库)根据关于进程健康状况的更细粒度的信息做出相应的断路和减载决策。如果不能在任何给定时间准确地确定服务的健康状况，服务就不可能正常降级。

根据我的经验，无限制的并发通常是导致服务降级或持续性能低下的主要因素。负载平衡(或者说负载削减)通常归结为有效地管理并发性，并在系统过载之前施加背压。

## 施加背压时需要反馈回路

[Matt Ranney](https://twitter.com/mranney) 有一篇[现象博客文章](http://engineering.voxer.com/2013/09/16/backpressure-in-nodejs/)关于 Node.js 中的无限并发性和反压力的需要。整篇文章非常值得一读，但最大的收获(至少对我来说)是在一个进程和它的下游(通常是一个负载平衡器，但有时这也可能是另一个服务)之间的反馈循环的需要。

> 诀窍在于，当资源耗尽时，某处的某样东西必须做出让步。随着需求的增加，你不可能永远神奇地获得更高的性能。为了限制传入的工作，一个好的第一步是某种站点范围的速率限制，通过 IP 地址、用户、会话，或者希望对应用程序有意义的东西。许多负载平衡器可以以比 Node.js 的传入服务器限制更复杂的方式进行速率限制，但它们通常不会注意到问题，直到您的进程已经深陷困境。

从正确性和可扩展性的角度来看，基于[静态阈值和限制的速率限制和电路中断可能被证明是容易出错和脆弱的](https://www.infoq.com/articles/envoy-service-mesh-cascading-failure)。一些负载平衡器(特别是 HAProxy)确实提供了大量关于每个服务器的*和每个后端*的*的内部队列长度的统计数据。*此外*，* HAProxy 还允许`agent-check`(独立于常规健康检查的辅助检查)，这使得流程能够向代理提供关于其健康状况的更准确和动态的反馈。为了[引用文档](https://cbonte.github.io/haproxy-dconv/1.7/configuration.html#5.2-agent-check):

> 通过与由`agent-port`参数设置的端口建立 TCP 连接并读取 ASCII 字符串来执行代理健康检查。该字符串由一系列单词组成，由空格、制表符或逗号以任意顺序分隔，可以选择以`/r`和/或`/n`结束，每个单词包括:
> 
> —正整数百分比的 ASCII 表示，例如`"75%"`。
> 此格式的值将设置与 HAProxy 启动时配置的服务器初始
> 权重成比例的权重。请注意，零
> 权重在统计页面上被报告为`DRAIN`，因为它在服务器上具有相同的
> 效果(它已从 LB 场中移除)。
> —字符串`maxconn:`，后跟一个整数(中间没有空格)。此格式中的值将设置服务器的`maxconn`。广告的最大连接数需要乘以负载平衡器和使用此健康检查的不同后端的数量，以获得服务器可能接收的连接总数。例子:`maxconn:30`
> —单词`ready`。这将使服务器的管理状态变为
> `READY`模式，从而取消任何`DRAIN`或`MAINT`状态
> —`drain`一词。这将使服务器的管理状态变为
> `DRAIN`模式，因此除了那些通过持久性接受的
> 之外，它不会接受任何新的连接。
> —单词`maint`。这将使服务器的管理状态变为
> `MAINT`模式，因此它将不再接受任何新的连接，健康
> 检查将停止。
> —单词`down`、`failed`或`stopped`，可选地在一个尖角(“#”)后跟随一个
> 描述字符串。所有这些都将服务器的
> 操作状态标记为`DOWN`，但是由于这个词本身是在 stats
> 页面上报告的，这种差异使管理员能够知道这种情况是否是
> 预期的:服务可能被故意停止，可能出现在
> 但未通过某些有效性测试，或者可能被视为关闭(例如:缺少进程、
> 或端口没有响应)。
> —如果健康检查
> 也报告服务是可访问的，则单词`up`将服务器的操作状态设置回`UP`。
> 
> 没有被代理通告的参数不会改变。对于
> 的例子，代理可能被设计成监视 CPU 的使用，并且只报告一个
> 相对权重，而从不与操作状态交互。类似地，
> 代理可以被设计成一个带有 3 个单选按钮
> 的最终用户界面，允许管理员只更改管理状态。
> 
> **但是，重要的是要考虑到只有代理可以恢复自己的操作，因此如果使用代理将服务器设置为耗尽模式或关闭状态，代理必须实施其他等效的操作以使服务再次运行。**
> 
> 未能连接到代理不被视为错误，因为连接性
> 是由“check”
> 参数启用的常规健康检查来测试的。但是警告，在
> 报告“关闭”后停止代理并不是一个好主意，因为只有报告“启动”的代理才能再次启动
> 服务器。

这种让服务动态地向下游传达其健康状况的模式对于构建自适应基础设施来说极其重要。一个恰当的例子是我在以前的工作中使用的架构。

我之前在实时图像处理初创公司 [imgix](https://www.imgix.com) 工作。通过简单的 URL API，可以实时获取和转换图像，然后通过 CDN 提供给世界各地的用户。我们的堆栈相当复杂([，如前所述](https://stackshare.io/imgix/how-imgix-built-a-stack-to-serve-100000-images-per-second)，但简而言之，我们的基础设施包括一个负载平衡和分布层，它与源提取层、源缓存层、图像处理层和内容交付层协同工作。



我们的负载平衡层的核心是一个名为溢洪道的服务，它既是反向代理又是请求代理。溢洪道是纯粹的内部服务；在 edge 上，我们运行 nginx 和 HAProxy，所以溢洪道并不完全是为了终止 TLS 或执行 edge 代理权限内的其他无数功能而构建的。

溢洪道由两部分组成——前端(称为溢洪道 FE)和代理。虽然最初这两个组件存在于同一个二进制文件中，但后来我们决定将它们分成单独的二进制文件，一起部署在同一台主机上。这主要是因为这两个组件具有不同的性能，前端几乎完全受 CPU 限制。前端的职责是对每个请求执行一些预处理，包括预先转移到我们的原始缓存层，以确保在图像转换请求外包给工作人员之前，图像已缓存在我们的数据中心内。

在任何给定的时间，我们都有一个固定的工人池(如果我没记错的话，有 12 个左右)，这些工人将连接到一个单独的溢洪道经纪人。这些工作人员负责执行实际的图像转换(裁剪、调整大小、PDF 处理、GIF 渲染等等)。工作人员处理了从几百页的 PDF 文件到几百帧的 gif 文件再到普通的图像文件。工作人员的另一个特点是，虽然所有的网络都是完全异步的，但 GPU 本身的实际转换却不是。考虑到我们是一项实时服务，不可能预测我们在任何给定时刻的流量模式。这要求我们的基础设施能够自适应不同形式的传入流量，而无需任何人工操作员干预。

考虑到我们经常看到的完全不同和千变万化的流量模式，如果接受连接意味着工作人员面临过载的风险，那么工作人员就迫切需要能够拒绝接受传入的请求(即使它们非常“健康”)。对工作者的每个请求都带有一些关于请求性质的元数据，这使得工作者能够确定它是否能够服务于该请求。每个 worker 都维护自己的一组关于当前正在操作的请求的统计信息。worker 将这些统计信息与请求元数据和其他启发式信息(如套接字缓冲区大小)结合使用，以确定它是否准备好接受传入的请求。当一个工人决定它不能接受一个请求时，它精心制作了一个响应，就像 HAProxy 的代理检查一样，通知其下游(溢洪道)它的健康状况。

溢洪道追踪了游泳池中所有工人的健康状况。溢洪道将首先尝试连续三次向不同的工作线程发送请求(优先选择本地文件系统中可能有原始映像并且没有过载的工作线程)，如果三个工作线程碰巧都拒绝接受请求，请求将在内存代理中排队。代理维护三种形式的队列——后进先出队列、先进先出队列和优先级队列。如果三个队列恰好都满了，代理将简单地拒绝请求，允许客户机(HAProxy)在补偿期后重试。一旦请求在这三个队列中的任何一个中排队，任何空闲的工作线程都能够将请求弹出队列并处理它。关于*如何将*优先级分配给请求，以及关于*如何决定任何特定请求必须放入三个队列(LIFO，FIFO，基于优先级)中的哪一个*，还有更复杂的内容，但这些超出了本文的范围。

这种形式的动态反馈循环对于我们服务的健康运行是不可协商的。代理队列大小(在所有三个队列中)是我们非常密切监控的，我们的一个关键 Prometheus 警报是当队列大小超过某个阈值时(这种情况很少发生)。



[Image from my presentation on the Prometheus monitoring system at Google NYC in November 2016](https://speakerdeck.com/copyconstructor/prometheus-at-google-nyc-tech-talks-nov-2016?slide=39)





[Alert taken from my presentation on the Prometheus monitoring system at OSCON in May 2017](https://speakerdeck.com/copyconstructor/prometheus-a-whirlwind-tour)



今年早些时候，优步发表了一篇有趣的文章，阐述了他们实施基于服务质量的减载层的方法。

> 通过分析六个月内发生的停机，我们发现 28%的停机可以通过[适度降级](https://en.wikipedia.org/wiki/Fault_tolerance)来缓解或避免。
> 
> 我们观察到的三种最常见的故障类型是由于:
> 
> —入站请求模式变化，包括过载和不良因素
> —资源耗尽，如 CPU、内存、io_loop 或网络资源
> —依赖性故障，包括基础架构、数据存储和下游服务
> 
> 我们实现了一个受 [CoDel](https://en.wikipedia.org/wiki/CoDel) 算法启发的过载检测器。为每个启用的端点添加一个轻量级请求缓冲区(由 goroutine 和[通道](https://www.sohamkamani.com/blog/2017/08/24/golang-channels-explained/)实现),以监控从调用者收到请求到处理程序开始处理之间的延迟。每个队列监控滑动时间窗口内的最小延迟，如果延迟超过配置的阈值，则触发过载条件。

然而，重要的是要记住，如果反压力没有一直传播回调用链，那么在分布式系统的某些组件上会有一定程度的排队。谷歌在 2013 年发表了一篇臭名昭著的文章，名为[](https://www.dropbox.com/s/vd3divhvrkjqdv7/longtail.pdf?dl=0)**，文章谈到了具有大扇出的系统中延迟可变性的几个原因(排队是一个重要原因)，以及减轻这种可变性的几个巧妙技术(通常涉及冗余请求)。**



**实时管理进程中的并发性构成了分布式减载的基础，其中系统中的每个组件都基于本地知识做出决策。虽然这有助于[的可伸缩性，消除了对集中式协调](https://twitter.com/copyconstruct/status/1022671271631314944)的需求，但它并没有完全消除对集中式速率限制的需求。**



**Myriad forms of rate limiting and load shedding techniques**



**对于那些对用排队论学习更多形式性能建模感兴趣的人，我推荐观看下面的演讲:**

1.  **[**应用表演理论**](https://www.infoq.com/presentations/little-usl-scalability-performance) ，[卡维亚乔希](https://twitter.com/kavya719)来自 QCon London2018**
2.  **[**排队论实践:工作工程师的绩效建模**](https://www.youtube.com/watch?v=yf6wSsOFqdI) ， [Eben Freeman](https://twitter.com/_emfree_) 摘自 LISA 2017**
3.  **[**停止限速—产能规划做对**](https://www.youtube.com/watch?v=m64SWl9bfvk) ，[乔恩·摩尔](https://twitter.com/jon_moore)出自《奇景 2017》**
4.  **[**预测性负载均衡:不公平但更快更健壮**](https://www.youtube.com/watch?v=6NdxUY1La2I) ，[史蒂夫·古瑞](https://twitter.com/stevegury)出自《奇缘 2017》**
5.  **章节 [**处理过载**](https://landing.google.com/sre/book/chapters/handling-overload.html) 和 [**处理连锁故障**](https://landing.google.com/sre/book/chapters/addressing-cascading-failures.html) 出自[](https://landing.google.com/sre/book.html)**

## ****结论****

****在 TCP/IP(其中[拥塞控制算法](https://en.wikipedia.org/wiki/TCP_congestion_control)取决于负载推断)、IP [ECN](https://en.wikipedia.org/wiki/Explicit_Congestion_Notification) (这是一种确定负载或近负载的显式机制)和以太网等协议中，控制环路和背压已经是一个解决的问题，具有类似[暂停帧](https://en.wikipedia.org/wiki/Ethernet_flow_control)的效果。****

****粗粒度的健康检查对于编排系统可能是足够的，但是被证明不足以确保服务质量和防止分布式系统中的级联故障。负载平衡器需要应用程序级可见性，以便成功且准确地将背压传播到客户端。如果不能在任何给定时间准确地确定服务的健康状况，服务就不可能优雅地降级。如果没有及时和足够的背压，服务可能会很快陷入失败的流沙。****







