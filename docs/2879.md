# Smerity.com:这是 ML，不是魔术:你应该问的简单问题，以帮助减少人工智能炒作

> 原文:[http://smerity.com/articles/2016/ml_not_magic.html?UTM _ source = Wanqu . co&UTM _ campaign = Wanqu+Daily&UTM _ medium = website](http://smerity.com/articles/2016/ml_not_magic.html?utm_source=wanqu.co&utm_campaign=Wanqu+Daily&utm_medium=website)

# 这是人工智能，而不是魔术:你应该问的简单问题，以帮助减少人工智能炒作

### 2016 年 7 月 3 日

在互联网泡沫的顶峰时期，你认为 T2 前缀投资是一种合法的策略是情有可原的。一家公司可以通过添加一个“e-”前缀或“来获得一个不错的估值跃升。com”后缀。仅仅意识到万维网的潜力就足以向投资者表明一家公司可能会利用它。然而，这些后缀和前缀遗漏了一个详细的攻击计划。

互联网还很年轻，充满了在技术或逻辑上不可能实现的承诺。一些承诺过于乐观。其他的是彻头彻尾的欺诈。即使承诺可能成为现实，很少有公司有天赋或远见来执行一个深思熟虑的互联网战略。

自那以后的几年里，在网络泡沫的起起落落之后，我们看到了互联网的承诺充分发挥出来，改变了我们的生活和交流方式。即使是最敏锐的观察者在早期阶段也看不到多年后成为现实的许多可能性。泡沫并没有终结互联网技术的最终崛起，但它确实让生活变得更加复杂。

## 进入，舞台左侧:人工智能

如果我能对人工智能领域做出什么承诺的话，那就是炒作永远会超过研究。在这篇文章中，我不会对定义吹毛求疵，只是采用媒体中使用的最广泛的术语:人工智能是指每当一个系统比我们预期的更聪明时。这是对人工智能效应(AI/ML 的明确应用不再被认为是智能)和即使一个系统仅仅是基本统计学的应用，如果它看起来是智能的，它也可能被报告为人工智能的认可。

就像网络泡沫前后的互联网一样，AI 是一项年轻的技术。并不是人工智能缺乏潜力，只是非理性的乐观情绪压倒了一切。当前缀投资再次有利可图时，大胆(或许不可能实现)的承诺是一个自然的结果——唯一的区别是前缀现在是“AI-”。就像网络泡沫一样，很少有实体有天赋或远见来正确执行他们可能承诺的复杂人工智能战略。

人工智能以一种路由器和以太网电缆无法做到的方式抓住了我们的想象力。人工智能干净利落地融入我们现有的小说，建立在人类长期持有的恐惧之上。《弗兰肯斯坦》让我们全神贯注于赋予尸体知觉的非正统科学实验的故事。再往后是[魔像](https://en.wikipedia.org/wiki/Golem)，完全由无生命物质魔法创造的拟人化生物。这些都激发了现代的重述，除了用天网的钢铁代替了肉体和泥土。

人工智能的叙述也让没有该领域经验的评论家对未来做出强有力的陈述。这些非专家评论员与可能提出相反观点的专家相比，具有同等的权重。这不是对权威的上诉，这只是对证据的请求。虽然专家绝不是绝对正确的，但他们领域的一个普遍要求是他们提供证据来支持他们的观点。某些论点，如硬件能力的指数增长或自我改进系统的概念，有从对话中去除任何证据要求的趋势。

一个根本且难以忽视的事实是，科幻小说比科学事实更有趣。正如报道医学或物理学进展的故事和公司应该持保留态度一样，*我们应该反对这种对人工智能现实的虚构。对于 AI/ML/NLP/CV 领域的从业者来说，这可能是一个痛苦的认识。对他们来说，没有必要大肆宣传这项研究——现实已经足够令人兴奋了。*

这篇文章旨在提供一些简单的规则，在不限制一个人“梦想成真”的能力的情况下，应该能够挑选出最可笑的人工智能前缀的例子。

## 尴尬的局面:记者、投资者和企业家

为什么我们会处于这种境地？基本上，人类想要一个故事。这与我们早期的弗兰肯斯坦根源相吻合。钩子越有趣，我们就越有可能去关注，也越有可能想要成为其中的一部分。

当我们审视企业家、记者和投资者之间的相互作用时，这种基本情况变得更加极端。给投资者和记者留下深刻印象的一个合理策略是让他们大吃一惊。记者们甚至还有一个次要的愿望，那就是让他们的读者感到惊奇，这可以直接从这一点得到满足。因此，通过看到人工智能前缀报道的增加，人工智能前缀投资的前提可以扩展到记者。

最令我不安的是这句话，是经允许从我最近的一次谈话中引用的。一份出版物上的一篇文章介绍了一家年轻的初创企业——只不过这篇文章从人工智能的角度大力推进。问题是:( a)他们的产品目前没有任何人工智能功能,( b)还没有计划如何在他们的产品中实现人工智能。他们告诉我:

> 可悲的是，这正是媒体想要听到和报道的。这也是他们不会感到“无聊”的唯一方式。我没有一开始就说 AI，但这是我们取得突破的唯一方法。我认为我们不会很快改变他们的想法。

这可能是一个极端的例子——能够在没有任何人工智能的情况下获得人工智能相关产品的新闻报道——但即使引擎盖下有人工智能，夸大事实仍然可能发生。记者可能会被他们采访的人误导(有意或无意),竭力追求最激动人心的故事。投资者也是如此。

从学术角度来看，实际科学进步的门槛已经确立(甚至有业内人士认为它不够严格)——记者和投资者应该利用这个门槛，或者在接受低于这个门槛的任何东西时要格外小心。

## 我们需要的质疑天性

杰克·克拉克是“世界上唯一的神经网络记者”，在彭博任职。虽然这条推文已经发布了将近一年，但它简洁地解释了为什么我真的很喜欢他的报道。

除了需要证据来过滤 AI 前缀，他还阅读研究论文来取乐。显然，我们不能指望每个记者、投资者或外行人都有这种水平的洞察力，但有没有一些我们可以依靠的广泛规则呢？

### 询问系统在什么情况下会失败

> “揭示你的模型的失败案例是避免过度宣传的一种方式”
> [凯文·墨菲](https://www.cs.ubc.ca/~murphyk/MLbook/)在 2015 ICML

目前还没有一个人工智能系统能神奇地适用于所有的用例。如果一名研究人员告诉你，一个模特得到了开箱即用的艺术效果，他们要么非常幸运，要么给了你一个现实的童话版本。即使他们的模型是任意灵活的，信息论仍然对我们有基本的限制。

*   “需要多少训练数据？”
*   "这能在无人监督的情况下进行吗？"
*   "系统能预测词汇以外的名字吗？"(即想象一下，如果我说“我的朋友 Rudinyard 对我很刻薄”——许多人工智能系统永远无法回答“谁对我很刻薄？”因为 Rudinyard 不在其词汇表中)
*   "随着输入故事变长，准确性会下降多少？"
*   "随着时间的推移，模型的性能有多稳定？"

询问什么是可能的上限并不是一个不合理的问题。它也应该有一个明确的答案，因为这是任何使用或创建人工智能系统的人都应该已经遇到过的事情。

### 真实世界很少看起来像一个数据集

很少有数据集能完全代表现实世界中的任务。这些限制的存在有多种原因。我们创建的数据集通常反映了现有人工智能系统容量的微小扩展。正如我们给学生的测试很少反映真实世界一样，我们给这些人工智能系统的测试也很少反映真实世界。

你可能会问，为什么数据集只是以前数据集的增量扩展——为什么不直接跳到反映真实世界的数据集(假设你可以实际收集这样的数据集)。从哲学上讲，我们使用这些测试/实验作为发现新信息的过程，通常与验证假设有关。如果你对一个系统或个人进行测试，而你知道他们会失败，那么测试不会产生新的信息。

因此，数据集上的良好性能也不一定意味着现实世界中的良好性能。我敢打赌，如果我们确定一个合理的准确性概念，即使是微不足道的无人驾驶汽车模型，只要有合理的数据，也能达到 90 多分。真正坚持的是最后的百分之几。当我们在公路上高速行驶时，可能在可疑的条件下犯错，结果可能是灾难性的。如果一个错误的代价很高，那么准确性真的没有任何意义，尤其是对于一个本来就不具有代表性的数据集。那么问题就变成了在标准使用中预期的失败案例数量是多少。如果这些失败案例的影响很小，或者它们可以在以后被人类发现，那么人工智能系统仍然可以产生积极的影响。

许多数据集也局限于特定的领域。例如，自然语言处理中的标准数据集是 Penn Treebank，主要由 1989 年《华尔街日报》的文章组成。让我重复一遍:1989 年。那是我出生的那一年，柏林墙倒塌的那一年，也是最初的 Game Boy 发行的那一年。随着时间的推移，语言会发生变化，因此现代文本数据集与旧文本数据集有很大不同也就不足为奇了。

不仅时间是一个问题，而且华尔街日报主要是由金融文章组成的。对于许多任务，我们已经在 Penn Treebank 上实现了令人难以置信的高精度。然而，当我们在其他地方使用这些训练好的模型时，例如在科学文章等“域外”数据集上，性能可能会直线下降。应用到 Twitter 上更是如此。推特也可以是一种不同的语言。

另一个有趣的问题是，最佳基线的性能如何？对于某些任务，令人沮丧的简单策略可以让你获得大部分的准确性。出于这个原因，新的视觉问答数据集(例如，给你一张图片，问“女孩的花是什么颜色？”)包括人类基线，其中*人类从未看到图像*。这很重要，因为它代表了世界的纯文本模型所能做到的最好。事实证明，一个调整良好的纯文本机器学习模型，它从未见过任何被询问的图像，有时可以击败更复杂的模型，这些模型试图实际上，你知道，做视觉问题回答。

### 任何未经发表的先进研究的声明都是可疑的

> “如果你孤立地进行研究，质量就会下降。这就是为什么军事研究很糟糕。”Yann LeCun 在 2015 年 ICML

人工智能领域的变化速度如此之快，以至于任何旁观者充其量只能跟得上。一个实体突然冒出一个令人惊叹的系统当然不是不可能的，但这种可能性要小得多。这也意味着他们没有通过学术界对他们的标准评估。在某些情况下，这是合理的-有许多对现实世界应用有用的人工智能系统可能永远不会收到论文-但这是你应该意识到的一个缺失元素。

之前的:

> 从学术角度来看，实际科学进步的门槛已经确立(甚至有业内人士认为它不够严格)——记者和投资者应该利用这个门槛，或者在接受低于这个门槛的任何东西时要格外小心。

如果你能看到一个系统在你面前工作，那么恭喜你，但是如果没有适当的评估，它就是一个数据——我们不知道它应该工作得多好(至少参见“基线”)，可能会有什么样的失败案例，或者它们发生的频率有多高。

### 人工智能不会改变基本用例或业务基本面

AI 不会拯救一个破碎的商业计划。一个简单的上限是询问商业计划是否可以用免费的人工代替自动化的部分。当离开一些简单且定义明确的任务时，在任何现实世界的任务中达到人类水平的表现都是极其困难的。

我们还可以问，人工智能的应用是增值还是根本性的变革。许多人工智能前缀只将人工智能作为一种附加值，将其作为吸引媒体或投资的手段。在这种情况下，人工智能仍然是一个有用的补充，但它强调底层业务必须是可行的。

所有这些都是在说，如果商业计划对自由人类不起作用，AI 就不会拯救它。

## 结论

人工智能是一个充满惊人潜力的年轻领域，但围绕它的许多神秘都是不必要的。这种神秘和缺乏理解使得大肆宣传不受限制地发展。

正如《Keras 深度学习图书馆》的作者 Francois Chollet 在[民主化人工智能](http://blog.keras.io/on-the-importance-of-democratizing-artificial-intelligence.html)中指出的那样:“让深度学习变得更容易实现应该是我们的优先事项之一”。可及性延伸到远远超过学者和工程师的受众——也延伸到记者、投资者和更广泛的公众。

我们应该反对这种对人工智能现实的虚构——问上面的问题是一个好的开始。

* * *

**感谢:**

![](../Images/f5520f2c777f0b3cd940de3893714512.png)