# Box 上的 Kubernetes:速度最快的微服务| Box 博客

> 原文:[https://www . box . com/blog/kubernetes-box-micro services-maximum-velocity/？UTM _ source = Wanqu . co&UTM _ campaign = Wanqu+Daily&UTM _ medium = website](https://www.box.com/blog/kubernetes-box-microservices-maximum-velocity/?utm_source=wanqu.co&utm_campaign=Wanqu+Daily&utm_medium=website)

几年前，我们开始将支持 Box 的单片 PHP 应用程序拆分成微服务。我们知道我们最终需要几十个(甚至几百个)微服务才能成功，但是有一个严重的问题:我们提供新服务的模型有点...过时了。所谓过时，我的意思是 19 世纪的人们可能有比我们在 Box 更好的方式来构建和部署微服务。

**开始时**

如果您想要部署新的生产服务，您首先必须向运营团队请求专用硬件。没错——因为我们在 AWS 和虚拟化内部实用化之前就开始使用 Box，所以我们的大部分技术堆栈仍然基本上基于专用于特定服务的裸机服务器。订购、安装和上线硬件可能需要几周(甚至几个月)的时间。然后，您必须编写 Puppet 概要文件来定制您的特定服务器。当然，傀儡回购是高度安全的，并被锁定以防止任何事故，这对于安全性和稳定性来说是很好的，但对于开发人员的速度来说就不那么好了。

经过几周的定制 Puppet 配置、为负载平衡器获取一些服务器、定制这些服务器、部署自己的 Nagios 检查以确保服务器和服务正常运行，以及可能完成了维基百科上的几乎每一篇文章之后，您终于准备好部署您的代码了。对于开发、试运行和生产环境，您也需要这样做。这项工作负担如此之重，以至于一些团队会完全跳过部署到试运行阶段(或者跳过负载平衡器或服务认证等“无关紧要”的事情)，从而在环境之间产生显著的不一致性。

所有这些工作仅仅是为了推出一项新服务——现在想象一下这一努力乘以几十或几百，你就知道我们有一个非常严重的问题。必须做一些事情，所以我们开始研究如何使服务部署和管理变得更加简单。

**挑选解决方案**

我们知道我们需要某种内部 PaaS——一个让开发人员能够快速轻松地将服务部署到开发、试运行和生产环境中的平台。我们必须做出的第一个决定是，是基于虚拟机还是基于容器来构建平台。我们知道容器的快速开发和部署特性非常适合我们的目标，并且我们希望滑向冰球要去的地方，所以我们选择围绕容器化技术构建我们的平台。

Docker 是图像和容器格式的显而易见的选择，但是用于管理跨许多服务器的容器的技术就不那么显而易见了，尤其是当我们在 2014 年末做出这个决定的时候。此时，Kubernetes 才刚刚推出，亚马逊 ECS 还不存在，Mesos 也没有原生支持 Docker 容器。

在对我们能找到的每一种编排技术进行全面评估后，似乎只有两种技术具有我们所需要的复杂性(和开放性),那就是 Kubernetes 和 Mesos。我们选择 Kubernetes 而不是 Mesos 的原因可以填充它自己的博客帖子，所以我们只说 Kubernetes 关于编排系统应该是什么样子以及它提供的功能的世界观更符合我们自己的架构愿景。说实话，Kubernetes 提供的 API 是我们一直想要的。此外，Kubernetes 团队给我们留下了难以置信的印象——毕竟，有谁比帮助建造和维护世界上最大的集装箱化平台的工程师更适合建造一个编排平台呢？

**新的工作流程**

经过大约 18 个月的工作，我们已经构建并部署了一个平台，该平台极大地简化了工程师在生产中获得服务的工作。新的工作流程是这样的:

一名工程师编写了一个 Docker 文件，将他们的服务打包成一个 Docker 映像。一旦他们的映像被 Jenkins 构建并发布到我们的内部注册中心，他们编写并测试 Kubernetes 对象，这些对象运行他们的服务，[建立服务发现](http://kubernetes.io/docs/user-guide/services/)，[生成并加载秘密](http://kubernetes.io/docs/user-guide/secrets/)，[提供运行时配置](http://kubernetes.io/docs/user-guide/kubectl/kubectl_create_configmap/)，[以及更多](http://kubernetes.io/docs/user-guide/#concept-guide)。

*注意:这是 Kubernetes 和其他编排解决方案之间的一个关键区别——虽然大多数解决方案需要你去许多不同的系统来管理这些部分(或者[编写你自己的胶水](https://github.com/Yelp/paasta)来将这些系统绑在一起)，但是 Kubernetes 认为你的基础设施基本上应该通过一组提交并存储在主服务器上的 Kubernetes 对象来描述。这不要与 Kubernetes 本身的单片化相混淆——上述每个部分的实际实现都是通过 Kubernetes 内部的单个微服务来实现的。统一的只是数据模型。*

一旦工程师写好了他们的配置(用 [Jsonnet](http://jsonnet.org/) 模板语言，以便于重构)，他们就将配置添加到中央 git 存储库中。然后，我们有一个“应用程序”，它负责使用“kubectl apply”不断地协调 git 存储库的状态和我们在每个数据中心拥有的各种 Kubernetes 主服务器的状态。(我们帮助贡献了[许多代码](https://github.com/kubernetes/kubernetes/pull/6027)来驱动“kubectl apply ”,我们将开源应用程序(由我们的实习生构建！)不久。)

此时，Kubernetes 接管并在各种服务器上创建 Docker 容器，使用[服务负载平衡器](https://github.com/kubernetes/contrib/tree/master/service-loadbalancer)自动配置我们的 haproxy 负载平衡器，向实例提供秘密和配置，等等。部署到不同的环境或集群非常简单，只需添加一个 if 语句，在中央 git 存储库中生成几个文件。

**结果**

上述工作流程将启动服务的时间从六个月缩短到平均不到一周。我们的一些微服务已经在不到一小时的时间内从本地开发进入多个数据中心的生产阶段。

我们目前在每个生产数据中心运行 Kubernetes 集群，几个关键路径服务已经迁移到该平台，更多服务即将推出。我们对 [Kubernetes 1.3](http://blog.kubernetes.io/2016/07/kubernetes-1.3-bridging-cloud-native-and-enterprise-workloads.html) 中新的 [PetSet](http://blog.kubernetes.io/2016/07/thousand-instances-of-cassandra-using-kubernetes-pet-set.html) 支持感到特别兴奋，这样我们最终也可以在 Kubernetes 上运行 Hadoop 等服务。

毫无疑问，没有 Kubernetes，这个项目是不可能的。Kubernetes 社区绝对是真正开源协作的非凡典范。我们一直对整个设计和开发过程的透明和开放印象深刻，这是对我们继续投资该项目的巨大信任票。Kubernetes 是一个生产就绪的平台，我们期待着在未来几年中在其上进行构建。