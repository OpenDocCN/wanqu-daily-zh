# 大规模网络搜索引擎的架构，大约在 2019 年

> 原文:[https://www . 0x 65 . dev/blog/2019-12-14/the-architecture-of-a-large-scale-web-search-engine-circa-2019 . html？UTM _ source = Wanqu . co&UTM _ campaign = Wanqu+Daily&UTM _ medium = website](https://www.0x65.dev/blog/2019-12-14/the-architecture-of-a-large-scale-web-search-engine-circa-2019.html?utm_source=wanqu.co&utm_campaign=Wanqu+Daily&utm_medium=website)

在这个降临系列的[之前的文章](https://0x65.dev/)中，我们已经描述了一些驱动我们的私人[搜索产品](https://beta.cliqz.com/#channel=blog)的技术。现在是我们引入将所有东西整合在一起的系统的时候了。重要的是要明白一个网络规模的搜索引擎是非常复杂的。它是一个分布式系统，对性能和延迟有很大的限制。除此之外，运营成本很容易变得极其高昂；包括人力资源，当然还有资金。

这篇文章探讨了我们今天使用的技术堆栈，以及我们的一些选择和决策，这些选择和决策已经被采用和重复了多年，以满足外部和内部用户的需求。

手头的主题非常广泛，不可能在一次会议中涵盖，但我们希望给你它的要点。

我们将优秀的开源和云原生技术与本土开发的工具相结合，这些工具已经过实战检验。在开源世界或商业努力中我们还没有找到解决方案的地方，我们已经准备好深入下去，从零开始编写一些核心系统，这在我们的规模下对我们很有效。

**免责声明:**我们描述了我们的系统截至今天的状况。当然，我们不是这样开始的。多年来，我们进行了多次架构改革，始终考虑到成本、流量和数据大小等限制因素。决不，我们会建议这是一个食谱，建立一个搜索引擎；正如更明智的人所说的那样，这是今天行之有效的方法:

> “过早优化是万恶之源”~ Donald Knuth

我们完全同意。事实上，我们真的建议任何人，不要试图一次把所有的材料都扔进锅里。而是一个一个地添加它们；一步一步慢慢增加复杂性。

鉴于这篇文章的性质，我们想提供一个所有主题的有序大纲:

*   作为产品的 Cliqz 搜索及其系统需求。
*   网络搜索系统:一个接近实时和真正自动化的搜索系统。
*   数据处理平台:促进近实时和批量索引。
*   过去部署是如何完成的？各种方法的利弊。
*   微服务架构:为搜索引擎结果页面提供内容的编排服务。
*   我们对使用容器和容器编排系统的需求(Kubernetes)。
*   介绍我们的 Kubernetes 堆栈——我们如何部署、运行和管理 Kubernetes 和各种附加组件，以及它们为我们解决的问题。
*   Kubernetes 上的本地开发-端到端用例。
*   优化成本。
*   机器学习系统。

## 我们的搜索体验—下拉菜单和 SERP

Cliqz 的搜索引擎有两个需求不同的消费者。

**随键入搜索**

[![](../Images/52b6dd24f68c088bc5414dca27ae88b9.png)](../../static/img/posts/architecture-of-large-scale-web-search-engine/ext.png)

Figure 1: Cliqz Dropdown in the Browser



在浏览器地址栏<sup class="footnote-ref">[【1】](#fn1)</sup>中搜索，下拉列表中显示结果。这种类型的搜索需要较少的结果(通常为 3 个)，但对等待时间非常敏感(小于 150 毫秒)；否则用户体验会受到影响。

**在 SERP 中搜索**

[![](../Images/c8970727c7ea088f4e27b0f8280d2c01.png)](../../static/img/posts/architecture-of-large-scale-web-search-engine/serp.gif)

Figure 2: Cliqz Search Engine Result Page [beta.cliqz.com](https://beta.cliqz.com/#channel=blog)



在一个[网页](https://beta.cliqz.com/#channel=blog)上搜索，典型的搜索引擎结果页面大家都知道。在这里，搜索的深度是无限的，但与下拉版本相比，它对延迟的要求较低(小于 1000 毫秒)。

## 全自动和接近实时的搜索

考虑类似于*“拜仁慕尼黑”*的查询。现在，这可能看起来是一个非常普通的查询，但是当发出这个查询时，它会涉及到我们系统中的几个服务。如果我们试图解释查询的意图，我们会发现用户可能是:

*   研究俱乐部(在这种情况下，维基百科片段将是相关的)
*   有兴趣订票，购买商品，注册成为官方粉丝(官网)
*   对俱乐部的最新消息感兴趣:
    *   关于比赛的赛前新闻
    *   游戏中的信息，如:实时比分，实时更新或评论。
    *   关于比赛的赛后分析
    *   关于俱乐部内部运作的淡季信息，转会窗口期间的活动，雇佣新教练等。
*   搜索旧网页和内容、俱乐部历史、过去比赛的记录等。

人们可能会注意到，这不仅仅是查找相关页面。所请求的信息不仅应该在语义上相关，还应该在时间上相关。搜索中的新近性或时间敏感性是用户体验的一个非常重要的因素。

为了使这成为一种连贯的体验，必须从不同的来源获得信息，并近乎实时地转换成可搜索的索引。我们需要确保所有模型、索引和资产都是最新的(例如，图像的加载必须反映当前事件，并保持标题和内容相对于发展中的故事是最新的)。尽管大规模成功执行看起来很难，但我们坚信，我们的用户应该始终获得最新的信息，这种直觉构成了我们整个系统架构的基础。

Cliqz 的数据处理和服务平台遵循多层 Lambda 架构。根据被索引内容的新近性，它由三层组成。它们是:

1.  **近实时索引**

    *   使用 [Kafka](https://kafka.apache.org) (生产者、消费者和流处理器) [Cassandra](https://cassandra.apache.org) 、Granne<sup class="footnote-ref">[【2】](#fn2)</sup>和 RocksDB 进行全自动供电。
    *   Cassandra 将索引数据存储在不同的表中。不同表中的记录具有不同的生存时间(TTL ),因此我们可以释放存储空间，因为数据在后面的阶段会被重新索引。
    *   该组件还负责我们的趋势或受欢迎度驱动的排名功能，这些功能有助于在不同时间长度的移动窗口内识别趋势。我们通过使用[kafk streams](https://kafka.apache.org/documentation/streams/)的流处理来实现这一点。
    *   所有这些都转化为产品特性，包括搜索结果中的最新内容和头条新闻。
2.  **每周或基于滑动窗口的批量索引**

    *   基于过去 60 天的内容。
    *   每周重新编制索引(Jenkins 上批量作业的端到端自动化管道)。
    *   机器学习和数据管道在最近的数据上执行，导致我们的搜索结果质量更高。
    *   一个很好的框架，使用数据子集测试和原型化新的 ML 模型和算法变化，从而降低对整个数据进行端到端实验的成本。
    *   基于 Map-Reduce 和 Spark 的批处理工作流通过 Luigi 进行管理，并使用 Jenkins 管道进行追溯管理。
    *   凯维，卡珊德拉，qpick 和格兰恩发球。
3.  **整批索引**

    *   基于所有可用的数据
    *   重新索引:每两个月一次
    *   通过 Luigi 管理基于 MapReduce 和 Spark 的批处理工作流
    *   用于在大数据集上训练大规模机器学习模型。例如:查询和单词嵌入、近似最近邻模型、语言模型等。
    *   凯维，卡珊德拉，皮克和格兰内发球

这里需要注意的是，SERP 上的大部分搜索相关内容都是由近实时和每周索引提供的。这与其他搜索引擎的行为类似，后者会将最近的内容放在该主题的历史内容之上。批处理索引处理与时间无关的查询、查询的长尾以及在理解搜索查询的上下文中罕见的、历史的或棘手的内容。这三者的结合给了我们必要的弹药来构建当前形式的 Cliqz 搜索。所有的系统都能够回答所有的查询，但是最终的结果是所有索引结果的混合。

## 部署—历史背景

> 你还没有掌握一个工具，直到你明白什么时候不应该使用它。~凯尔西·海塔尔

从一开始，我们就专注于使用公共云提供商提供搜索服务，而不是管理内部基础设施。在过去的十年中，鉴于运营自己的数据中心所需的复杂性和资源，这已经成为整个行业的规范，相比之下，托管服务相对容易，创业公司可以轻松消化现收现付模式。亚马逊网络服务(AWS)<sup class="footnote-ref">[【3】](#fn3)</sup>对我们来说很方便，因为它允许我们从管理自己的机器和基础设施中抽象出来。如果没有 AWS，我们可能需要付出更多的努力才能达到这个阶段。(但是，它们既方便又贵。在这篇文章中，你会看到我们想出的一些降低成本的技巧，但是我们建议你在大规模使用云服务时要非常小心。)

我们通常努力避免提供可能对我们有用的托管服务，因为在我们通常运营的规模下，成本可能高得难以承受。让我们从 2014 年说起。我们早期遇到的一个越来越大的问题是在 AWS 上可靠地供应资源和部署应用程序。

我们开始努力在 AWS 之上构建我们自己的基础设施和配置管理系统。我们专注于发布一个 python 自带的解决方案，以方便开发人员加入。我们包装了 **[Fabric](https://get.fabric.io)** 项目，并将其与 **[Boto](https://github.com/boto/boto)** 耦合，以提供良好的界面来启动机器，并通过位于服务源的 *deploy.py* 文件驱动的几行代码来配置应用程序。然后，它被打包到项目模板生成器中，以便于新项目的启动。那时，是 docker 的早期，传统上我们以 python 包或普通 python 代码的形式发布，由于依赖管理，这很有挑战性。尽管该项目获得了很大的吸引力，并被 Cliqz 的许多服务用于驱动许多产品，但库驱动的基础设施和配置管理方法肯定缺少一些东西。全局状态管理、基础架构更改的集中锁定、没有项目或开发人员使用的云资源的集中视图、依赖外部工具来清理孤立资源、有限的配置管理、对开发人员使用情况的有限观察、来自工具常规用户的上下文渗透，这些都是造成摩擦并进而导致运营复杂性增加的因素。

这促使我们探索替代的外部解决方案，因为由于资源有限，不得不停止本土努力。我们最终采用的替代方案是来自 [Hashicorp](https://www.hashicorp.com) 的解决方案组合，包括 [Consul](https://www.consul.io) ，Terraform 和 [Packer](https://www.packer.io) ，以及最终的配置管理工具，如**[【ansi ble】](https://www.ansible.com)**和 **[Salt](https://www.saltstack.com)** 。

Terraform 展示了一种优秀的声明式基础设施管理方法，云原生空间中的许多当前技术都利用了这种方法。因此，经过仔细评估后，我们决定淘汰我们基于 fab 的 Terraform 部署库。除了技术上的利弊，我们还必须考虑人的因素。一些团队比其他团队更慢地采用变更，这可能是因为缺乏资源，或者因为转换的成本不一致。对我们来说，迁移花了很长时间，大约一年。

**[Terraform](https://www.terraform.io)** 无疑为我们带来了一些我们在旧的部署项目中缺失的现成功能，包括:

*   基础设施的中央政府管理。
*   详细计划、修补和应用支持。
*   使用最少的孤立资源轻松拆卸资源。
*   支持多种云。

同时，在我们与 Terraform 的旅程中，我们也面临一些挑战:

*   复杂的云专用 DSL，通常不会干涸。
*   很难用其他工具来包装它。
*   有限且有时复杂的模板支持。
*   没有关于服务运行状况的反馈。
*   不容易回滚。
*   缺少由 terragrunt 等第三方实现的关键功能。

Terraform 在 Cliqz 肯定有它的位置，现在我们仍然使用它来部署我们的大多数 Kubernetes 基础设施。

## 搜索系统的复杂性

[![](../Images/2eda05a0f4b2fe532fced56a8050d370.png)](../../static/img/posts/architecture-of-large-scale-web-search-engine/fuse_overview.png)

Figure 3: Search Overview



多年来，我们已经从拥有数十台服务器的分布式架构发展到整体式架构，最终发展到微服务架构。

考虑到可用的资源，我们相信的每个解决方案在当时都是最方便的；例如，monolith 版本是因为我们的大部分延迟来自集群机器之间的网络 IO。当时，AWS 推出了 X1 实例，内存高达 2 TB。架构的快速变化使我们能够快速减少延迟，但当然，成本也增加了。在下一次架构迭代中，我们专注于成本。一步一步地，我们试图在不恶化其他变量的情况下修正一个变量。这可能看起来不是一个非常奇特的方法，但对我们来说效果很好。

> 微服务架构风格是一种将单个应用程序开发为一套小型服务的方法，每个服务都在自己的进程中运行，并通过轻量级机制(通常是 HTTP 资源 API)进行通信。~马丁·福勒

Martin Fowler 的微服务定义在技术上是正确的，但有些抽象。对我们来说，它通常没有给出关于如何准确构建和分配微服务的足够描述，而这是重要的关注点。转向微服务为我们带来了:

*   更好的模块化和团队自治以及关注点分离。
*   水平可伸缩性和工作负载分区。
*   故障隔离和对多语言的更好支持。
*   多租户和更好的安全性。
*   更好的操作自动化。

纵观整个架构以及我们如何构建微服务，当向后端发出搜索查询时，请求路径中会触发大量服务。每个服务都被视为一个微服务，因为它具有关注点分离，由轻量级协议(REST/ [GRPC](https://grpc.io) )驱动，并且是可水平扩展的。每个服务可以由单独的微服务组成，并且可以有一个持久层。请求路径通常包括:

*   **Web 应用防火墙(WAF)** -针对常见 Web 漏洞的应用防火墙。
*   **负载平衡器** -请求摄取和负载平衡。
*   **入口代理** -路由、边缘可观察性、发现、策略执行。
*   **Eagle**-SERP 的服务器端渲染。
*   **融合** - API 网关、结果混合器、边缘缓存、认证/授权。
*   **建议** -查询建议<sup class="footnote-ref">[【4】](#fn4)</sup>。
*   **排名**<sup class="footnote-ref">[【5】](#fn5)</sup>——使用接近实时的索引和预编译的批量索引(Lambda 架构)提供搜索结果。
*   **丰富的结果**<sup class="footnote-ref">[【6】](#fn6)</sup>-添加丰富的信息，如天气、实况比分、其他第三方来源的片段。
*   **知识图和即时答案** -与查询相关的要点信息。
*   **Places** -基于地理位置的内容推荐。
*   **新闻** -来自知名新闻来源的实时内容。
*   **追踪器** -通过 [WhoTracks.me](https://whotracks.me) 的域特定追踪器信息。
*   **图片** -与用户查询相关的图片结果。

所有这些服务都通过一个通用的 API 网关进行协调，该网关负责处理搜索量，并配备了一些功能，如提供流量激增保护、基于请求/ cpu /内存/自定义指标使用的自动扩展、边缘缓存、流量阴影和分割、A/B 测试<sup class="footnote-ref">[【7】](#fn7)</sup>、蓝绿<sup class="footnote-ref">[【8】](#fn8)</sup>部署、金丝雀发布<sup class="footnote-ref">[【9】](#fn9)</sup>等。该平台还负责向正在使用的服务提供许多这样的功能。

## Docker 容器和容器编排系统

到目前为止，我们已经描述了我们产品的一些需求和具体细节。我们描述了我们是如何进行部署的，以及我们尝试的解决方案有哪些缺点。鉴于这些经验，我们选择 Docker 作为我们所有服务的基础构建模块。我们开始使用 docker 容器交付代码，而不是使用带有代码和依赖项的普通虚拟机。使用 docker，代码及其依赖项作为 docker 映像被发送到容器注册中心(ECR)。

但是，一旦服务再次开始增长，就需要管理它们，特别是当我们想要在生产中扩展它们的时候。多年来，我们不得不引入一个容器编排系统，这一点变得很明显。导致引入的痛点通常是**浪费计算资源**和**基础设施的复杂性**和**配置管理。**

我们总是缺少人员和计算能力，这是大多数资源有限的初创企业共有的情况。当然，要想有效，我们必须专注于解决现有工具无法解决的问题。但是，我们不相信重新发明轮子(直到它彻底改变现有的景观)。我们是开源软件的狂热用户，在那里我们找到了关键业务问题的解决方案。

1.0 版本发布后，我们就开始评估[Kubernetes](https://github.com/kubernetes/kubernetes)<sup class="footnote-ref">[【10】](#fn10)</sup>(k8s)，并在 1.4 版本之前运行生产级别的工作负载——一旦项目在工具方面表现出稳定性和成熟度。与此同时，我们评估了其他编排系统，包括 Apache Mesos 和 Docker Swarm，用于我们的大型项目，如 fetcher (web scale crawler)。我们最终决定用 Kubernetes 来运行一切，因为很明显，该项目显示出有希望用一种有凝聚力的方法来处理编排和配置管理，而其他人则没有，并且还包括一个强大的社区支持。

## kubernetes-Cliqz 堆栈

[![](../Images/cd84c6cd62b70f07275780034cace67b.png)](../../static/img/posts/architecture-of-large-scale-web-search-engine/tech.jpg)

Figure 4: OSS at Cliqz



> 开源赢了！

Cliqz 在很大程度上依赖于许多开源软件(OSS)项目，这些项目通常在云原生计算基金会<sup class="footnote-ref">[【11】](#fn11)</sup>的保护伞下，以提供内聚的云原生体验。我们尽最大努力通过代码、博客帖子和其他渠道(包括 slack)来回馈社区。我们将分享一些关键 OSS 项目的使用细节，这些项目构成了我们堆栈的核心:

**kops—kublantes 管弦乐团**

对于容器编排，我们使用 [KOPS](https://github.com/kubernetes/kops) 和一些自主开发的工具来管理集群生命周期和插件管理，从而自我管理多区域 Kubernetes 集群。向 Justin Santa Barbara 和 kops 维护人员大声疾呼，感谢他们出色的工作，以一致的方式提供了一个很好的集成体验来启动 k8s 控制平面和工作节点。目前，我们不依赖托管产品，只是因为 KOPS 的灵活性和 EKS 的不成熟，这是一个 AWS 托管的 k8s 控制平面。

使用 KOPS 和自我管理集群意味着我们可以真正按照自己的节奏设置，在故障排除过程中更深入地研究，激活应用程序要求但仅在特定 Kubernetes 版本中可用的功能。如果我们等待云产品，我们将不得不等待相当长的时间才能达到我们现在所处的阶段。

**织网——网络覆盖**

值得注意的是，Kubernetes 有助于抽象系统的所有部分。这不仅包括计算和存储，还包括网络。对于可以增长到数百个节点的集群，我们采用了一个[覆盖网络](https://en.wikipedia.org/wiki/Overlay_network)，它构成了为在多个节点、可用性区域和地区上繁殖的 pod 提供平面网络和网络策略执行功能的主干。 [Weave Net](https://www.weave.works/oss/net/) 是我们早期登陆的首选覆盖，因为它易于管理，并且通过 gossip 进行路由管理。随着我们变得更大，我们可能会转向 [AWS VPC CNI](https://github.com/aws/amazon-vpc-cni-k8s) 和 [Calico](https://www.projectcalico.org) ，因为它们成熟了，可以提供更少的网络跳数和更高的路由和流量一致性。到目前为止，weave net 在我们的延迟和吞吐量目标方面表现出色，没有理由进行转换。

**Helm/Helm file—包装管理和交付**

我们从一开始就依赖 helm (v2)来管理 Kubernetes 清单的打包和发布。尽管它有它的痛点，我们发现它是一个优秀的发布管理和模板资源。我们遵循一个单一的存储库结构来存储所有使用 chartmuseum 项目打包和提供的服务的导航图。特定于环境的值随后被保存在单独的存储库中，以区分不同的关注点。这些都是通过 [Helmfile](https://github.com/roboll/helmfile) 使用 gitOps 模式驱动的，它提供了一种声明式的方法来进行多舵图表发布管理和相关的基本插件，如 diff、tillerless 和 secret management rest with[SOPS](https://github.com/mozilla/sops)。使用通过[詹金斯](https://jenkins.io)驱动的 CI / CD 管道来验证和部署对该库的更改。

**Tilt/K9s—无应力局部 Kubernetes 开发**

我们早期面临的一个问题是:如何最好地将 k8s 纳入开发人员开发生命周期的内部循环。一些要求很快就变得显而易见。如何将代码构建并同步到容器中，并且尽可能快地完成。最初，我们有一个简单的自行开发的解决方案，在源代码更改时利用文件系统事件，并将所有内容同步到容器中。我们还尝试了一些项目，包括谷歌的 [Skaffold](https://github.com/GoogleContainerTools/skaffold) 和微软的 [Draft](https://github.com/Azure/draft) ，试图解决同样的问题。最终对我们起作用的是风车工程公司的 [Tilt](https://tilt.dev) (大喊到丹尼尔·本特利)，他们手上有一个优秀的产品，其工作流程由使用 [starlark](https://github.com/bazelbuild/starlark) 语言编写的 Tiltfile 驱动。它能够监视文件的编辑，可以自动应用更改，实时构建容器映像，通过集群构建加快构建速度，跳过注册表，并且有一个漂亮的用户界面，可以在单个窗格中查看有关您的服务的所有信息，等等。当你想更深入地挖掘时，我们通过一个名为 [K9s](https://github.com/derailed/k9s) 的令人敬畏的 CLI 工具来打开 k8s 的本质，以交互方式运行 K9s 命令并简化开发人员的工作流程。今天，我们在 k8s 上运行的所有工作负载都是在集群中开发的，借助 helm / tilt / k9s，我们可以获得跨项目的一致而快速的体验，任何新加入的人都可以通过几个命令轻松加入。

**普罗米修斯、警报管理器、耶格、格拉法纳和洛基——可观测性**

我们在很大程度上依赖于 [Prometheus](https://prometheus.io) 监控解决方案和时间序列数据库(tsdb)来收集、汇总和转发我们从单个服务中丢弃的指标。普罗米修斯配备了优秀的查询语言 PromQl 和警报解决方案[警报管理器](https://prometheus.io/docs/alerting/alertmanager/)。 [Jaeger](https://www.jaegertracing.io) 构成了我们痕迹聚合的主干。最近，我们开始从 [Graylog](https://www.graylog.org) 转移到 [Loki](https://grafana.com/oss/loki/) 作为我们的日志后端，以提供类似 Prometheus 的体验。这一切都是为了提供一个单一的玻璃窗格，在这里可以满足所有的可观察性要求，我们打算通过 Grafana 提供这一点，这是我们的制图解决方案。为了协调所有这些服务，我们在很大程度上依赖于 [Prometheus Operator](https://github.com/coreos/prometheus-operator) 项目，该项目通过集成来管理我们目前拥有的许多多租户 Prometheus 部署的生命周期。在任何给定的时间，我们都会摄取成千上万的时间序列，以收集关于运行基础设施和服务的见解，从而在出现故障时提供帮助。

未来，我们计划集成[灭霸](https://github.com/thanos-io/thanos)或 [Cortex](https://github.com/cortexproject/cortex) 项目，以应对 Prometheus 可扩展性挑战，并为历史分析提供全局查询视图、高可用性和数据备份。

**Luigi 和 Jenkins——自动化数据管道**

我们使用[路易吉](https://github.com/spotify/luigi)和[詹金斯](https://jenkins.io)来编排和自动化我们的数据管道。批处理作业通过 steps 提交给 EMR，Luigi 帮助我们在这些作业的基础上构建高度复杂的批处理工作流。Jenkins 用于在 ETL 过程中触发一系列操作，为我们提供对自动化和资源使用的控制，并深入到单个任务。

我们在版本化的 docker 容器中打包和版本化我们的批处理作业代码，以保持一致的开发和生产体验。

**附加项目**

我们还包括社区开发的许多其他项目，这些项目作为插件交付，并作为集群生命周期的一部分进行维护，以便为生产和开发环境中部署的服务提供价值。我们在下面简要讨论它们:

*   **[Argo 工作流和 CD](https://argoproj.github.io/)**—评估为 Jenkins 的批处理任务和持续部署工作的替代方案。
*   **[AWS IAM 认证器](https://github.com/kubernetes-sigs/aws-iam-authenticator)**—k8s 中的用户身份管理。
*   **[海图博物馆](https://chartmuseum.com)**—为我们的远程掌舵海图服务。
*   **[集群自动缩放器](https://github.com/kubernetes/autoscaler/tree/master/cluster-autoscaler)**—管理集群中的按需和定点车队的缩放。
*   **[垂直窗格自动缩放](https://github.com/kubernetes/autoscaler/tree/master/vertical-pod-autoscaler)**—根据需要或基于自定义指标垂直缩放窗格。
*   **[领事](https://www.consul.io)**—许多项目的状态存储，在那里我们可以尝试移动到[自定义资源定义](https://kubernetes.io/docs/concepts/extend-kubernetes/api-extension/custom-resources/) (CRDs)。
*   **[外部 DNS](https://github.com/kubernetes-sigs/external-dns)**—将 DNS 记录映射到 Route53 进行外部和内部访问。
*   **[Kube 缩减器](https://github.com/hjacobs/kube-downscaler)**—缩减不再使用的部署和状态集。
*   **[kube 2 iam](https://github.com/jtblin/kube2iam)**—透明代理，用于限制对 pod 的 aws 元数据访问和角色管理。
*   **[【Loki/prom tail】](https://grafana.com/oss/loki/)**—日志装运和聚集。
*   **[指标服务器](https://github.com/kubernetes-sigs/metrics-server)**—指标聚合和与其他消费者的接口。
*   **[Nginx 入口](https://github.com/kubernetes/ingress-nginx)**—内外服务入口控制器。我们继续评估其他入口控制器的扩展 API 网关功能，包括 Gloo、Istio 入口网关和 Kong。
*   **[Prometheus Operator](https://github.com/coreos/prometheus-operator)**—Prometheus Operator 堆栈，用于提供 Grafana、Prometheus、AlertManager 和 Jaeger 部署。
*   **[RBAC 管理员](https://github.com/FairwindsOps/rbac-manager)**—轻松管理 k8s 资源基于角色的访问控制的操作员。
*   **[点终止处理器](https://github.com/helm/charts/tree/master/stable/k8s-spot-termination-handler)**—通过先发制人地封锁和排空节点来优雅地处理点终止。
*   **[Istio](https://istio.io)**—我们继续评估 Istio 的网格、可观察性、流量路由和整形能力。对于其中的许多功能，我们已经在内部建立了解决方案，这些解决方案随着时间的推移已经显示出局限性，我们打算通过这个优秀的项目来实现这些功能。

我们在 k8s 方面的经验加上出色的社区工具，使我们不仅能够交付提供搜索的核心无状态服务，还帮助我们在多个可用性区域和集群中运行大型和关键的有状态工作负载，如 Cassandra、Kafka、Memcached 和 RocksDB，以实现高可用性和复制。我们开发了额外的工具来管理和安全地执行我们在 Kubernetes 内的规模的这些工作负载。

## 使用 Tilt 的本地开发—端到端使用案例。

到目前为止，我们已经介绍了很多我们使用的工具，但是我们想举一个具体的例子来说明这个工具是如何影响我们开发人员的日常工作流程的。

让我们以一个从事排名工作的工程师为例。以前，工作流程是:

1.  使用自定义操作系统映像、标记实例和带有所有权信息的相关资源启动 spot 实例。
2.  Rsync 应用程序代码到实例并安装应用程序依赖项。
3.  弄清楚设置其他服务，如 api 网关和前端，它们的依赖和部署。
4.  对它们进行配置，使它们能够很好地相互协作。
5.  开始编写排名应用程序。
6.  最后，一旦完成，确保**终止**实例。

我们可以看到，一个人需要重复地遵循一系列步骤，一遍又一遍，团队中的每个新工程师都必须重复这些步骤，这完全是对开发人员生产力的浪费。如果实例丢失，我们重复。此外，生产和本地开发工作流之间存在明显的差异，导致在某些时候出现不一致。有人可能会认为需要设置其他服务，如前端和排名，但这里的目标是通用的，此外，它总是有利于产品的完全可见性。此外，随着团队规模的增长，更多的云资源被创建，更多的资源未被充分利用。工程师让实例运行，因为他们不想每天重复设置过程。如果一个团队成员离开并拥有一个没有足够标签的孤立实例，那么识别关闭该实例并删除所述云资源是否安全是一个挑战。

理想的情况是，为工程师提供一个基本模板，用他自己的完整版 SERP 以及其他负责排名的服务来设置本地环境。我们一般配置基本模板，它用用户创建的唯一标识符名称来标记资源，并允许他们控制其应用程序的生命周期。由于 K8s 已经抽象出启动实例和管理它们的需求(我们使用 KOPS 集中管理它们)，我们使用模板来设置默认值(在非工作时间自动缩减)，因此极大地降低了成本。

用户现在所关心的是在本地编辑器中编写的代码，我们的工具由 Docker、Helm 和 Tilt 在 Kubernetes 上的组合组成，它简化了上述工作流程，像魔术一样在幕后工作。

这里有一个例子 [Tiltfile](https://docs.tilt.dev/api.html) ，它描述了设置一个 mini-SERP 版本所需的服务和其他依赖服务。要在开发模式下启动这些服务，用户只需运行:`tilt up`

```
# -*- mode: Python -*-

"""
This Tiltfile manages 1 primary service which depends on a number of other micro services.
Also, it makes it easier to launch some extra ancilliary services which may be
useful during development.
Here's a quick rundown of these services and their properties:
* ranking: Handles ranking
* api-gateway: API Gateway for frontend
* frontend: Server Side Rendering for SERP

"""

####################
# Project defaults #
####################

project = "some-project"
namespace = "some-namespace"
chart_name = "some-project-chart"
deploy_path = "../../deploy"
charts_path = "{}/charts".format(deploy_path)
chart_path = "{}/{}".format(charts_path, chart_name)
values_path = "{}/some-project/services/development.yaml".format(deploy_path)
secrets_path = "{}/some-project/services/secrets.yaml".format(deploy_path)
secrets_dec_path = "{}/some-project/services/secrets.yaml.dec".format(deploy_path)
chart_version = "X.X.X"

# Load tiltfile library
load("../../libs/tilt/Tiltfile", "validate_environment")
env = validate_environment(project, namespace)

# Docker repository path for components
serving_image = env["docker_registry"] + "/some-repo/services/some-project/serving"

####################################
# Build services and deploy to k8s #
####################################

# Watch development values file for helm chart to re-execute Tiltfile in case of changes
watch_file(values_path)

# Build docker images
# Uncomment the live_update part if you wish to use the live_update function
# i.e., no container restarts while developing. Ex: Using Python debugging
docker_build(serving_image, "serving", dockerfile="./serving/Dockerfile", build_args={"PIP_INDEX_URL": env["pip_index_url"], "AWS_REGION": env["region"]} #, live_update=[sync('serving/src/', '/some-project/'),]
)

# Update local helm repos list
local("helm repo update")

# Remove old download chart in case of changes
local("rm -rf {}".format(chart_path))

# Decrypt secrets
local("export HELM_TILLER_SILENT=true && helm tiller run {} -- helm secrets dec {}".format(namespace, secrets_path))

# Convert helm chart to standard k8s manifests
template_script = "helm fetch {}/{} --version {} --untar --untardir {} && helm template {} --namespace {} --name {} -f {} -f {}".format(env["chart_repo"], chart_name, chart_version, charts_path, chart_path, namespace, env["release_name"], values_path, secrets_dec_path)
yaml_blob = local(template_script)

# Clean secrets file
local("rm {}".format(secrets_dec_path))

# Deploy k8s manifests
k8s_yaml(yaml_blob)

dev_config = read_yaml(values_path)

# Port-forward specific resources
k8s_resource('{}-{}'.format(env["release_name"], 'ranking'), port_forwards=['XXXX:XXXX'], new_name="short-name-1")
k8s_resource('{}-{}'.format(env["release_name"], 'some-project-2'), new_name="short-name-2")

if dev_config.get('api-gateway', {}).get('enabled', False):
  k8s_resource('{}-{}'.format(env["release_name"], 'some-project-3'), port_forwards=['XXXX:XXXX'], new_name="short-name-3")

if dev_config.get('frontend', {}).get('enabled', False):
  k8s_resource('{}-{}'.format(env["release_name"], 'some-project-4-1'), port_forwards=['XXXX:XXXX'], new_name="short-name-4-1")
  k8s_resource('{}-{}'.format(env["release_name"], 'some-project-4-2'), new_name="short-name-4-2") 
```

注意事项:

1.  Helm charts 主要负责应用程序打包和管理它们的发布生命周期。我们使用 helm 模板并使用可定制的 yamls 为这些模板提供值。这使我们能够配置他们的核心版本。这包括给容器分配资源，允许一种简单的方式来配置它们连接到哪些服务，它们可以在哪些端口上运行，等等。

2.  Tilt 用于使用提供的 helm 图表设置本地 k8s 开发环境，并将本地代码映射到图表中描述的服务。它提供了这样的功能，我们可以不断地构建 docker 容器并将应用程序部署到 k8s 或执行本地更新(rsync 本地更改到运行的容器中)。用户还可以将应用程序转发到自己的本地实例，以便在开发时访问服务端点。在我们的例子中，我们使用 k8s 清单通过从 helm 图表中提取渲染模板来进行部署。这是由于我们复杂的海图要求，我们无法充分利用 Tilt 提供的舵功能。

3.  如果需要与其他团队成员共享应用程序端点，图表提供了一个统一的机制来创建内部入口端点。

4.  我们的图表是通过通用 helm charts 存储库提供的，因此在生产和开发中，我们使用相同的基本代码(版本化的 docker 映像)、相同的图表模板，但根据我们的需求(部署名称、端点名称、资源、复制等)使用不同的值文件来制作模板。)

5.  我们在每个项目中保持这种做法的一致性，从而提供更加轻松的入职体验，并提高对云资源的可管理性和控制力。

> 任何足够先进的技术都和魔法没什么区别。~亚瑟·C·克拉克。

不过，有一点需要注意的是，魔法也有它的缺点。它通过更有效的资源共享提高了生产率、可靠性并降低了成本。但是，当一些东西坏了，人们看不到它们一定是什么，追踪问题变得很困难，特别是因为事情总是在最不方便的时候失败。因此，尽管我们为自己的工作感到自豪，但我们知道这一事实后仍保持谦逊。

## 优化成本

拥有一个廉价的基础设施和一个网络规模的搜索引擎并不相关，也就是说，有一些方法可以让你省钱。让我们讨论一下我们如何使用基于 K8s 的基础架构来优化成本:

1 .**斑点实例**

*   我们严重依赖于 [AWS spot 实例](https://aws.amazon.com/ec2/spot/)，因为使用它们迫使我们为故障构建系统。但这是值得的，因为它们比[按需实例](https://docs.aws.amazon.com/AWSEC2/latest/UserGuide/ec2-on-demand-instances.html)便宜得多。但是要小心，不要陷入和我们一样的自我伤害。我们太习惯了，以至于有时我们出价高于自己，发生的次数比我们希望的要多。此外，不要耗尽高性能的机器，否则你会陷入与其他公司的竞标战。最后，不要在大型 NLP/ML 会议之前使用 spot GPU 实例。
*   使用 spot 的混合实例池:我们不仅将 Spot 实例用于一次性工作，还用于服务工作负载。我们想出了一个巧妙的策略，我们使用分布在多个可用性区域的混合实例类型(但配置相似)创建一个节点池来运行 kubernetes 资源。这与[点终止处理器](https://github.com/helm/charts/tree/master/stable/k8s-spot-termination-handler)相结合，使我们能够及时将我们的无状态工作负载转移到新创建的或备用容量的点节点，从而避免了潜在的长时间停机。

2 .**共享 CPU 和内存**

由于我们完全致力于 Kubernetes，我们根据需要多少 CPU 或内存以及一项服务需要多少副本来讨论工作负载供应。在这种情况下，如果[请求和限制](https://kubernetes.io/docs/concepts/configuration/manage-compute-resources-container/)相等，我们将获得有保证的性能。但是，如果请求很低，而限制很高，这在零星工作负载的情况下可能很有用，我们可以过度供应并最大限度地利用实例上的资源(减少实例上的空闲资源)。

3 .**集群自动缩放器、垂直和水平 Pod 自动缩放器**

我们部署这些来自动启动和缩减[pod](https://kubernetes.io/docs/concepts/workloads/pods/pod/)的规模，并且只有在需要的时候才会这样做。这意味着当没有工作负载时，只有最小的一组实例在运行，我们不需要手动干预来实现这一点。

4 .**开发环境中的部署缩减**

对于开发环境中的所有服务，我们使用部署[下缩放器](https://github.com/hjacobs/kube-downscaler)在特定时间将 pod 副本下缩放至 0。在我们的应用程序的 kubernetes 清单中使用一个[注释](https://kubernetes.io/docs/concepts/overview/working-with-objects/annotations/)，我们可以指定一个正常运行时间表:

```
annotations:
    downscaler/uptime: Mon-Fri 08:00-19:30 Europe/Berlin 
```

这意味着部署在非工作时间缩减至零。反过来，由于实例上没有活动的工作负载，集群自动缩放器会自动缩减实例。

5 .**成本评估和实例建议——长期成本降低**

在生产中，一旦我们确定了我们的资源利用率，我们就可以选择将被大量使用的实例。我们可以采用[保留实例](https://aws.amazon.com/ec2/pricing/reserved-instances/)定价模式，而不是按需购买，这种模式需要至少 1 年的预付款。反过来，与按需运行实例相比，成本要低得多。

对于 kubernetes，有一些像 [kubecost](https://kubecost.com) 这样的解决方案，它可以随着时间的推移监控使用情况，并在此基础上推荐其他节省成本的方法。它还提供了工作负载的估计价格，因此人们可以对部署系统的总成本有一个大致的了解。在单个界面中，还会通知用户可能不再有用的资源，如 ebs 卷等。

所有这些步骤每年为我们节省数万欧元。对于基础设施费用较高的大型组织，如果执行得当，这些策略平均每年可以轻松节省数百万美元。

## 机器学习系统

[![](../Images/cc6b0a583cbd9de6ddc9c80abc47b558.png)](../../static/img/posts/architecture-of-large-scale-web-search-engine/ml_debt.png)

Figure 5: Hidden Technical Debt in Machine Learning Systems — Sculley et al.<sup class="footnote-ref">[[12]](#fn12)</sup>



有趣的是，我们的 Kubernetes 之旅以最意想不到的方式开始。我们正在探索建立基础设施的想法，这允许我们使用 Tensorflow 运行分布式深度学习实验。在当时，这是一个全新的想法，尽管 Tensorflow 不久前推出了分布式培训，但除了少数资源充足的组织之外，只有少数人知道如何专门针对大型环境运行和管理这种端到端的工作负载。当时还没有云产品可以帮助解决这个问题。

我们开始使用使用 Terraform 部署的分布式设置，但我们很快意识到，如果我们希望将其扩展到组织的所有工程师，这种解决方案有其局限性。同时，我们发现了一些社区贡献，其中通过使用 smart jinja 模板引擎来创建深度学习培训应用程序的分布式部署(参数服务器和工人模式)，生成了普通的 Kubernetes 清单。这是我们与 Kubernetes 的第一次接触。与此同时，我们开始致力于构建近乎实时的搜索，同时尝试最近排名。就在那时，kubernetes 为我们展示了最明亮的一面，我们决定继续深入其中。

作为我们机器学习系统之旅的一部分，就像上面描述的大多数基础设施一样，我们的目标是向整个组织开放它，让所有开发人员更容易在 Kubernetes 上部署应用程序。我们真的希望他们更多地关注解决问题，而不是试图解决与服务相关的基础架构挑战。

但是，从一个人将机器学习应用于他们的问题所获得的所有收益中，我们很快意识到维护机器学习系统是一种真正的痛苦。它比仅仅编写 ML 代码或训练模型要深入得多。即使对于我们这样规模的组织，我们也需要解决其中的一些问题。它们在论文《机器学习系统中隐藏的技术债务》<sup class="footnote-ref">[【12:1】](#fn12)</sup>中有深入的描述。对于任何考虑在生产中大规模依赖和运行机器学习系统的人来说，这是一本好书。在我们的流程中，我们考虑了几种解决方案，例如:

在所有这些产品中，我们发现 **Kubeflow** 最相关、功能最全、性价比最高且可根据我们的需求定制。

前阵子我们也在官方的 [Kubeflow 博客](https://medium.com/kubeflow/)上写下了其中的一些原因<sup class="footnote-ref">[【17】](#fn17)</sup>。除了为我们提供像 TfJob 和 PytorchJob 这样的定制资源来运行我们的培训代码之外，kubeflow 的好处之一就是它开箱即用的出色的[笔记本](https://jupyter.org)支持。

**Kubeflow 用例@ Cliqz**

负责我们的近实时搜索排名的许多功能利用了 Kubeflow 的笔记本。工程师可以在集群中旋转笔记本电脑，并直接接入我们的数据基础设施(批处理和实时流)。这使得共享笔记本和一起处理代码的不同部分变得更加容易。对于工程师来说，实验变得更加容易，因为他们不必重新设置笔记本电脑服务器，提供访问数据基础架构的权限并查看部署的血淋淋的细节，使用简单的 web 界面，人们可以选择笔记本电脑所需的资源(cpu、内存甚至 gpu)，分配 ebs 卷并启动笔记本电脑服务器。有趣的是，一些实验是在低至 0.5 CPU 和 1gb RAM 的笔记本电脑上进行的。通常，这种能力在我们的集群中很容易获得，我们可以轻松地促进这种笔记本的产生，而无需启动新的实例。在不同的环境中，如果来自不同团队的两个工程师在工作，他们很可能会启动他们自己的实例。这导致成本增加和资源利用不足。

此外，可以提交作业，然后这些作业可以用于在笔记本中训练、验证和服务模型。这方面一个有趣的项目是[整流罩](https://github.com/kubeflow/fairing)。

Kubeflow 本身是一个非常全面的计划，我们只是刚刚开始触及它的表面。最近，我们还开始关注一些项目，如 [Katib](https://github.com/kubeflow/katib) (机器学习模型的超参数调整)[KFServing](https://github.com/kubeflow/kfserving)(Kubernetes 上机器学习模型的无服务器推理)[kube flow Pipelines](https://github.com/kubeflow/pipelines)(kube flow 的端到端机器学习管道)和 [TFX](https://www.tensorflow.org/tfx) (创建和管理生产 ML 管道)。我们已经有了一些围绕这些项目的原型，并希望在不久的将来将它们投入生产。

鉴于所有这些好处，我们要衷心感谢 Kubeflow 背后的团队为这个惊人的项目。

…

随着我们越来越依赖机器学习及其变体，我们希望围绕机器学习的过程得到简化，并且总体上更具可重复性。这就是模型跟踪、模型管理、数据版本控制和沿袭变得至关重要的地方。

为了在我们应用定期更新和评估的规模上保持一致，我们需要一个围绕数据管理的解决方案来为生产中的模型提供服务，这有助于在我们的实时生产服务中自动热交换模型和索引。为了解决这个问题，我们构建了一个内部解决方案“Hydra ”,它为下游服务提供了执行数据集发布-订阅的能力。它还确保了 Kubernetes 集群中服务的卷管理。我们将在以后的文章中详细描述这一点。

## 最后的话

> 一旦你成功了，你的下一个目标应该是帮助别人也成功。~凯尔西·海塔尔

设计 Cliqz 既有挑战性，同时也很有趣。我们认为，我们前面还有很长的路要走。随着这一领域的不断发展，有几种可能性和途径可供选择。

尽管 Cliqz 雇用了 120 多名员工，但代码库是由数千名热情的开源开发人员有效开发的，他们分布在全球各地，致力于提供高质量的代码，并为人类构建安全可靠的软件系统。没有他们，我们不可能取得今天的成就。我们衷心感谢开源社区，无论何时我们遇到困难，他们都非常慷慨，乐于为我们提供解决方案。通过这篇文章，我们希望与其他可能有类似问题并正在寻找答案的人分享我们的奋斗、经历和解决方案。本着开放的精神，我们也在尽我们的有限资源做出贡献。

Cliqz 提供的完全私密的搜索服务是我们对关注隐私的网络的贡献，这是一项艰巨但并非不可能的任务。我们邀请您试用我们的[搜索](https://beta.cliqz.com/#channel=blog)，并在[桌面](https://cliqz.com/en/desktop)和[移动](https://cliqz.com/en/mobile)上下载我们的浏览器，成为这项任务的一部分。如果你喜欢解决这样的问题，那就来加入我们吧。

*再见(直到我们再次相见)*

## 备注和参考文献

* * *

分享这篇文章

* * *