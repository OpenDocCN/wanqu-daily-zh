# 经受意外——ACM 队列

> 原文:[http://queue.acm.org/detail.cfm?id=2371516&UTM _ source = Wanqu . co&UTM _ campaign = Wanqu+Daily&UTM _ medium =网站](http://queue.acm.org/detail.cfm?id=2371516&utm_source=wanqu.co&utm_campaign=Wanqu+Daily&utm_medium=website)

<label>September 16, 2012
**[Volume 10, issue 9](issuedetail.cfm?issue=2367376)**</label>

# 经受意外

## 失败是会发生的，复原力训练可以帮助组织做好准备。

### 克里帕·克里希南，谷歌

无论是吹倒电线的飓风，还是让一个大陆的所有航班停飞的火山灰云，或者是啃噬地下纤维的卑微啮齿动物——意想不到的事情都会发生。我们不能做太多来防止它，但是我们可以做很多来为它做准备。为此，谷歌每年都会在全公司范围内开展为期多天的灾难恢复测试活动——DiRT，其目标是确保谷歌的服务和内部业务运营在灾难发生后继续运行。

开发 DiRT 的目的是通过故意在关键系统和业务流程中造成故障来发现其中的漏洞，并在此类故障以不受控制的方式发生之前修复它们。DiRT 通过破坏实时系统来测试谷歌的技术稳健性，并通过明确阻止关键人员、领域专家和领导参与来测试我们的运营弹性。在我们没有弹性但应该有弹性的地方，我们会努力去修正它。(见侧栏，[“谷歌污垢:来自被测试者的观点”，](https://queue.acm.org/detail.cfm?id=2371516#sidebar)汤姆·莱蒙塞利。)

### 设定期望

污垢式事件要想成功，一个组织首先需要接受系统和过程失败作为一种学习的方式。事情*会*出错。当他们这样做时，重点需要放在修复错误上，而不是因为复杂系统的失败而斥责个人或团队。

一个组织还需要相信，从垃圾事件中学习的价值是值得付出的。这些事件并不便宜，它们需要相当大的工程投资，伴随着相当大的生产力中断，并可能导致用户面临的问题或收入损失。例如，污垢涉及数百名工程和操作人员几天的工作，事情并不总是按计划进行。污垢会导致意外停机，在某些情况下还会造成收入损失。然而，由于 DiRT 是一项全公司范围的活动，它有一个好处，那就是一旦出现这类事件，所有合适的人都可以在接到通知后立即控制住。

然而，为了从这种恢复事件中获得最大利益，组织还需要投资于对其服务的持续测试。大型的、肮脏的、全公司范围的事件应该更少地测试常规故障条件，例如单一服务故障转移或随叫随到的切换，而更多地测试复杂的场景或系统和团队之间较少测试的接口。复杂的故障通常仅仅是系统中较小部分的弱点造成的。随着系统中较小组件的不断测试，较大组件出现故障的可能性越来越小。

一个简单的例子是测试组织从数据中心损失中恢复的能力。这种损失可以通过切断设备电源或导致网络链路故障来模拟。理论上，该响应将涉及一系列事件，从将流量从丢失的数据中心重定向到以某种特定顺序进行的一系列单一服务故障转移。然而，阻碍恢复过程的只是核心基础设施服务(如 DNS(域名系统)或 LDAP(轻量级目录访问协议))的单个实例的故障切换。测试此类服务的故障转移可以而且应该连续进行，而不应该必须等待 DiRT 事件。

### 发展计划

开始这种练习的一个好方法是从小处着手，让练习不断发展。从一开始就把它变成一个大而复杂的事情是很容易的，但是这样做可能会带来意想不到的开销和复杂性。

从小处着手不仅适用于参与测试的团队数量，也适用于测试的复杂性。一些容易记住的规则和一个简单的、可重复的练习形式对团队的快速参与大有帮助。如果不是所有的团队都认同，那么就和少数认同的团队一起工作，随着实践证明自己是有用的，会有更多的团队参与进来。(施瓦格也不会疼！)

谷歌的经历就是一个例子:DiRT 最初只专注于测试关键的面向用户的服务。最初的障碍是所有主要的面向用户的团队都编写了测试，并且测试是安全的，不会引起中断，尽管我们确实意识到一些测试不是很有用。这让团队“玩”经过几次迭代，这个练习吸引了更多的团队，并且包含了更少的低质量/低价值的测试。

测试设计也是如此。虽然测试的质量非常重要，并且直接影响到测试的价值，但是灾难恢复测试事件不必从过于复杂的测试或者完美的测试集(不存在)开始。DiRT 从单个团队测试特定于他们服务的故障场景开始。总体“灾难”仅仅是理论上的。在随后的 DiRT 练习中，测试的第一个主要中断是我们的主要源代码控制管理服务器，它暴露了依赖于该系统的几个不可复制的关键功能。当每个部分都被修复后，我们进展到一个更大的灾难，包括海湾地区的一次大地震。

我们模拟了地震，摧毁了该地区的一个数据中心，该数据中心容纳了我们的许多内部系统。虽然这次中断暴露了几个单独托管的服务，但也暴露了其他有趣的依赖关系。例如，为了避免受到停机的影响，一些团队决定将服务从数据中心故障转移到他们的工作站。由于“地震”发生在山景城的谷歌总部附近，测试团队也断开了山景城园区的连接——这意味着所有这些故障转移都失败了。此外，许多人没有预料到的是，数据中心停机导致身份认证系统以意想不到的方式失败，这反过来又将大多数团队锁定在他们的工作站之外。

当工程师们意识到捷径已经失败，没有人可以完成任何工作，他们都同时决定这是一个吃晚饭的好时间，我们结束了我们的咖啡馆。为了与 DiRT 目标保持一致，在下一次测试中修复了其中的一些问题。

如今，生产和内部系统、网络和数据中心运营，以及人力资源、财务、安全和设施等多个业务部门都在进行测试。在最近的污垢演习中，我们在没有通知的情况下摧毁了几个数据中心集群、基础架构中心和办公室。大多数情况都顺利解决了。

值得一提的是，在谷歌考虑 DiRT 这个概念之前，大多数运营团队已经在持续测试他们的系统，并使用基于流行角色扮演游戏的格式进行交叉培训。随着问题的确定，修复被纳入设计过程。对于这些团队中的许多人来说，污垢仅仅提供了一个安全的机会来测试风险更高的故障条件，或者与其他系统和团队的较少测试的交互。

### 测试什么

设计污垢测试时，有几个角度需要考虑。如前所述，最简单的情况是特定于服务的测试。此类别测试服务及其组件是否具有容错能力。这些测试通常是包含在内的，只需要直接的团队做出响应，它们揭示了技术和操作问题，包括文档差距、陈旧的配置或处理关键紧急情况的知识差距。理想情况下，这些测试成为服务的持续测试过程的一部分。

更复杂的技术测试用例会创建并行导致多个系统故障的场景。示例包括数据中心中断、光纤切断或核心基础架构故障，这些都体现在相关服务中。如果设计测试的团队是跨职能的，并且整合了来自公司各个领域的技术领导和主题专家，那么这样的测试会有更大的价值。这些人了解他们的服务的复杂性，并且在列举依赖性和故障模式以便设计现实的和有意义的场景方面处于非常有利的位置。

这类测试的目标是识别服务和团队之间较少测试的接口中的弱点。这样的场景可能有潜在的风险和破坏性，他们可能需要几个团队的帮助来解决错误情况。DiRT 是这类测试的一个很好的平台，因为它是一个全公司范围的练习，并且所有解决问题的必要团队都是随叫随到。

一个经常被忽视的测试领域是业务流程和通信。系统和流程是高度交织在一起的，将系统测试和业务流程测试分开是不现实的:业务系统的失败会影响业务流程，相反，如果没有合适的人员，一个正常工作的系统是没有多大用处的。

前面的“地震”场景暴露了几个这样的例子，其中一些在这里描述:

湾区的消失使山景城的人和人的系统与外界断开了联系。这意味着地理位置分散的办公室中的团队需要为关键操作提供全天候的随叫随到服务。然而，将警报和页面重定向到这些办公室所需的配置更改取决于受停机影响的系统。即使对于完全具有全球专业知识的团队来说，由于这个过程失败，事情也不会进展顺利。

更成功的故障转移是用于内部业务功能的批准跟踪系统。然而，该系统本身是无用的，因为所有的关键审批者都在山景城，因此不可用。不幸的是，他们也是唯一有能力改变审批链的人。

在相同的场景中，我们测试了记录的紧急通信计划的使用。第一次泥土测试显示，在测试的时候，只有一个人能够找到计划并出现在正确的电话桥上。在接下来的演习中，100 多人找到了它。这时我们才知道这座桥容纳不了超过 40 个来电者。在另一次通话中，其中一个打电话的人让桥处于等待状态。虽然等待音乐对灵魂来说是极好的，但我们很快意识到我们需要把人们从桥上赶走的方法。

作为另一个例子，我们模拟了数据中心的长期停电。该试验要求设施长时间依靠备用发电机运行，这反过来又要求购买大量柴油燃料，而不能通过总部通常的审批链。我们希望机构中有人调用我们记录的紧急支出流程，但由于他们不知道在哪里，测试人员创造性地找到了一名员工，他提出将全部六位数的费用记在他的个人信用卡上。大量关于某个东西应该如何工作的文档并不意味着任何人都会使用它，或者如果他们使用它，它就会工作。唯一确定的方法是通过测试。

当然，如果不努力解决测试中出现的问题，测试几乎没有任何价值。一种将失败视为学习手段的组织文化，对于让团队定期发现和解决系统中的问题大有帮助。

### 风险缓解

污垢测试可能具有破坏性，任何时候都可能出现故障。可以采取几个步骤来减少潜在的损害。

至少，所有的测试都需要由一个跨职能的技术团队进行彻底的审查，并伴随着一个在出现问题时进行恢复的计划。如果以前从未尝试过该测试，在沙盒中运行它可以帮助控制影响。然而，沙盒的另一面是，这些环境的配置可能与生产环境中的配置有很大不同，从而导致不太现实的结果。

有不中断服务的测试方法:在谷歌，我们把我们已经知道无法通过某些测试的服务列入“白名单”。本质上，他们已经没有通过测试，当失败的条件已经被很好地理解时，没有理由让他们停机。虽然服务可以“预先通过”并免除自己的责任，但没有“预先通过”测试的概念——服务必须通过“通过”

一个集中配备人员的指挥中心，可以了解和监控在任何给定时间进行的所有测试，使 DiRT 成为一个更安全的测试环境。当不可预见的事情发生时，指挥中心的团队(主要由各个领域的技术专家组成)会介入，恢复测试或修复令人不快的问题。

### 接缝

DiRT 的核心是两个团队:一个技术团队和一个协调团队。

技术团队负责设计所有主要的测试，并评估各个团队编写的所有测试的质量和影响。技术团队还负责实际导致更大的停机，并监控它们以确保事情不会出错。这也是处理测试不可预见的副作用的团队。

协调员处理大部分测试的计划、调度和执行。他们与技术团队紧密合作，以确保测试不会相互冲突，并且每个测试的准备工作(比如设置沙箱)都提前完成。

两支队伍都在泥土指挥中心。执掌大权的人通常拥有足够多的名人录。当没有太多事情发生时，指挥中心充满了干扰；这里住着注意力持续时间短的非常聪明的人，他们睡眠不足，咖啡因摄入过多。然而，当事情出错时——它们确实出错了——它们会保持警惕，有的放矢，并完全专注于灭火和让错误得到沟通、解决或回滚——此外，还会归档进行修复。

指挥中心也是谷歌最有趣的 20%项目之一的人的家:编造和叙述灾难的说书人，从僵尸的攻击到以一个错误的算命师为特色的怪异心理惊悚片。

### 结论

无论其风格如何，灾难恢复测试事件都是在受控环境中发现系统和流程问题的绝佳工具。基本原则是接受失败会发生，组织需要为失败做好准备。通常，一个可靠的执行发起人和支持者有助于为练习设定正确的基调。在谷歌的例子中，运营副总裁 Ben Treynor 支持从持续测试中学习和先发制人地修复故障。

诚然，这些练习需要大量的工作，但是在不受控制的环境中，有机会在故障发生之前识别和修复故障具有不可估量的价值。

爱它，恨它？让我们知道

[【电子邮件保护】](/cdn-cgi/l/email-protection)

Kripa Krishnan 是谷歌的一名技术项目经理，负责公司的灾难恢复项目(DiRT)已经有六年了。她还负责政府工作的谷歌应用程序，并在其他领域工作过，包括存储和计费。她目前正致力于 Google Apps 的隐私和安全基础设施项目。在谷歌之前，Kripa 与科索沃远程医疗项目合作，在该地区建立远程医疗基础设施和虚拟教育网络。在前世，她在印度经营了几年剧院和表演艺术组织。

## 谷歌污垢:来自被测试者的观点

### 不知道僵尸下一次会袭击哪里。

#### 托马斯·利蒙塞利，谷歌

这是从负责运行被测服务的工程师的角度，对 Google DiRT(灾难恢复测试)实践的虚构描述。名字、地点和情况都被改变了。

*【电话铃声】*

**我**喂？

玛丽你好，汤姆。我在监督一次泥地训练。[服务名称]随时待命，对吗？

我是。

**Mary** 在本练习中，我们假设[服务名称]数据库需要从备份中恢复。

我好吧。这是现场演习吗？

玛丽:不，告诉我怎么做。

嗯，我会按照我们运营文件中的指示去做。

玛丽，你能找到那份文件吗？

*【几下按键之后】*

是的，我这里有。

**Mary** 好了，调出服务的克隆，并将数据库恢复到其中。

在接下来的几分钟里，我有了两个发现。首先，文档中的一个命令现在需要额外的参数。其次，用于执行恢复的临时区域没有足够的空间。在编写过程时，它有足够的空间，但是从那时起，数据库一直在增长。

Mary 提交了一份错误报告，请求更新文档。她还提交了一份错误报告，以建立一个进程来防止磁盘空间问题的发生。

我检查了我的电子邮件，看到了来自我们的缺陷数据库的通知。这些漏洞被抄送给我，并被标记为 2011 年的 *DiRT 的一部分，所有带有这个标记的东西都将受到各方的关注，以确保它在接下来的几个月里受到关注。在等待恢复完成时，我修复了第一个 bug。*

第二个 bug 需要更多的时间。我们需要将恢复区域添加到我们的季度资源估计和分配流程中。另外，我们将向我们的监控系统添加一些规则，以检测数据库大小是否接近恢复区域的大小。

**Me** 好了，服务的备份已经读取。我在上面运行一个克隆的服务，我给你发一条即时消息，你可以用它的网址来访问它。

*【几下按键之后】*

玛丽:好的，我可以存取数据了。看起来不错。恭喜你。

**我**谢谢！

玛丽好了，我不打扰你工作了。哦，我不应该告诉你这些，但是在下午 2 点会有一些...好玩。

你知道我下午 3 点下班，对吧？如果你碰巧迟到了一个小时...

玛丽没有这样的运气。我在加利福尼亚，下午 3 点。你的时间是我去吃午饭的时间。

练习结束一分钟后，我收到一封电子邮件，其中有一个练习后文档的链接。我用发生的事情更新它，链接到被归档的错误，等等。我还想到了一些其他的方法来改进这个过程并记录下来，在我们的 bug 数据库中为每一个方法提交特性请求。

下午 2 点，我的呼机没有响，但是我在仪表盘上看到佐治亚州停电了。我们内部聊天室的每个人都在谈论这件事。我不太担心。我们的服务运行在世界各地的四个数据中心，系统已经自动将 Web 请求重定向到其他三个位置。

过渡是完美的，只丢失了“正在进行中”的查询，这完全在我们的 SLA(服务级别协议)范围之内。

我的收件箱里出现了一封新邮件，解释说僵尸已经入侵了佐治亚州，并试图吃掉那里的数据中心技术人员的大脑。僵尸切断了数据中心的网络连接。没有网络流量进出。最后，电子邮件指出，这是一次肮脏演习的一部分，没有真正的技术人员被吃掉大脑，但网络连接确实被禁用了。

*【电话再次响起】*

玛丽你好！开心了吗？

我总是玩得很开心。但我猜你指的是乔治亚州的停电？

玛丽是的。为那些技术人员感到羞耻。

嗯，我认识他们中的很多人，他们都很聪明。那些僵尸

会吃上几个小时。

Mary 您的服务仍在 SLA 范围内吗？

我看了一下我的控制面板，发现三个数据中心执行通常分布在四个位置的工作，延迟略有增加，但在 SLA 范围内。事实是，我不需要查看我的仪表板，因为如果延迟是不可接受的(或者如果不加检查，增长速度将达到不可接受的水平)，我会收到寻呼。

我一切都很好。

很好，因为我是来监督另一场考试的。

**我**一大群丧尸还不够吗？

玛丽:在我的书里没有。你看，你的 SLA 说你的服务应该能够同时经受住两个数据中心的停机。

她是正确的。我们公司的标准是能够同时承受两次停机。原因很简单。数据中心和服务需要能够偶尔停机进行计划维护。在这段时间内，另一个数据中心可能会因意外原因(如僵尸攻击)而停机。能够承受两次同时中断的能力称为 N+2 冗余。

我那你想让我做什么？

**Mary** 假设欧洲的数据中心正在进行定期预防性维护。

我按照我们的程序，暂时关闭了欧洲的服务。来自欧洲客户的网络流量分布在其余两个数据中心。由于这是一次有序的关闭，所以没有丢失任何查询。

**我**搞定！

Mary 你在 SLA 范围内吗？

我看了一下仪表板，发现延迟进一步增加了。整个服务在两个较小的数据中心上运行。两个停机数据中心中的每一个都比合并后的较小的工作数据中心大；然而，有足够的能力来处理这种情况。

我我们只是勉强符合 SLA。

玛丽祝贺你。你通过了。您可以在欧洲数据中心提供服务。

无论如何，我决定提出一个错误。我们留在 SLA 内，但是太接近了，不舒服。我们当然可以做得更好。

我看了看我的时钟，发现已经快下午 3 点了。我完成了练习后文档的填写，就在这时，下一个值班人员上线了。我给她发了一条即时消息，解释她错过了什么。

我还提醒她锁好办公室的门。不知道僵尸下一次会袭击哪里。

Tom Limoncelli 是谷歌纽约办公室的一名网站可靠性工程师。

2012 年 ACM 1542-7730/12/0900 10.00 美元

![acmqueue](../Images/4f57fce9b685ad00824bd02663d98c4d.png)

*原载于《队列》第 10 卷第 9 期*——
见本条目于 [ACM 数字图书馆](https://portal.acm.org/citation.cfm?id=2371516)

* * *

更多相关文章:

Sanjay Sha - [**企业应用程序的可靠性**](detail.cfm?id=3374665)
企业可靠性是一门学科，它确保应用程序将以一致、可预测和经济高效的方式交付所需的业务功能，而不会损害可用性、性能和可维护性等核心方面。本文描述了一组核心原则和工程方法，企业可以应用这些原则和方法来帮助他们驾驭复杂的企业可靠性环境，并交付高度可靠且经济高效的应用程序。

随着 MongoDB 的特性越来越丰富和复杂，开发更复杂的方法来发现 bug 的需求也在增长。三年前，MongDB 在其工具包中添加了一个自主开发的 JavaScript fuzzer，现在它是我们最多产的 bug 查找工具，负责在两个发布周期中检测近 200 个 bug。这些错误跨越了从分片到存储引擎的一系列 MongoDB 组件，症状从死锁到数据不一致。fuzzer 作为 CI(持续集成)系统的一部分运行，它经常在新提交的代码中捕获 bug。

罗伯特·v·宾德，布鲁诺·勒加德，安妮·克莱默 - [**基于模型的测试:它站在哪里？**](detail.cfm?id=2723708)
你可能听说过 MBT(基于模型的测试)，但是像许多没有使用过 MBT 的软件工程专业人员一样，你可能会好奇其他人对这种测试设计方法的体验。从 2014 年 6 月中旬到 2014 年 8 月初，我们进行了一项调查，以了解 MBT 用户对其效率和效果的看法。2014 年 MBT 用户调查是 2012 年类似调查的后续，面向所有评估或使用过任何 MBT 方法的人。它的 32 个问题包括 2013 年高级自动化测试用户会议上分发的一份调查中的一些问题。一些问题侧重于 MBT 系统的效率和效果，提供了经理们最感兴趣的数据。

特里·科塔，迈克尔·多纳特，贾法尔·侯赛因 - [**电子艺界的自动化 QA 测试:由事件驱动**](detail.cfm?id=2627372)
对于数百万游戏极客来说，电子艺界的 QA(质量保证)测试员这个职位一定看起来像是一份梦寐以求的工作。但从公司的角度来看，与 QA 相关的开销看起来非常可怕，尤其是在一个大型多人游戏的时代。

* * *

* * *

[![](../Images/ad65ebb8b75e7581c1bc43a3736aed3c.png)](#) 
ACM 公司版权所有。