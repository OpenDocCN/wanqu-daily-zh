# 基本性能分析如何为我们节省数百万| Heap

> 原文:[https://blog . heapanalytics . com/basic-performance-analysis-saved-us-millions/？UTM _ source = Wanqu . co&UTM _ campaign = Wanqu+Daily&UTM _ medium = website](https://blog.heapanalytics.com/basic-performance-analysis-saved-us-millions/?utm_source=wanqu.co&utm_campaign=Wanqu+Daily&utm_medium=website)

*这是我如何应用基本性能分析技术发现一个小变化的故事，这个小变化使我们的 Postgres 集群的 CPU 使用率提高了 10 倍，并在下一年为 Heap 节省了数百万美元。*

## 为客户分析编制数据索引

Heap 是一个客户分析工具，可以自动捕捉用户与您的网站或应用程序的每次交互。一旦安装在网站上，Heap 将自动跟踪每一次浏览量、点击量、表单提交量等等。从那里，网站的所有者可以使用 Heap 对原始数据的不同子集执行许多不同种类的聚合。

为了能够洞察这些数据，Heap 允许用户根据原始数据定义事件。“登录”就是一个例子，它可以被定义为“在/login 页面上提交表单”。

为了快速进行分析，我们使用了一种非常不寻常的索引策略，它依赖于 Postgres 的部分索引特性。部分索引类似于普通的 Postgres 索引，只是它只包含满足指定谓词的行。你可以把它想象成一个带有 WHERE 子句的常规索引。对于我们的一个客户创建的每个事件定义，我们在该客户的原始事件数据上创建一个部分索引，仅限于匹配定义的行。每当一个新的行被插入到我们的 events 表中时，Postgres 将根据表中每个部分索引的谓词自动测试事件，并将该行添加到必要的索引中。

对于每个事件定义，相应的部分索引使得检索所有匹配的事件非常快，因为索引正好包含满足定义的事件。[如果你想了解更多关于我们如何使用部分索引的信息，你应该阅读我们的博客文章，这篇文章更加深入](https://qa.fictive-heap.net/blog/running-10-million-postgresql-indexes-in-production)。

## 问题:异常高的 CPU 使用率

当我们第一次推出这种索引策略时，我们的 CPU 使用率明显高于我们以前的索引策略。我们认为这是有意义的:我们最大的客户有*千*个这样的索引，为了支持基于 CSS 选择器的过滤器，很多这样的部分索引包含一个正则表达式过滤器。我们认为，由于正则表达式的计算成本相当高，所以在插入每个事件时对一千个正则表达式进行测试会导致 Postgres 使用大量 CPU，这才有意义。没有真正的证据证明这一点，但这成为了 Heap 中每个人对 Postgres 使用如此多 CPU 的解释。我们假设这是索引策略的一个基本权衡。

大约在 10 月份，随着我们的数据量持续增长，我们开始在接收高峰时段到来的所有数据时遇到问题。在某些日子里，一个新事件需要几个小时才能在堆仪表板中显示出来。这对于一个用于实时分析的工具来说是完全不可接受的。我认为我应该尝试优化 Heap 的摄取吞吐量，而不是走典型的路线，花钱解决这个问题。

## 用火焰图可视化 CPU 使用

在此之前，我调试性能问题的经验有限。在谷歌搜索了一会儿后，我在[火焰图](http://www.brendangregg.com/flamegraphs.html)上看到了[布兰登·格雷格的](http://www.brendangregg.com/bio.html)帖子。火焰图是 Brendan Gregg 发明的一种可视化方式，用于快速识别代码的哪些部分占用了 CPU。创建火焰图的第一步是使用 Linux perf 工具对进程堆栈进行采样:

性能记录-p $(进程的 PID)-f99-g-睡眠 60

这将在 60 秒内以每秒 99 次的速度对给定进程的堆栈进行采样，并将数据写入名为 perf.data 的文件中。从那里，您可以从 [Brendan Gregg 的火焰图形库](https://github.com/brendangregg/FlameGraph)中运行以下命令来处理文件并生成火焰图形:

性能脚本|。/stack collapse-perf . pl > out . perf-folded。/flame graph . pl out . perf-folded > flame-graph . SVG

我创建的第一批火焰图之一是 Postgres 后端进程。由于我们使用连接池，单个后端进程将服务于多个查询。由于我们运行的绝大多数查询都是插入，Postgres 后端进程的火焰图可以让我们很好地了解将事件插入数据库时 CPU 的使用情况。在我从 pg_stat_activity 获得的 Postgres 进程的 pid 上运行上述命令后，我获得了下面的火焰图:



您可以点按图像以在新标签中打开它，然后点按矩形以放大。将鼠标悬停在一个矩形上会弹出关于该矩形的一些信息。对于门外汉来说，火焰图可能很难理解。布伦丹·格雷格给出了以下解释来解释这一点:

*x 轴显示堆叠剖面总体，按字母顺序排序(不是时间的推移)，y 轴显示堆叠深度。每个矩形代表一个堆栈框架。框架越宽，它出现在堆栈中的次数就越多。顶部边缘显示了 CPU 上的内容，下面是它的祖先。颜色通常不重要，随机选取以区分帧。*

从火焰图中可以很清楚地看出，大约 55%的 CPU 时间花在了 ExecOpenIndices 上(图中右侧的黄色大条)。稍微查看一下火焰图，就会发现大部分时间是在两个不同的函数之间分配的，BuildIndexInfo 和 index_open。BuildIndexInfo 调用了大约 20%的 CPU 时间。看起来大部分时间都花在了 relationship index 上。

查看 RelationGetIndexPredicate 的[源代码，似乎它的目的是解析和优化部分索引谓词。在 RelationGetIndexPredicate 上花费这么多时间是有道理的，因为解析一个任意的表达式比计算一个已经解析过的表达式要困难得多。](https://github.com/postgres/postgres/blob/REL9_5_STABLE/src/backend/utils/cache/relcache.c?ts=4#L4109-L4176)

现在让我们看看在 ExecOpenIndices 中花费的剩余时间。剩下的时间大部分花在 index_open 上。看起来好像 index_open 调用了 relation_open，后者又调用了 RelationIdGetRelation。[来自源代码](https://github.com/postgres/postgres/blob/REL9_5_STABLE/src/backend/utils/cache/relcache.c?ts=4#L1715-L1772)中 RelationIdGetRelation 的文档，其目的是查找不同关系的元数据。(在这种情况下，它主要用于查找部分索引。)根据花费在 relationgetindex 和 RelationIdGetRelation 上的时间，似乎 **Postgres 花费在获取和解析部分索引谓词上的时间比评估它们的时间多得多**。

## 实施修复

查看这些不同函数的源代码，会发现正在进行大量的缓存。在 RelationGetIndexPredicate 中，Postgres 首先检查它是否已经提取了谓词，并立即返回它。

RelationIdGetRelation 首先使用 [RelationIdCacheLookup](https://github.com/postgres/postgres/blob/ee6922112e9b3c02b995bd1d838c9a261f060133/src/backend/utils/cache/relcache.c?ts=4#L202-L212) 来检查关系元数据是否已经被计算和缓存。似乎在正常情况下，索引元数据将被提取和解析一次，然后在其余时间从缓存中读取。

对我们来说不幸的是，如果你一次写一个事件到成千上万个不同的表中，缓存不能很好地工作。Postgres 有一个用于服务查询的进程池，每个进程都有自己的缓存。每个插入都在这些过程中被分配循环。当一次插入一个事件时，对于具有成千上万个底层表的分片模式，不太可能由同一个进程处理两个对同一个表的插入。这意味着索引元数据几乎不会在执行插入的进程中被缓存。因此，对于我们插入的几乎每个事件，Postgres 都需要获取并解析一次目标表的索引元数据。

这表明我们可以做一个简单的改变:**我们可以批量插入许多事件到同一个表**，而不是单独插入所有的事件。通过使用一个命令插入多个事件，Postgres 只需要每批获取和解析一次索引元数据。我们以前考虑过批处理插入，以减少事务数量，但从未想过节省 CPU 资源，因为我们假设所有的 CPU 都用于评估索引谓词。

批量插入的初始基准显示 CPU 使用率降低了 10 倍。一旦我们获得了这些结果，我们就开始在生产中测试批量插入。最终，当使用平均大小约为 50 个事件的批次时，我们确实获得了大约 10 倍的摄取吞吐量提升。下面是我们部署批处理前后不同 kafka 分区的接收延迟:



左边的单位是小时潜伏期。我们能够在几分钟内处理完大约一个小时的积压工作。

部署批处理后，我拍摄了另一张插入的火焰图:



这一次，似乎大部分时间都花在了 ExecQual(中间的红色条)上，它基于源代码的[，是用于计算部分索引谓词的函数。这意味着 Postgres 现在花费了大部分 CPU 来执行评估部分索引谓词的实际工作。](https://github.com/postgres/postgres/blob/REL9_5_STABLE/src/backend/executor/execQual.c?ts=4#L5242-L5332)

我是六个月前发现的。从那以后，我们不需要向我们的集群添加任何额外的 CPU，看起来在接下来的几个月里也不需要！我能够仅使用基本的性能分析技术找到这个成功之处。找到 10 倍胜率真的不需要太多。

顺便说一下，如果你有兴趣做这种工作，我们正在招聘！在此申请或在 twitter 上联系。

**附加资源:**





