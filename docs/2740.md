# 通过机器学习提高销售额| Per Harald Borgen | Xeneta | Medium

> 原文：<https://medium.com/xeneta/boosting-sales-with-machine-learning-fbcf2e618be3?utm_source=wanqu.co&utm_campaign=Wanqu+Daily&utm_medium=website>



# 利用机器学习提高销售额

## 我们如何使用自然语言处理来确认销售线索

在这篇博文中，我将解释我们如何通过训练机器学习算法来预测基于公司描述的销售线索的质量，从而使我们在 [Xeneta](http://www.xeneta.com) 的销售过程更加有效。

如果你想立即查看这个脚本，请访问 [GitHub](https://github.com/xeneta/LeadQualifier) ,并随时提出改进建议，因为它还在不断开发中。

# 问题是

它始于业务发展代表 Edvard 的一个请求，他已经厌倦了执行单调乏味的任务，即浏览写满公司名称的大 excel 表格，试图确定我们应该联系哪些公司。



An example of a list of potential companies to contact, pulled from sec.gov



这种对销售线索的**的资格预审可能需要几个小时，因为它迫使销售代表搞清楚每家公司都做些什么(例如，通过在 LinkedIn 上阅读它们)，这样他/她就可以有资格猜测这家公司是否非常适合我们的 SaaS 应用程序。**

**你如何做出一个符合条件的猜测？要理解这一点，你首先需要知道我们是做什么的:**

> **本质上，Xeneta 通过提供**海运市场情报，帮助运输集装箱的公司发现节约潜力。****



**This customer had a 748K USD saving potential down to market average on its sea freight spend.**



**更具体地说，如果您的公司每年装运超过 500 个集装箱，您很可能会发现使用 Xeneta 的巨大节约潜力，因为我们能够准确地告诉您您在哪里支付了高于市场平均价格的**。****



**This widget compares a customers’ contracted rate (purple line) to the market average (green graph) for 20 foot containers from China to Northern Europe.**



**这意味着我们的目标客户彼此大相径庭，因为他们唯一的共同点是他们多少都参与了海运。以下是我们针对的公司类别的一些示例:**

*   **汽车的**
*   **货运代理**
*   **化学品**
*   **消费和零售**
*   **低价商品**

# **假设**

**虽然在寻找线索时，广泛的客户范围是一个挑战，但我们通常能够通过阅读 Xeneta **对某家公司的描述来判断该公司是否感兴趣，因为它通常包含他们是否参与向世界各地发送信息的暗示。****

**这让我们思考:**

> **给定一个公司描述，我们能训练一个算法来预测它是否是一个潜在的 Xeneta 客户吗？**

**如果是这样的话，这种算法可以为销售团队节省大量时间，因为它可以在他们开始手动确认销售线索之前对 excel 表格进行粗略排序。**

# **发展**

**当我开始研究这个时，我很快意识到机器学习部分不是唯一的问题。我们还需要一种获取公司描述的方法。**

**我们考虑抓取这些公司的网站，并获取关于我们的*部分。但是这听起来像是一个混乱的、不可预测的和耗时的活动，所以我们开始寻找 API 来代替。经过一番搜索，我们发现了 [FullContact](http://www.fullcontact.com) ，它有一个公司 API，为你提供数百万家公司的描述。***



***然而，他们的 API 只接受公司的 URL 作为输入，这在我们的 excel 表格中很少出现。***

***因此，我们必须找到一种方法来获取 URL，这使我们进入了以下工作流程:***

*   ***使用 Google API 搜索公司名称(hacky，我知道…)***
*   ***遍历搜索结果，找到最可能正确的 URL***
*   ***使用此 URL 查询 FullContact API***

***当然，每一步都会有损失，所以我们要找到一个更好的方法。然而，这足以检验这个想法。***

# ***数据集***

***有了这些脚本，下一步就是创建我们的训练数据集。它需要包含至少 1000 家**合格**公司和 1000 家**不合格**公司。***

***第一类很简单，因为我们可以简单地从 SalesForce 导出 1000 个 Xeneta 用户的列表。***

***然而，找到 1000 个不合格的公司有点困难，因为我们不会跟踪那些我们已经避免联系的公司。于是爱德华手动**取消了** 1000 家公司的资格。***

# ***清理数据***

***完成这些后，是时候开始编写自然语言处理脚本了，第一步是清理描述，因为它们非常脏，包含了许多不相关的信息。***

***在下面的例子中，我将介绍我们目前正在应用的每一种清理技术，并向您展示一个**原始描述**是如何作为一个**数字数组结束的。*****



***An example of a raw description.***



## ***正则表达式***

***我们做的第一件事是使用正则表达式去掉非字母字符，因为我们的模型只能学习单词。***

```
***description = re.sub(“[^a-zA-Z]”, “ “, description)***
```



***After removing non-alphabetical characters.***



## ***史泰克***

***我们也是词干。这意味着减少同一个单词的多个变体。因此，我们没有接受像**制造商、制造、制造&制造、**这样的词，而是把它们简化为**制造。*****

```
***from nltk.stem.snowball import SnowballStemmer
stemmer = SnowballStemmer(‘english’)
description = getDescription()description = [stemmer.stem(word) for word in description]***
```



***After stemming the words.***



## ***停止言语***

***然后，我们使用自然语言工具包删除停用词。停用词是与文本的概念理解关系不大的词，如 ***is，to，for，at，I，it 等。******

```
**from nltk.corpus import stopwords
stopWords = set(stopwords.words('english'))
description = getDescription()description = [word for word in description if not word in stopWords]**
```



**After removing stop words.**



# **转换数据**

**但是清理和堵塞数据实际上不会帮助我们进行任何机器学习，因为我们还需要将描述转换成机器可以理解的东西，即数字。**

## **一袋单词**

**为此，我们使用单词袋(BoW)方法。如果你不熟悉 BoW，我会推荐你阅读这个 Kaggle 教程。**

**BoW 是一种将**文本短语转换成向量**的简单技术，其中向量中的每一项都代表一个特定的单词。 [Scikit learn 的计数矢量器](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html)给你一个超级简单的方法来做到这一点:**

```
**from sklearn.feature_extraction.text import CountVectorizervectorizer = CountVectorizer(analyzer = ‘word’, max_features=5000)
vectorizer.fit(training_data)
vectorized_training_data = vectorizer.[transform](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html#sklearn.feature_extraction.text.CountVectorizer.fit_transform)(training_data)**
```

****max_features** 参数告诉矢量器你希望我们的词汇表中有多少单词。在这个例子中，矢量器将包括在我们的数据集中出现最频繁的 5000 个单词，并拒绝其余的单词。**



**An example of a very small (35 items) Bag of Words vector. (Ours is 5K items long).**



## **Tf-idf 转换**

**最后，我们还应用了一个 **tf-idf** 变换，它是**词频逆文档频率的缩写。**这是一种调整文档中不同单词重要性的技术。**

**更具体地说，tf-idf 将强调在描述中频繁出现的词(**术语频率**)，而不强调在整个数据集中频繁出现的词(**逆文档频率**)。**

```
**from sklearn.feature_extraction.text import TfidfTransformer
tfidf = TfidfTransformer(norm=’l1')tfidf.fit(vectorized_training_data)
tfidf_vectorized_data = tfidf.transform(vectorized_training_data)**
```

**同样， [scikit learn](http://scikit-learn.org/stable/) 通过提供现成的 tf-idf 挽救了局面。只需**将**模型拟合到你的矢量化训练数据，然后使用**变换**方法对其进行变换。**



**The vector after applying tf-idf. (Sorry about the bad formatting)**



# **该算法**

**在所有数据被**清理**、**矢量化**、**转换**之后，我们终于可以开始做一些机器学习了，这是这个任务最简单的部分之一。**

**我先把数据切片成 70%的训练数据和 30%的测试数据，然后开始用两个 [scikit learn](http://scikit-learn.org/stable/) 算法:[随机森林](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) (RF)和 [K 近邻](http://scikit-learn.org/stable/auto_examples/neighbors/plot_classification.html) (KNN)。很快就清楚了，RF 优于 KNN，因为前者很快达到 80%以上的准确率，而后者停留在 60%。**

**拟合 scikit 学习模型非常简单:**

```
**def runForest(X_train, X_test, Y_train, Y_test):
 forest = RandomForestClassifier(n_estimators=100)
 forest = forest.fit(X_train, Y_train)
 score = forest.score(X_test, Y_test)
 return scoreforest_score = runForest(X_train, X_test, Y_train, Y_test)**
```

**因此，我继续研究 RF，看看通过调整以下参数可以提高多少精度:**

*   ****词汇:**计数矢量器在词汇中包含多少个单词(目前为 5K)**
*   ****克数范围:**要包含在单词包中的短语的大小(当前为 1-3，表示最多 3 个单词-短语)**
*   ****估计量:**随机森林中包含的估计量(目前为 90)**

**通过调整这些参数，该算法在测试数据集上达到了 86.4%的准确率，并且实际上开始对我们的销售团队有用。**

# **前方的路**

**然而，剧本并没有完成。有很多方法可以改进它。例如，该算法很可能偏向于我们目前在训练数据中的那种描述。在更多真实数据上测试时，这可能会成为性能瓶颈。**

**以下是我们考虑在未来开展的几项活动:**

*   **获取更多数据(抓取、其他 API、改进数据清理)**
*   **测试其他类型的数据转换(例如 word2vec)**
*   **测试其他最大似然算法(如神经网络)**

**如果你想了解进展，我们会定期推送至 GitHub。如果你有什么想补充的，欢迎在下面留下你的评论。**

**干杯，**

**[Per Harald Borgen](http://www.twitter.com/perborgen)**



