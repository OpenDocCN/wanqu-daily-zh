# 21 世纪的大问题:你信任谁的黑匣子？奥莱利

> 原文：<https://www.oreilly.com/ideas/the-great-question-of-the-21st-century-whose-black-box-do-you-trust?utm_source=wanqu.co&utm_campaign=Wanqu+Daily&utm_medium=website>

<aside class="post-note post-note-intro">

2016 年 Next:Economy 峰会探讨了技术驱动的算法在塑造我们的社会中的作用，以及如何负责任地使用它们。[访问 Safari 查看活动](https://www.safaribooksonline.com/library/view/nexteconomy-summit-2016/9781491976067/?utm_source=oreilly&utm_medium=newsite&utm_campaign=whose_black_box_do_you_trust_text_cta)的全部演讲。

</aside>

几年前，大型综合医疗服务提供商 Kaiser Permanente 的首席医疗信息官 John Mattison 对我说，“21 世纪最大的问题将是‘你信任谁的黑匣子？’“Mattison 谈到了算法在医学中日益增长的重要性，但更广泛地说，他的观点是，我们越来越信任那些我们不理解其决策方法的系统。(一个[黑盒](http://en.wikipedia.org/wiki/Black_box)，根据定义，是一个输入和输出已知的系统，但是通过哪个系统把一个转换成另一个是未知的。)

人们非常关注算法在塑造消费者体验方面的作用。很少有人关注算法在形成商业决策激励方面的作用。

## 学得更快。深入挖掘。看得更远。

例如，多年来，人们一直对算法如何塑造我们从谷歌或脸书看到的新闻感到绝望。伊莱·帕里泽(Eli Pariser)警告了一个“[过滤泡沫](http://en.wikipedia.org/wiki/Filter_bubble)”，在这个泡沫中，算法会考虑我们的偏好，并继续向我们提供更多我们已经想听的东西，而不是让我们接触其他观点。这是一个真实的风险——尽管搜索引擎和社交媒体公司正在努力克服。

但在我最近与 VentureBeat 的克里斯·奥布莱恩的一次谈话中，我发现了一个更深层、更普遍的风险。这也是算法塑造作家和出版商选择的方式。你会写并发布你认为最有新闻价值的东西，或者在社交媒体上最受关注的东西吗？你是使用最能体现主题的格式(一篇深刻、权威的研究，所谓的“长阅读”)，还是决定用简短有力的文章来获得关注，从而获得更高的浏览量和更多的广告费，这样更有利可图？你会选择视频而不是文本吗，即使文本能让你做得更好？

从搜索引擎和社交媒体获得关注的需求可以说是新闻媒体变得低俗的一个因素，这种报道风格导致甚至伟大的出版物形成了一种炒作文化、[虚假争议和其他增加流量的技术。](http://www.washingtonpost.com/posteverything/wp/2016/09/06/why-hillary-clintons-perceived-corruption-seems-to-echo-louder-than-donald-trumps-actual-corruption/?utm_term=.e81189eb3662)[美国总统大选报道中的竞争垫底](http://www.vox.com/2016/9/12/12887522/donald-trump-interview-shocking-numb)是新闻业收入从订阅到广告，从本地读者的安全基础到通过社交媒体追逐读者的主要转变的牺牲品。如果你想生意兴隆，你必须取悦算法。

奥布莱恩还谈到了今天的媒体记者在导航算法的竞争需求方面遇到的困难，这些算法决定了他们的故事是否会被看到。你会优化谷歌搜索结果或脸书新闻结果吗？当两种不同算法的需求发生冲突时，或者当它们突然改变时，会发生什么？

当谷歌是城里唯一的游戏时，搜索引擎优化(SEO)相当简单。谷歌提供了丰富的工具来帮助网络出版商理解它的算法重视什么样的东西，以及什么样的东西会发出危险信号。有一整个行业致力于帮助网络出版商做正确的(“白帽 SEO”)和另一个致力于帮助肆无忌惮的出版商绕过规则(“黑帽 SEO”))黑帽 SEO 的一种形式是开发“[内容农场](http://en.wikipedia.org/wiki/Content_farm)”，大量交叉链接的低质量内容(通常是从其他网站上搜集来的)欺骗算法，让它们认为自己受到了高度重视。[2011 年，当谷歌重新调整其算法](http://searchengineland.com/library/google/google-panda-update)以降低内容农场的等级时，许多一直遵循这一做法的公司受到了严重伤害。[许多人倒闭了](http://searchengineland.com/google-panda-two-years-later-losers-still-losing-one-real-recovery-149491)(他们也应该倒闭)，其他人不得不改善他们的商业行为以求生存。

针对脸书的出版商最近经历了类似的经历，脸书上个月宣布,[更新其新闻订阅算法，以减少“点击诱饵”标题](http://newsroom.fb.com/news/2016/08/news-feed-fyi-further-reducing-clickbait-in-feed/)(用实际文章内容未兑现的承诺来戏弄用户的标题)的报道。脸书的目标值得称赞，就像谷歌一样:创造更好的用户体验。正如脸书研究员 Alex Peysakhovitch 和 Kristin Hendrix 在声明中写道:“我们的新闻订阅价值观之一是在我们的平台上进行真实的交流。…这就是为什么我们努力了解人们认为什么类型的故事和帖子是真实的，这样我们就可以在新闻提要中展示更多的故事和帖子。我们还努力了解人们发现哪些类型的故事是误导性的和垃圾的，以帮助确保人们更少看到这些内容。”

正如沃伦·巴菲特(Warren Buffet)[说过的话](http://www.goodreads.com/quotes/148174-it-takes-20-years-to-build-a-reputation-and-five)，“建立一个声誉需要 20 年，毁掉它只需 5 分钟。如果你考虑到这一点，你会以不同的方式做事。”谷歌和脸书都明白，他们的声誉取决于人们能否找到他们想要的东西。两者都使用“长点击”和“短点击”的概念作为衡量的一种方式。(如果有人点击了一个链接，然后马上回来，他们并不觉得很有趣。如果他们离开一段时间，然后回来，他们很可能花了一些时间仔细研究结果。这是一个很好的信号，表明他们认为这是值得的。)

在这里，我们得到了黑盒位。据 TechCrunch 报道，脸书新闻订阅产品管理副总裁 Adam Mosseri 表示，“脸书不会公开发布定义 clickbait 的多页指导文件，因为‘其中很大一部分实际上是垃圾邮件，如果你披露我们正在做什么以及我们是如何做的，他们会对其进行逆向工程，并找出如何绕过它。’"

因为许多塑造我们社会的算法都是黑盒——要么是因为脸书列举的那些原因，要么是因为在深度学习的世界中，它们甚至对它们的创造者来说都是不可思议的——所以信任问题是关键。

在不知道算法遵循的确切规则的情况下，理解如何评估算法是当今世界的一个关键学科。这是可能的。以下是我评估一个算法是否可信的四条规则:

1.  它的创造者已经清楚地表明了他们所寻求的结果，外部观察者有可能证实这一结果。
2.  成功是可以衡量的。
3.  算法创建者的目标与算法消费者的目标是一致的。
4.  这种算法能让它的创造者和使用者做出更好的长期决策吗？

让我们考虑几个例子。

## 谷歌搜索和脸书新闻

继续上面的讨论，你可以看到我的四个原则在谷歌搜索和脸书新闻中的应用:

1.  预期结果的清晰度。谷歌和脸书都明确表示，他们的算法优先考虑用户的利益，而不是广告商或出版商的利益。因为目标是明确的，所以当看起来不是这样时，很容易提出问题。语句的清晰性使得评估算法是否达到目标变得更加容易。
2.  可测量性。硅谷公司已经把 A/B 测试和寻找方法来衡量他们的算法何时达到目标变成了一门艺术。例如，谷歌有一个搜索质量团队，使用数千名“机械土耳其人”风格的评论者对搜索结果表示赞成或反对，但他们更重要的衡量标准是基于实际用户行为的，如长时间点击与短时间点击，或者人们是首先点击顶部结果，还是第二次，还是第十次。就广告而言，谷歌通过提供广告工具和商业模式来建立信任，广告工具可以估计广告将获得多少点击量，而商业模式实际上只对点击量收费。这种可衡量性推动了谷歌的财务成功，因为点击付费广告模式比之前的页面浏览量付费模式更容易衡量。(值得注意的是，脸书没有同样的点击付费模式；他们甚至不提供等同于页面浏览量的数据，而是提供“覆盖范围”——定义为你的帖子出现在哪个新闻源的人数。它是否被看见还不知道。它们也提供了一个参与度的指标——点击、分享或以其他方式对你的帖子做出反应的人。)
3.  目标一致。从长远来看，谷歌或脸书和他们的用户有相当高的目标一致性。如果他们总是向用户展示他们不想看的内容，这些用户最终会停止使用这项服务。这些服务和他们的广告商之间也有相当高的目标一致性。如果广告不兑现，顾客将不再购买。但是服务和内容发布者之间存在潜在的目标分歧。有强烈的动机操纵系统以获得更大的可见性，即使制作的内容对用户来说不是最佳的。谷歌与内容农场、脸书和其他拥有 clickbait 标题和列表文章的社交媒体一起面对这个问题。算法经理的工作就是调整算法来处理这些对立的力量，就像飞机自动驾驶仪的设计者必须设计算法来处理不断变化的天气条件一样。
4.  长期决策。平台目标和用户目标之间的一致性在短期内保持不变。但这种情况会长期持续下去吗？

## 自动驾驶汽车

随着对自动驾驶汽车和卡车的狂热，人们很容易忘记我们已经有很长一段时间基本上自动驾驶的飞机了。任何会飞的人都把自己的生命托付给了机器人。是的，机舱里有飞行员，但他们并不像你想象的那样经常驾驶飞机。他们扮演着“机器人监督人和后备机制”的角色飞行员还没有被替换；他们被提升为经理。他们做出行政决策，如“让我们改变高度或路线，因为空中交通管制报告前方天气恶劣”或“我们有一个医疗紧急情况，所以我们需要在最近的机场降落，可以容纳我们的飞机。”对于军用无人机，这些监管人员仍然存在。他们就在地面上，可能在几千英里之外。

如果几个月前你和我一样，你可能会认为自动驾驶有点像巡航控制——它让飞机在漫长无聊的路段飞行，而飞行员则负责起飞和着陆等困难的事情。并非如此。在去蒙特利尔参加 StartupFest 的路上，我和一名飞机驾驶员进行了长时间的交谈(甚至坐在副驾驶的位置上，感受自动驾驶仪对控制装置的细微调整，以保持飞机始终在航线上。)

![](img/7e08085ad8222ebf7587527e4c2d441d.png)

Figure 1\. Image courtesy of Tim O’Reilly.



飞行员告诉我的事情令人大开眼界，与我预期的正好相反。“我们不可能在旧金山这样繁忙的机场手动起飞或降落。如果你不准时或者不在正确的高度，你就会给其他人带来麻烦。”“什么时候手动飞行？”“当周围没有其他人的时候。”

让我们对飞机自动驾驶仪进行四项测试:

1.  预期结果的清晰度。让飞机沿着预定的路线从 A 点到 B 点。根据已知的航空原理，对风和天气做出正确反应。针对繁忙机场的拥堵情况进行优化。不要撞车。
2.  成功是可以衡量的。这些成果的实现是由大量传感器和控制装置组成的，这些传感器和控制装置允许自动驾驶仪对来自这些传感器的实时数据做出反应。全球定位系统。高度传感器。空速。态度。湍流。最终的衡量标准是飞行的成功:飞机的实际行为与物理和航空法则之间的一致性。无论何时出现故障(出于任何原因——人为、机械或“天灾”)，国家运输安全委员会[都会深入分析原因并改进流程，以降低相同事故再次发生的可能性。](http://en.wikipedia.org/wiki/National_Transportation_Safety_Board)
3.  目标一致。没有乘客会反对这些目标:不要撞车。在最短的时间内把我送到那里。给我一个平稳的旅程。但乘客可能会反对航空公司优化油耗而不是旅行时间的决定。飞行员也不太可能与夺走他们工作的目标保持一致。
4.  长期决策。从长远来看，飞机所有者和飞行员之间，或者航空公司所有者和社会之间的目标可能会有一点曙光。例如，飞行员可能会正确地认为，过多使用自动驾驶仪会剥夺他们必要的经验，增加他们意外地必须手动驾驶飞机时坠毁的可能性。将飞机升级为完全自主的成本也可能令人望而却步。事实上，我们仍然有飞行员在飞机上，这可能证明了更换高成本设备需要很长时间，也证明了公众的恐惧和航空公司飞行员协会为捍卫其成员的工作所做的工作。

自动驾驶汽车和卡车也可以进行同样的分析。目标很明确:避免所有事故，比任何人类驾驶员都更安全地驾驶。目标是可以衡量的，实现目标的系统越有机会学习就会变得越好。正如自动驾驶汽车行业之父之一的巴斯蒂安·特龙在去年我的 Next:Economy 峰会上所说的那样，自动驾驶汽车比任何人都学得快，因为每当其中一辆车犯了错误，错误和避免错误的方法都可以传递给其他车辆。

在自动驾驶汽车和卡车的情况下，我们可以看到争论最终很可能出现在测试 3 和 4 中。我怀疑，自动驾驶汽车技术的采用推迟主要不是因为安全问题或算法的可证明成功，而是因为改变汽车和卡车的巨大安装基础的成本，以及以驾驶为生的人将继续需要保持“人在循环中”的论点。

我们越早接受每个人在确定自动驾驶汽车是否安全方面都有共同利益，我们就可以开始讨论需要共享哪些数据，以便对这个问题得出客观的答案。然后我们可以开始讨论我们可能需要考虑的其他目标。一旦我们理解了算法的支持者和批评者的目标不一致的地方，我们就可以就哪个目标最有意义展开真正的争论。在许多领域，这种争论发生在市场中，发生在集体表现为亚当·斯密的“看不见的手”的伟大斗争中。但通常情况下，它是以政府监管的形式出现的。

## 监管新技术

仔细想想，政府法规也是一种算法，一套规则和程序，用于实现应该是确定的结果。不幸的是，政府法规经常不能通过我关于你是否可以信任一个算法的四项测试。

1.  预期结果的清晰度。当法规颁布时，通常会说明其预期结果。只是很少以一种容易理解的方式完成。像英国政府数字服务和美国消费者金融保护局这样的新机构已经[将简明语言作为优先事项](http://www.consumerfinance.gov/plain-writing/)，并且已经证明可以创建目标和实现与谷歌搜索质量或 Adwords 质量的目标和实现一样清晰的法规。但这种清晰是罕见的。
2.  成功是可以衡量的。规章很少包括任何衡量或确定其效果的规定。即使进行了测量，也只是几年后的事。
3.  目标一致。监管者和消费者的目标通常是一致的——例如，想想 1911 年三角内衣厂火灾后制定的消防法规。在我的 2009 年 [Gov 2.0 峰会](http://www.gov2summit.com/gov2009)上，卡尔·马拉默德做了一个[的精彩演讲](http://chimera.labs.oreilly.com/books/1234000000774/ch03.html)，讲述了纽约市血汗工厂火灾在安全法规发展中的作用。一次会议演讲很少能得到起立鼓掌。这是其中一个演讲。[视频在这里](http://youtu.be/9E43_fdhu-o?t=3m46s)。)但通常情况下，监管服务于政府的需求，而不是公民或那些有权参与监管过程的人的需求。政策制定者已经开始接受这样一种观点，即制定规则是为了平衡各方的利益冲突，而不是为了服务公众——我仍然记得我与前众议院议长南希·佩洛西(Nancy Pelosi)关于 2011 年《制止网络盗版法案》(Stop Online Piracy Act)的一次谈话。我把反对它的理由说成是糟糕的公共政策，但她的回应告诉我，真正的决策标准是什么:“我们必须平衡科技行业的利益和好莱坞的利益。”
4.  长期决策。随着时间的推移，规章制度与社会需求不合拍。当监管没有达到预期效果时，它们通常会继续存在。新的法规往往只是简单地堆在它们上面。

先说个好例子。在 CFPB 关于发薪日、车辆所有权和某些高成本分期贷款的监管提案中，我们看到了监管的明确理由:

> “该局担心，提供担保贷款的贷款人开发了与其他信贷市场做法大相径庭的商业模式，因为他们未能评估消费者偿还贷款的能力，并在试图从消费者账户中提款的过程中从事有害的做法。该局认为，与这些担保贷款相关的消费者损害的可能性很高，因为许多消费者难以偿还贷款。特别是，许多获得担保贷款的消费者似乎缺乏偿还贷款的能力，当支付不起的贷款到期时，他们面临三种选择之一:获得额外的担保贷款，违约担保贷款，或支付担保贷款，但无法满足其他主要的财务义务或基本生活费用。许多贷款人可能会寻求直接从消费者账户中获得担保贷款的还款。该局担心，当贷款人多次试图从消费者账户中提取资金未果时，消费者可能会遭受多项费用和其他损害。”

该提案接着详细说明了旨在解决这一赤字的规则。CFPB 还建立了衡量和执行机制。

相比之下，看看纽约市对出租车和豪华轿车司机的规定。他们的目标陈述含糊不清，范围令人麻木。我要求任何人提出一种方法，通过这种方法可以评估这些规则是否达到了预期的结果。

最近，当我乘坐 Lyft 从纽瓦克机场飞往曼哈顿时，我想到了这一点。像往常一样，我就司机的工作采访了他。在其他问题中，我问他，他把我放下后会不会在曼哈顿接乘客，或者回新泽西。“我没有在曼哈顿搭载乘客的执照，”他告诉我。

想一想这个问题。给优步、Lyft 和出租车司机发执照的可能目标是什么？乘客安全。保护乘客免受价格欺诈。减少拥堵。(后两个目标是 1637 年国王查理一世在伦敦颁布第一部出租车条例的原因。)禁止 Lyft 司机在新泽西和纽约搭载乘客并不能实现这些目标。鉴于按需汽车服务(以及最终的按需自动驾驶汽车)等新技术有机会重塑城市交通选择，监管目标很容易落后于社会优先事项。我们有机会使用这些技术来改善交通，降低消费者的成本，减少拥堵和停车需求，改善环境，以及其他许多可以提出、衡量和实现的目标。

传统上导致对出租车进行地理限制的一个目标是通过限制可用司机的数量来支持现有的运输公司(这在华盛顿特区等地区尤为繁重，司机经常往返于弗吉尼亚特区和马里兰州之间)。明确这个目标至少是讨论的起点。你不能开始衡量法规的影响，直到你知道他们试图完成什么。

政府未能解释或证明或衡量其运作的暗箱操作是对政府信任度空前低下的主要原因之一。在当前的选举中，政治谎言的正常化对这种信任的未来不是一个好兆头。

## 长期信任和主算法

这让我回到了我开始这篇文章的主题:算法在新闻出版中的作用。当人们困惑地看着媒体在当前选举中的行为，它对实质性问题的挖掘失败，以及它对保持赛马刺激的关注时，你可以使用我的黑盒信任规则来帮助理解。

有一种主算法统治着我们的社会，并且，向[佩德罗·多明戈斯](http://www.amazon.com/Master-Algorithm-Ultimate-Learning-Machine/dp/0465065708)道歉，它不是某种强大的机器学习新方法。也不是政府的规定。这是[一条几十年前就被编码进现代商业的规则](http://medium.com/@timoreilly/why-the-game-of-business-needs-to-change-its-rules-4332ee4917de#.e2c6e0dqs)，从那以后基本上没有受到挑战。这种观念认为，企业唯一的义务是对股东负责。

正是这种算法让哥伦比亚广播公司董事长莱斯利·莫维斯在三月份说(川普的竞选)“也许对美国没有好处，但对哥伦比亚广播公司绝对有好处。”

这次选举不仅是对媒体出版商的真正考验，也是对谷歌和脸书这样的平台的考验。当奖励出版商的算法与有利于用户的算法不一致时，谷歌和脸书会站在哪一边？我们能相信谁的黑匣子？