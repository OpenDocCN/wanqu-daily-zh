# 认识一下 YouTube 的隐藏工作者，他们努力让广告远离仇恨视频

> 原文：<https://www.wired.com/2017/04/zerochaos-google-ads-quality-raters/?utm_source=wanqu.co&utm_campaign=Wanqu+Daily&utm_medium=website>

每天，在美国各地，为谷歌工作的人们登录他们的电脑，开始观看 YouTube。他们在视频中寻找暴力。他们在视频标题中寻找充满仇恨的语言。他们决定是否将剪辑归类为“攻击性”或“敏感”他们是谷歌所谓的“广告质量评估员”，由外部机构聘请的临时工，他们做出的判断机器仍然不能自己做出。现在，谷歌似乎急需这些人的帮助。

谷歌旗下的视频巨头 YouTube 每天出售伴随该网站数百万视频的广告。自动系统决定这些广告出现在哪里，广告商通常不知道他们的广告将出现在哪个特定的视频旁边。最近，这种不确定性已经成为谷歌的一个大问题。在多份 [报告](https://www.theguardian.com/media/2017/mar/16/guardian-pulls-ads-google-placed-extremist-material)披露该公司曾允许反对宣扬仇恨和恐怖主义的 YouTube 视频的广告运行后，该公司受到了审查。像沃尔玛、百事可乐和威瑞森这样的广告商放弃了这个平台和更广泛的谷歌广告网络。

谷歌试图控制叙述，称媒体夸大了广告出现在攻击性视频旁边的问题。该公司表示，被标记的视频“不到广告商总印象的千分之一”。谷歌首席商务官菲利普·辛德勒[表示，这个问题影响了](https://www.recode.net/2017/4/3/15157654/google-youtube-advertising-controversy-interview-philipp-schindler)数量“非常、非常、非常少”的视频。但广告评级机构表示，该公司正在将他们作为一股阻止问题恶化的力量。

因为谷歌 90%的收入来自广告客户，它需要通过快速锁定攻击性内容来防止更多的流失。但用户每天向 YouTube 上传近 60 万小时的新视频；这需要一个小城市的人夜以继日地工作才能看完。这就是为什么这家科技巨头强调开发人工智能内容过滤器很难，这种软件可以以比以往任何时候都更大的片段标记攻击性视频。辛德勒[最近告诉彭博](https://www.bloomberg.com/news/articles/2017-04-03/google-updates-ads-polices-again-ramps-up-ai-to-curtail-youtube-crisis)“这个问题不能被人类解决，也不应该被人类解决。

问题是，该公司仍然需要人类来训练这个人工智能。因此，谷歌仍然依赖大量人类工人来识别和标记攻击性材料，以建立其人工智能将从中学习的数据宝库。但八名现任和前任评级员告诉《连线》杂志，在公司越来越依赖广告评级员工作的时候，与谷歌沟通不畅和工作缺乏稳定性正在削弱他们做好工作的能力。

“我不是说这是当前危机的全部原因，”一位前谷歌广告评级员说，他没有被授权与《连线》谈论该计划。“但我确实认为项目的不稳定性是一个因素。我们评分员训练人工智能，但我们非常清楚人类的眼睛——和人类的大脑——需要在评估内容时进行一些深思熟虑的思考。”

人工任务

科技公司长期以来一直雇佣内容版主；随着人们上传和分享越来越多的内容，这项工作对这些互联网巨头变得越来越重要。《连线》采访的广告评级人员解释说，他们的角色不仅仅是监控视频。他们阅读评论区来标记用户之间的辱骂性玩笑。他们检查由谷歌广告网络提供服务的各种网站，以确保它们符合公司的质量标准。他们按类别对网站进行分类，如零售或新闻，并点击广告中的链接，看看它们是否有效。而且，正如他们的名字所暗示的，他们自己对广告质量进行评级。

然而，根据谷歌发给他们的一封电子邮件，今年 3 月，在广告客户抵制之后，谷歌要求评级机构将其他工作放在一边，支持“高优先级评级项目”，这将“在可预见的未来”消耗他们的工作量。这个新项目意味着几乎完全专注于 YouTube——对照广告客户认为令人反感的内容清单，检查视频或整个频道的内容。“这是一个巨大的变化，”一位广告评分员说。

评分者说，他们的工作量表明，数量和速度比准确性更重要。在某些情况下，他们被要求在不到两分钟的时间内回顾长达数小时的视频。在匿名在线论坛上，评分者交换节省时间的技巧——例如，查找说唱视频歌词以快速浏览脏话，或者以 10 秒钟为单位跳过一个片段，而不是看完整个片段。一个计时器记录他们在每个视频上花了多长时间，虽然这只是一个建议的截止日期，但评分者说这增加了一层压力。“我担心如果我连续花太长时间看太多视频，我会被解雇，”一名评分员告诉《连线》。

广告评级机构不只是将视频标记为不合适。他们被要求对他们的标题和内容进行细致的评估——例如，将它们归类为包含“不适当的语言”，如“亵渎”、“仇恨言论”或“其他”或“暴力”，子类别为“恐怖主义”、“战争和冲突”、“死亡和悲剧”或“其他”。还有“毒品”和“性/裸体”(子类别有“虐待”、“裸体”或“其他”)。该系统还为广告评级机构提供了“其他敏感内容”的选项——比如说，如果有人分享极端的政治观点。(*格言* [最近报道](http://adage.com/article/digital/youtube-feels-ad-squeeze-creators/308489/)谷歌现在允许客户选择退出带有“性暗示”和“耸人听闻和令人震惊”内容的广告，以及含有“亵渎和粗话”的内容)

广告人说，有些材料并不总是完全符合所提供的类别。在这种情况下，评分者会将材料标记为“不可评分”一位目前的评分者描述了他不得不评价两个讲西班牙语的人在说唱比赛中的表现。他告诉《连线》杂志:“我检查了一下，因为外语的原因，它是不可译的。”。“我还添加了一条评论，说这似乎是一段人们用外语互相侮辱的视频，但我不能确切地说出他们是否在使用脏话。”(一位前评级员表示，从最近的广告评级职位空缺来看，谷歌似乎优先考虑聘用双语评级员。当视频使用他们不理解的语言时，工作人员也可以勾选一个复选框。)

多个广告评级机构表示，他们被要求观看内容令人震惊的视频。一位评价者说:“最近，图片内容更加生动了……有人试图带着他们的狗在卡车里自杀。”。这位评价者说，那个人点燃了卡车，然后下车自杀，头部中枪。在广告商经常光顾的在线论坛上，匿名发帖者说他们看过针对妇女、儿童和动物的暴力视频。几位发帖者表示，在连续观看了几个这样的视频后，他们需要休息一下。广告评级人员表示，他们不知道谷歌是如何选择他们将观看的视频的——他们在评级前只看到视频的标题和缩略图，而不是理由。评级机构负责观看的视频中的其他典型内容包括人们谈论视频游戏、政治和阴谋论。

综合来看，评估视频所需的工作范围和细微差别表明，谷歌在处理 YouTube 的广告问题时仍然需要人工帮助。“我们有很多信息来源，但我们最重要的来源之一是像你这样的人，”谷歌在一份描述他们广告评级工作目的的文件中告诉评级人员。但是，尽管只有机器智能可以应对 YouTube 的规模，正如公司高管和代表们一再强调的那样，直到谷歌的机器——或任何其他人的机器——足够聪明，能够自己区分，比如说，真正冒犯性的言论和其他形式的表达，这些努力仍然需要依靠人。