# HipChat 如何使用 ElasticSearch 和 Redis 存储和索引数十亿条消息-高可伸缩性-

> 原文：<http://highscalability.com/blog/2014/1/6/how-hipchat-stores-and-indexes-billions-of-messages-using-el.html?utm_source=wanqu.co&utm_campaign=Wanqu+Daily&utm_medium=website>

![](img/1f990901f6dd64766ac61ad0b37e95a1.png)

*本文来自于采访 [祖海布](http://www.linkedin.com/in/zuhaib) ，一位制作工程师在[hip chat](https://www.hipchat.com/)， 的群聊和团队 IM。T19】*

HipChat 始于一个不寻常的空间，一个你可能认为不会有多大前途的企业集团消息传递，但正如我们所了解的那样，它们里面有黄金 [企业山丘](http://www.developereconomics.com/still-building-consumer-apps-enterprise-pays-4x/) 。这就是为什么 Atlassian，well 的制造者想到了像 JIRA 和 Confluence， [在 2012 年收购 HipChat](http://blog.hipchat.com/2012/03/07/weve-been-acquired-by-atlassian/)。

在一个不常听到的故事中，一个更大的母公司的资源和关系实际上帮助 HipChat 进入了一个 [指数增长周期](https://s3.amazonaws.com/uploads.hipchat.com/10804/368466/10joz8sztfw4dfc/HipChat1B.jpg) 。在达到 12 亿条消息的存储量后，他们现在每隔几个月就要将发送、存储和索引的消息数量翻一番。

这种增长给曾经充足的基础设施带来了巨大压力。HipChat 展示了一个常见的扩展模式。开始简单，经历流量峰值，然后想我们现在怎么办？使用更大的计算机通常是第一个也是最好的答案。他们做到了。这给了他们一些思考下一步该做什么的喘息空间。在 AWS 上，在某个拐点之后，你开始走向云原生，也就是水平扩展。这就是他们所做的。

但是故事有一个转折。除了 HipChat 的云/SaaS 版本之外，安全问题还推动了 hip chat 内部版本的开发。我们将在本周晚些时候的的[帖子中更多地讨论这一有趣的进展。](http://highscalability.com/blog/2014/1/8/under-snowdens-light-software-architecture-choices-become-mu.html)

虽然 HipChat 没有 Google scale 大，但是 HipChat 有很好的东西可以学习，他们如何及时地索引和搜索数十亿条消息，这是 IRC 和 HipChat 之间的关键区别。在负载下索引和存储消息同时不丢失消息是一个挑战。

这是 HipChat 走的路，你能学到什么？让我们看看……

## 统计数据

*   每秒 60 条消息。

*   存储了 12 亿份文件

*   4TB 的 EBS Raid

*   AWS 上的 8 台 ElasticSearch 服务器

*   26 前端代理发球。后端应用服务器的数量是这个数字的两倍。

*   18 人

*   .5 太字节的搜索数据。

## 平台

*   **托管** : AWS EC2 East 有 75 个实例目前全部是 Ubuntu 12.04 LTS

*   **数据库** : CouchDB 当前用于聊天记录，正在过渡到 ElasticSearch。MySQL-RDS 用于其他一切

*   **缓存**:重定向

*   **搜索**:弹性搜索

*   **队列/工人服务器**:齿轮工(队列)和[卷发器](https://github.com/powdahound/curler)、(工人)

*   **语言** : Twisted Python (XMPP 服务器)和 PHP (Web 前端)

*   **系统配置**:开源 Chef + Fabric

*   **代码部署** : Capistrano

*   **监控**:感知并监控泵送警报至传呼机

*   **制图** : statsd +石墨

## 产品

*   流量非常具有突发性。周末和节假日会很安静。在高峰负载期间，每秒钟有数百个请求。聊天信息实际上并不构成大部分流量；它是存在信息(离开、空闲、可用)、人们连接/断开连接等。因此，每秒 60 条消息可能看起来很低，但这只是一个平均值。

*   HipChat 希望成为您的通知中心，在这里您可以与您的团队协作，并获得来自您的工具和其他系统的所有信息。有助于让每个人都了解情况。尤其是远程办公室。

*   使用 HipChat 而不是 IRC 的主要原因是，HipChat 会存储和索引每一个对话，以便你以后可以搜索它们。搜索是重点，所以你可以留在 HipChat。这个功能对团队来说的好处是，你可以在任何时候回去，并且记得发生了什么和你同意做什么。它还会将消息路由到同一用户拥有的多个设备，以及临时消息缓存/重试(如果发送消息时您的设备不可达)。

*   增长来自更多的客户，但随着每个站点使用该产品的客户越来越多，参与度也越来越高。他们的 API 集成也带来了增长。

*   消息的存储和搜索是他们系统中主要的可伸缩性瓶颈。

*   HipChat 使用 XMPP，因此任何 XMPP 客户端都可以连接到系统，这是一个巨大的成功。他们已经建立了自己的原生客户端(Windows、Linux、Mac、iOS、Android ),并扩展了 PDF 查看、自定义表情、自动用户注册等功能。

*   不久前，将维基这样的工具引入企业文化几乎是不可能的。现在企业级工具似乎被接受了。为什么是现在？

    *   基于文本的交流现在已经很普遍并被接受。我们有短信、即时消息和 Skype，所以使用聊天工具现在很自然。

    *   分布式工作团队的兴起。团队越来越分散。我们不能只是坐在一起听一堂课。有必要记录一切，这意味着组织沟通被视为一项巨大的资产。

    *   增强功能。像内嵌图片、动画 gif 等功能使它变得有趣，吸引了更多的人群。

*   HipChat 有一个 API，使得编写类似于 T2 IRC 机器人的工具成为可能。示例用途是位存储桶提交。在 10:08，开发人员 X 提交了一些代码来修复一个 bug。它通过 HipChat 发送出去，带有直接指向代码提交和提交日志的链接。全自动的。Bitbucket commit 点击一个 web 钩子，使用其中一个插件来发布信息。插件有助于编写你自己的机器人。转到您的 Bitbucket 帐户。假设我有我的 API 令牌，我想在提交发生时向这个 API 提交。GitHub 也是如此。

*   从客户端的 Adobe Air 开始，它会泄漏内存并导致机器停机。所以转移到原生应用。痛苦，但是很好的痛苦。他们的用户遍布公司各个部门的所有平台。你需要去用户所在的地方。希望用户在所有操作系统上都有很好的体验。用户是每个人，而不仅仅是技术人员。

## XMPP 服务器架构

*   HipChat 基于 XMPP，消息是在一个 [XMPP 节](http://xmpp.org/rfcs/rfc3920.html) 中的任何内容，可以是一行文本或一长段日志输出中的任何内容。他们不想谈论他们的 XMPP 架构，所以没有很多细节。

*   他们没有使用第三方 XMPP 服务器，而是使用 Twisted Python 和 XMPP 库构建了自己的服务器。这允许创建一个可伸缩的后端，用户管理，和简单的添加功能，而不需要与别人的代码库冲突。

*   AWS 上的 RDS 用于用户身份验证以及事务和 SQL 有用的其他领域。这是一项稳定、成熟的技术。对于内部产品，他们使用 MariaDB。

*   Redis 进行缓存。像哪些用户在哪些房间、在线信息、谁在线等信息，所以连接到哪个 XMPP 服务器并不重要，XMPP 服务器本身并没有限制。

*   增加的负载暴露了代理服务器的弱点，以及它们可以处理多少客户端。

    *   这是一个真正的问题，因为不丢失消息是重中之重。客户表示，不丢弃消息比低延迟更重要。用户宁愿晚收到消息，也不愿根本收不到消息。

    *   有了 6 台 XMPP 服务器，系统运行良好。随着连接数量的增加，他们开始发现不可接受的延迟。连接不仅来自客户端，还来自支持其编程接口的机器人。

    *   作为第一步，他们将前端服务器和应用服务器分开。代理处理连接，后端应用程序处理小节。前端服务器的数量由活动监听客户端的数量决定，而不是由发送的消息数量决定。在提供及时服务的同时保持如此多的连接是一个挑战。

    *   解决数据存储问题后，计划是研究如何优化连接管理。Twisted 工作得很好，但是它们有很多连接，所以必须找出如何更好地处理它。

## 存储架构

*   在经历增长的同时，HipChat 上发送了 10 亿条消息，他们将 CouchDB 和 Lucene 的消息存储和搜索解决方案推向了极限。

    *   认为 Redis 会是失败点。以为沙发/Lucene 就够好了。没有进行适当的容量规划和查看邮件增长率。增长速度比他们想象的要快，不应该如此关注 Redis，而应该关注数据存储。

    *   那时候，他们相信通过增加更多的马力来扩大规模，向越来越大的亚马逊实例升级。随着他们的成长，这种方法只能再工作 2 个月。所以他们不得不做一些不同的事情。

    *   Couch/Lucene 已经一年多没有更新了，它也不能做 faceting 了。另一个不同的原因。

*   亚马逊上大约 5 亿条消息是一个转折点。有了专用服务器和 200g RAM，他们以前的架构可能还能工作，但不是在资源有限的云中。

*   他们想留在亚马逊。

    *   喜欢它的柔韧性。只需创建一个新实例，然后继续前进。

    *   亚马逊的片状让你发展得更好。不要把所有的鸡蛋放在一个篮子里，如果一个节点出现故障，你必须处理它，否则一些用户的流量将会丢失。

    *   采用动态模型。可以很快丢失一个实例并产生新的实例。云原生类型的东西。随时杀死一个节点。杀一个 Redis 高手。5 分钟恢复。目前在美国东部的所有 4 个可用区域进行划分，但还不是多区域。

    *   EBS only 让你拥有 1TB 的数据。当他们遇到这个限制时，并不知道这个限制。使用 Couch 时，他们遇到了 EBS 磁盘大小限制的问题。HipChat 的数据是 0.5 万亿字节。为了进行压缩，Couch 必须将数据复制到一个压缩文件中，这将占用双倍的空间。周末压缩期间，2 TB RAID 达到极限。不想要 RAID 解决方案。

*   亚马逊 DynamoDB 不是一个选项，因为他们正在推出 HipChat 服务器，这是一种防火墙后的托管服务。

    *   HipChat 服务器推动技术堆栈的决策。私有版本是你自己的解决方案。某些客户无法使用云/SaaS 解决方案，如银行和金融机构。国家安全局吓坏了国际客户。雇佣了两名工程师来创建该产品的可安装版本。

    *   Redis 集群可以是自托管的，它可以像 ElasticSearch 一样在 AWS 上工作。他们在内部版本中使用 MariaDB，而不是 RDS。

    *   不能考虑完全的 SaaS 解决方案，因为那会被锁定。

*   现在过渡到弹性搜索。

    *   迁移到 ElasticSearch 作为他们的存储和搜索后端，因为它可以吃掉他们可以提供给它的所有数据，它高度可用，它可以通过简单地添加更多节点来透明地扩展，它是多租户的，它可以通过分片和复制透明地处理节点丢失，并且它构建在 Lucene 之上。

    *   并不真正需要 MapReduce 功能。调查了 BigCouch 和 Riak 搜索(看起来没烤好)。但是 ES 在一杆进洞上的表现相当不错。我喜欢去掉一个组件的想法，这样就少了一件需要解决的问题。ES HA 让他们对自己系统的可靠性充满信心。

    *   Lucene compatible 是一个巨大的胜利，因为他们所有的查询都已经与 Lucene 兼容，所以这是一个自然的迁移途径。

    *   客户数据多种多样，从聊天记录到图片都有，因此回复类型也多种多样。他们需要能够从超过 12 亿个文档中快速定向查询数据。

    *   越来越常见的一个举措是，HipChat 也使用 ElasticSearch 作为他们的键值存储，减少了他们需要的数据库系统的数量，从而降低了整体复杂性。性能和响应时间如此之好，他们想为什么不用它呢？10 毫秒到 100 毫秒之间的响应时间。它在某些领域击败了沙发，但前面没有任何缓存。为什么有多种工具？

    *   有了 ES，一个节点可以在无人注意的情况下关闭，当它重新平衡时，你会得到一个关于高 CPU 使用率的警报，但它一直在突突前进。

    *   拥有 8 个 ES 节点来应对流量的增长。

    *   与所有基于 Java 的产品一样，JVM 调优可能很棘手。

        *   要使用 ES，必须对将要使用的堆空间进行容量规划

        *   测试缓存。ES 可以缓存过滤结果，速度很快，但是需要很大的堆空间。8 台机器上有 22g 的堆，打开缓存时内存耗尽。因此，除非有计划，否则请关闭缓存。

        *   有缓存问题，因为它会遇到内存不足的错误，然后失败。集群在几分钟内就自愈了。只有少数用户注意到了一个问题。

*   由于网络不可靠的问题，Amazon 上的自动故障转移很成问题。在群集中，它会导致选举错误地发生。

    *   在 ElasticSearch 上遇到了这个问题。最初有 6 ES 节点作为主候选节点运行。一个节点将耗尽内存或遇到 GC 暂停，除此之外还有网络丢失。然后其他人再也看不到主人，举行选举，宣布自己是主人。他们选举架构的缺陷是他们不需要法定人数。所以出现了大脑分裂。两位大师。引发了很多问题。

    *   解决方案是在专用节点上运行 ElasticSearch masters。他们所做的就是做主人。从那以后就没有问题了。主控器处理碎片分配是如何完成的，谁是主要的，并映射副本碎片的位置。使重新平衡变得更加容易，因为主服务器可以出色地处理所有重新平衡。可以从任何节点查询，并将自己进行内部路由。

*   使用月份索引。每个月都是一个单独的指标。每个主索引有 8 个碎片，然后在其上有两个副本。如果一个节点丢失，系统仍然可以运行。

*   不将 RDS 移入 ES。他们需要 SQL 的东西是存放在 RDS/MariaDB 中的，通常是用户管理数据。

*   在 Redis 集群被释放之前，Redis 在主/从设置中有大量缓存。有一个 Redis stat 服务器，谁在一个房间里，谁离线。Redis history 缓存最后 75 条消息，以防止第一次加载会话时不断地冲击数据库。内部状态或快速数据的状态，如登录人数。

## 通用

*   Gearman 用于异步作业，如 iOS 推送和发送电子邮件。

*   AWS West 用于灾难恢复。所有内容都复制到 AWS West。

*   厨师用于所有配置。ElasticSearch 为厨师准备了一本不错的食谱。容易上手。比如 Chef，因为你可以开始编写 Ruby 代码，而不是使用木偶风格的 DSL。它还有一个非常活跃的社区。

*   收购经验。他们现在可以接触到公司的核心资产和人才，但 Atlassian 不会破坏有效的东西，我们买下你是有原因的。例如，我可以在内部询问如何扩大 ElasticSearch 的规模，当 Atlassian 的其他人需要帮助时，他们可以提供帮助。整体体验不错。

*   团队结构是扁平的。还是一个小团队。目前有 18 人左右。devops 的两个人。平台、iOS、Android 的开发者，服务器端的几个，还有一个 web 开发工程师(在法国)。

*   Capistrano 用于部署到所有机箱。

*   Sensu 为监控 app。忘记监控 ElasticSearch 节点的堆空间，然后在没有任何通知的情况下遇到 OOM 问题。目前堆的 75%,这是他们想要的最佳点。

*   竹子用于持续整合。

*   由开发人员驱动的客户端版本尚未正式发布。有一个测试的准备区。

*   组旗。可以控制哪些组获得一个特性来测试特性，以缓慢释放特性并控制机器上的负载。

*   特征标志。例如，在 ElasticSearch 首次展示期间，这是一个很好的保护措施。如果他们注意到一个 bug，他们可以关闭一个功能，回到沙发上。用户不会注意到差异。在 Couch 和 ElasticSearch 之间的过渡阶段，他们将应用程序复制到两家商店。

*   新的 API 版本将使用 Oauth，因此开发人员可以使用 HipChat API 在他们自己的服务器上进行部署。让客户使用他们自己的服务器是一种更具可扩展性的模式。

## 未来

*   几个月后将达到 20 亿条信息，预计 ElasticSearch 可以处理大约 20 亿条信息。不确定如何处理预期的负载增加。希望去 Amazon West 获得更多的数据中心可用性，并可能将更多的用户放在不同的数据中心。

*   希望使用 AWS 的自动缩放功能。

*   进入语音、私人一对一视频、音频聊天、基本会议。

*   将来可能会使用 RabbitMQ 进行消息传递。

*   与 Confluence(一个 wiki)的更大集成。使用 HipChat 聊天，然后使用 Confluence 页面获取详细信息。

## 课

*   这些企业应用程序是有钱可赚的。向企业销售可能是一种折磨。漫长的销售周期意味着它可能成功也可能失败。但如果你打了，这是一个有利可图的关系。所以你可能要考虑企业市场。时代在变。企业的可能仍然是乏味和缓慢的，但他们也在采用新的工具和做事的方式，那里有一个机会。

*   **隐私变得越来越重要，在向企业销售产品时，它会影响您的产品组合选择**。HipChat 正在制作他们产品的内部版本，以满足那些不信任公共网络或云的用户。对于程序员来说，云作为一个平台非常有意义。对于企业来说，云可能是邪恶的。这意味着您必须做出灵活的技术堆栈选择。如果你 100%依赖 AWS 服务，那么将你的系统转移到另一个数据中心几乎是不可能的。这对网飞来说可能无关紧要，但如果你想打入企业市场，这就很重要了。

*   **扩大规模以获得一些喘息空间**。当你在等待弄清楚你的架构下一步是什么的时候，你可以花很少的钱扩大规模，给自己多几个月的喘息空间。

*   **挑不能失败的**。HipChat 将永不丢失用户聊天记录作为一个优先事项，因此他们的架构将这一优先事项反映到将聊天内容保存到磁盘上，然后在停机的系统恢复时重新加载。

*   **走土人** 。您的客户在许多不同的平台上，本地应用程序将提供最佳体验。对于一家初创公司来说，这是大量的资源，太多了。因此，在某种程度上，卖给一家拥有更多资源的公司是有意义的，这样你就可以生产出更好的产品。

*   **特色与团旗打造更好的发布练习** 。如果您可以选择哪些组可以看到一个特性，并且如果您可以在生产和测试中关闭特性，那么您就不必如此害怕发布新的构建。

*   **用** 选择你觉得真正有信心的技术。ElasticSearch 横向扩展以应对增长的能力帮助 HipChat 对他们的解决方案充满信心。用户会很高兴。这种感觉很好。

*   **成为流程的一部分，你变得更有价值，难以去除** 。HipChat 作为人和工具之间的自然交汇点，也是编写实现各种有用的工作流技巧的机器人的自然点。这使得 HipChat 成为企业中的一个平台玩法。它启用了原本无法构建的功能。如果你能做到这一点，你很难摆脱。

*   **AWS 需要单独的节点存在总线** 。可笑的是，在云中，机器的存在信息不能从客观的第三方来源获得。如果你看看机架，它通常有一个单独的存在总线，因此插槽可以知道其他插槽是否可用。这样你就不用猜了。在云中，软件使用基于原始 TCP 的连接技术和心跳来猜测另一个节点何时关闭，这可能会导致裂脑问题和故障转移时的数据丢失。是时候进化并向可靠性迈出一大步了。

*   **产品决策驱动堆栈决策** 。HipChat 服务器推动技术堆栈的决策。Redis 集群可以自托管。Amazon DynamoDB 不是一个选项，因为他们正在防火墙后推出托管服务。

*   全力解决问题只会让你一事无成。即使在云中，您也需要容量规划。除非您的架构从一开始就完全是云原生的，否则任何架构都会有负载拐点，在这些拐点处，他们的架构将不再能够处理负载。看增长率。投射出去。什么会破？你会怎么做？不要再犯同样的错误。HipChat 将如何处理 40 亿条消息？那不清楚。

*   **知道自己系统的极限** 。EBS 有 1 TB 的存储限制，这是一个很大的限制，但是如果您的存储接近这个限制，就需要有一个计划。类似地，如果您的数据库(如 Couch)在压缩阶段使用两倍的磁盘空间，这将影响您的限制。

*   **世界会给你惊喜**。六个月前，HipChat 认为 Redis 将是最薄弱的环节，但它仍然很强大，而 Couch 和 EBS 是最薄弱的环节。

## 相关文章