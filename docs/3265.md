# Twitter 背后的基础设施:效率和优化

> 原文:[https://blog . Twitter . com/2016/the-infra structure-behind-Twitter-efficiency-and-optimization？UTM _ source = Wanqu . co&UTM _ campaign = Wanqu+Daily&UTM _ medium = website](https://blog.twitter.com/2016/the-infrastructure-behind-twitter-efficiency-and-optimization?utm_source=wanqu.co&utm_campaign=Wanqu+Daily&utm_medium=website)

在过去，我们已经发布了关于[欺骗](https://blog.twitter.com/2011/finagle-a-protocol-agnostic-rpc-system)、[曼哈顿](https://blog.twitter.com/2014/manhattan-our-real-time-multi-tenant-distributed-database-for-twitter-scale)的细节，以及我们[如何重新架构](https://blog.twitter.com/2013/new-tweets-per-second-record-and-how)该网站以便能够处理诸如空中楼阁、超级碗、2014 年世界杯、全球除夕庆祝活动等事件的摘要。在这个基础设施系列中，我们将重点关注运行 Twitter 的核心基础设施和组件。我们还将在每个博客中重点关注围绕可扩展性、可靠性和效率所做的努力，突出我们基础架构的历史、我们面临的挑战、吸取的教训、进行的升级以及我们的发展方向。

### 数据中心效率

**历史**

Twitter 的硬件和数据中心达到了很少有科技公司能达到的规模。然而，这并不是一帆风顺的。通过结合物理改进和基于软件的更改，我们的正常运行时间已经成熟。

在 fail whale 盛行期间，由于软件限制以及硬件或基础设施级别的物理故障，会发生停机。故障域存在于各种定义中，必须汇总这些定义才能确定服务的风险和所需冗余。随着业务在客户、服务、媒体内容和全球存在方面的扩展，该战略演变为高效和灵活地支持服务。

**挑战**

软件对裸机的依赖进一步依赖于我们的数据中心运行和维护电源、光纤连接和环境正常运行时间的能力。这些离散的物理故障域必须根据分布在硬件上的服务进行审查，以提供容错能力。

最初决定选择哪家数据中心服务提供商进行扩展是在选址、运营和设计专业化刚刚起步的时候。我们从托管提供商开始，然后随着规模的扩大迁移到主机托管设施。设备故障、数据中心设计问题、维护问题和人为错误会导致早期服务中断。因此，我们不断迭代物理层设计，以提高硬件和数据中心运营的弹性。

服务中断的物理原因包括服务器组件级别、架顶式交换机和核心交换机的硬件故障。例如，在对我们定制的服务器进行初步评估期间，硬件团队确定，鉴于服务器电源的低故障率，第二个电源的成本是不合理的，因此将其从设计中删除。数据中心电源拓扑通过机架的独立物理鞭提供冗余，并需要第二个电源。移除第二个电源消除了冗余电源路径，使得硬件在电源系统中的配电故障期间易受影响。为了减轻单电源的影响，需要在机架级别添加 ATS 单元，以便为电源提供辅助路径。

具有不同光纤路径、电源和物理域的系统分层继续将服务与相对较小规模中断的影响隔离开来，从而提高了弹性。

**经验教训和重大技术升级、迁移和采用**

我们学会了对物理故障域(即建筑电力和冷却、硬件、光纤)与分布在它们之间的服务之间的依赖关系进行建模，以更好地预测容错能力并推动改进。

我们增加了额外的数据中心，以提供区域多样性，从而降低自然灾害的风险，并在重大升级、部署或事故期间根据需要提供区域间故障转移的能力。数据中心的主动-主动操作提供了分阶段的代码部署，降低了代码部署的整体影响。

随着环境范围的扩大和硬件在更高工作温度下的弹性设计，数据中心的用电效率得到了提高。

**未来工作**

我们的数据中心在战略和运营方面不断发展，能够在不中断用户的情况下实时更改运营网络和硬件。未来几年，我们的战略将继续通过优化和保持灵活性，在提高效率的同时，关注现有电力和物理空间的规模。

### 硬件效率

**历史和挑战**

我们的硬件工程团队开始对购买的现成硬件的性能进行鉴定和验证，并逐渐发展为针对成本和性能优化的硬件定制。

以 Twitter 的规模采购和消费硬件会面临一系列独特的挑战。为了满足我们内部客户的需求，我们最初启动了一项计划来验证和确保所购硬件的质量。该团队主要关注性能和可靠性测试，以确保系统能够满足需求。运行系统测试来验证行为是可预测的，并且引入的错误很少。

随着我们扩展我们的主要工作负载(Mesos、Hadoop、Manhattan 和 MySQL ),市场上的产品显然不能完全满足需求。现成的服务器带有企业功能，如 raid 控制器和热插拔电源。这些组件在小范围内提高了可靠性，但通常会降低性能并增加成本；例如，一些 raid 控制器会干扰固态硬盘的性能，可能会占系统成本的三分之一。

当时，我们是 mysql 数据库的大用户。SAS 媒体的供应和性能都出现了问题。大多数部署是 1u 服务器，使用的驱动器总数加上写回高速缓存可以预测系统的性能，通常时间限制为持续 2000 次连续 IOPS。为了继续扩展这一工作负载，我们搁置了 CPU 内核和磁盘容量，以满足 IOPS 需求。我们目前无法找到经济高效的解决方案。

随着我们的硬件数量达到临界质量，投资硬件工程团队以定制白盒解决方案，重点降低资本支出和提高性能指标是明智之举。

**重大技术变更和采用**

我们已经在硬件技术堆栈中进行了许多转变。下面是采用新技术和内部开发平台的时间表。

*   2012 年——固态硬盘成为 MySQL 和键/值数据库的主要存储介质。
*   2013 年——我们开发了首个针对 Hadoop 工作负载的定制解决方案，并成为我们的主要批量存储解决方案。
*   2013 -我们的定制解决方案专为 Mesos、TFE 和缓存工作负载而开发。
*   2014 年-我们的定制 SSD 键/值服务器完成开发。
*   2015 年-我们的定制数据库解决方案得以开发。
*   2016 年——我们开发了用于机器学习模型推理和训练的 GPU 系统。

**吸取的经验教训**

我们硬件工程团队的目标是通过做一些小的权衡来改善我们的总拥有成本，从而显著降低资本支出和运营支出。降低服务器成本有两个原则:

1.  移除未使用的组件
2.  提高利用率

Twitter 的工作负载分为四个主要垂直领域:存储、计算、数据库和 gpu。Twitter 在每个垂直基础上定义需求，允许硬件工程为每个需求产生一个集中的特性集。这种方法允许我们在设备可能闲置或未充分利用的情况下优化组件选择。例如，我们的存储配置专为 Hadoop 工作负载而设计，交付时总拥有成本比原始 OEM 解决方案降低了 20%。同时，该设计提高了硬件的性能和可靠性。同样，对于我们的垂直计算，硬件工程团队通过删除不必要的功能提高了这些系统的效率。

运行一台服务器所需的开销是最低的，我们很快就达到了这样一个点，即 it 部门不再能够通过移除组件来降低成本。特别是在垂直计算领域，我们认为最佳方法是寻找用单个节点取代多个节点的解决方案，并依靠 Aurora/Mesos 来管理容量。我们选定了一种设计，用一个节点取代了我们上一代的两个计算节点。

我们的设计验证从一系列粗略的基准测试开始，然后进展到一系列生产负载测试，确认缩放系数为 2。这种改进大部分来自于简单地增加 CPU 的线程数，但是我们的测试证实每线程性能有 20-50%的改进。此外，由于更多线程分担了服务器开销，我们看到每线程能效提高了 25%。

对于初始部署，我们的监测显示替换系数为 1.5，远低于设计目标。对性能数据的检查显示，工作负载特征中存在一个有缺陷的假设，需要对其进行识别。

我们的硬件工程团队最初的行动是开发一个模型来预测当前 Aurora 作业集在各种硬件配置中的打包效率。该模型正确预测了我们在车队中观察到的比例因子，并表明我们由于不可预见的存储需求而搁置了旧件。此外，该模型预测，通过改变内存配置，我们还将看到一个更好的缩放因子。

硬件配置更改需要时间来实施，因此硬件工程部门确定了几项大型工作，并与我们的 SRE 团队合作来调整计划要求，以减少存储需求。这些变化部署起来很快，并立即改进到 1.85 的缩放系数。

为了永久解决这个问题，我们需要调整服务器的配置。只需扩展已安装的内存和磁盘容量，就能以最小的成本增加将 CPU 核心利用率提高 20%。硬件工程与我们的制造合作伙伴一起调整了这些服务器初始发货的物料清单。后续观察证实，缩放系数为 2.4，超过了目标设计。

### 从裸机迁移到 mesos

直到 2012 年，在 Twitter 内部运行服务都需要硬件。服务所有者必须找出并请求特定型号或类别的服务器，担心您的机架多样性，维护脚本以部署代码，并管理失效的硬件。基本上没有“服务发现”当 web 服务需要与用户服务对话时，它通常会加载一个 YAML 文件，该文件包含用户服务的所有主机 IP 和端口以及使用该列表的服务(在 wiki 页面中跟踪端口预留)。随着硬件的淘汰或添加，管理需要编辑和提交对 YAML 文件的更改，这些更改将在下一次部署时发布。在缓存层中进行更改意味着许多部署需要数小时甚至数天时间，一次添加几台主机并分阶段部署。在部署期间处理缓存不一致是经常发生的事情，因为一些主机会使用新列表，而一些主机会使用旧列表。有可能主机运行旧代码(因为在部署过程中机器暂时停机)导致站点行为不稳定。

2012/2013 年，Twitter 开始采用两件事:服务发现(通过 zookeeper 集群和 [Finagle](https://twitter.github.io/finagle/) 的核心模块中的库)和 [Mesos](http://mesos.apache.org/) (包括我们自己在 Mesos 上的调度框架，名为 [Aurora](http://aurora.apache.org/) ，现在是 Apache 项目)。

服务发现不再需要静态 YAML 主机列表。一个服务要么在启动时自注册，要么在 mesos 下自动注册到一个“服务器集”(这只是一个基于角色、环境和服务名的 zookeeper 中 znodes 列表的路径)。任何需要与该服务对话的服务只需观察该路径，并实时查看那里有哪些服务器。

有了 Mesos/aurora，不是有一个脚本(我们是 [Capistrano](https://github.com/capistrano/capistrano) 的重度用户)来获取主机列表、推送二进制文件并编排滚动重启，而是服务所有者将软件包推送到一个名为“packer”的服务中(这是一个由 HDFS 支持的服务)，上传一个描述服务的 Aurora 配置(它需要多少 CPU、多少内存、需要多少实例、每个实例应该运行的所有任务的命令行)，Aurora 将完成部署。它在可用的主机上调度实例，从 packer 下载工件，在服务发现中注册它，并启动它。如果出现任何故障(硬件失效、网络故障等)，Mesos/Aurora 会自动在另一台主机上重新调度实例。

**Twitter 的私人平台即服务**

Mesos/Aurora 和服务发现的结合是革命性的。在接下来的几年里，有许多错误和成长的烦恼，也有许多关于分布式系统的惨痛教训，但基本设计是合理的。在旧世界中，团队不断地处理和思考硬件及其管理。在新的世界里，工程师们只需要考虑如何最好地配置他们的服务，以及要部署多少容量。随着时间的推移，我们还能够从根本上提高 Twitter 车队的 CPU 利用率，因为通常每个拥有自己裸机硬件的服务都没有充分利用其资源，并且在管理容量方面做得很差。Mesos 允许我们将多个服务打包到一个盒子中，而无需考虑它，并且向服务添加容量只需请求配额、更改一行配置并进行部署。

两年内，大多数“无状态”服务都转移到了 Mesos。一些最重要和最大的服务(包括我们的用户服务和广告服务系统)是第一批迁移的。作为最大的公司，他们看到了其运营负担的最大好处。这使他们能够减轻运营负担。

我们一直在寻找提高效率和优化基础设施的方法。作为这项工作的一部分，我们定期对公共云提供商和产品进行基准测试，以验证我们对基础架构的总体拥有成本和性能预期。我们在公共云领域也有良好的表现，并将继续利用公共云作为最佳选择。本帖的下一个系列将主要关注我们的基础设施的规模。

特别感谢[詹妮弗·弗雷泽](https://twitter.com/jenniferfraser)、[大卫·巴尔](https://twitter.com/davebarr)、[杰夫·帕皮里昂](https://twitter.com/gpapilion)、[马特·辛格](https://twitter.com/mattbytes)和[林东](https://twitter.com/lamdong)对这篇博文的贡献。