# 在生产中使用 Kubernetes 一年:经验教训

> 原文:[http://techbeacon . com/一年-使用-kubernetes-生产-经验教训？UTM _ source = Wanqu . co&UTM _ campaign = Wanqu+Daily&UTM _ medium = website](http://techbeacon.com/one-year-using-kubernetes-production-lessons-learned?utm_source=wanqu.co&utm_campaign=Wanqu+Daily&utm_medium=website)

2015 年初，在亚马逊 EC2 上运行部署多年后，我在 [Luminis Technologies](http://luminis-technologies.com/) 的团队受命为我们所有的开发团队构建一个新的部署平台。这些年来，基于 AWS 的设置对于[部署新版本](https://content.microfocus.com/continuous-delivery-release-automation-tb/effective-product-release?lx=-DC2cJ&custom_url=continuous-delivery-release-automation-tb?utm_source=techbeacon&utm_medium=referral&utm_campaign=7014J000000dVOkQAM)非常有效，但是使用定制脚本和工具来自动化部署的部署设置对于运营以外的团队来说并不容易使用——尤其是那些没有资源来学习这些脚本和工具的所有细节的小团队。主要问题是没有“部署单元”，没有部署单元，开发和操作之间就会有差距。[集装箱化趋势](http://techbeacon.com/essential-guide-software-containers-application-development)显然将改变这一点。

如果您还没有接受 Docker 和 Kubernetes 的生产就绪性，请阅读我的团队是如何成为早期采用者的。我们已经将 Kubernetes 投入生产一年多了。

## 从容器和容器编排工具开始

我现在相信[容器是未来](http://techbeacon.com/state-containers-5-things-you-need-know-now)的部署格式。它们使得将应用程序与其所需的基础设施打包更加容易。虽然像 [Docker](http://techbeacon.com/docker-just-first-killer-app-container-revolution) 这样的工具提供了实际的容器，但我们还需要工具来处理诸如复制和故障转移之类的事情，以及自动化部署到多台机器的 API。

Kubernetes 和 Docker Swarm 等[集群工具在 2015 年初的状态非常不成熟，只有早期的 alpha 版本可用。我们仍然尝试使用它们，并从 Docker Swarm 开始。](http://techbeacon.com/scaling-containers-essential-guide-container-clusters)

起初，我们用大使模式和一堆脚本来自动部署，用它来处理我们自己的网络。这能有多难？这是我们的第一个艰难的教训:**容器集群、网络和部署自动化实际上是*很难解决的问题*。**

我们很快意识到这一点，并决定赌上另一个可用的工具。Kubernetes 似乎是最好的选择，因为它得到了 Google、Red Hat、Core OS 和其他组织的支持，这些组织清楚地知道如何运行大规模部署。

## 使用 Kubernetes 实现负载平衡

使用 Kubernetes 时，您必须熟悉一些概念，例如[【pods】](http://kubernetes.io/docs/user-guide/pods/)[服务](http://kubernetes.io/docs/user-guide/services/)和 [复制控制器](http://kubernetes.io/docs/user-guide/replication-controller/) 。如果您还不熟悉这些概念，有一些很好的资源可以帮助您快速了解。Kubernetes [文档](http://kubernetes.io/docs/whatisk8s/) 是一个很好的起点，因为它为初学者提供了几个指南。

一旦我们启动并运行了 Kubernetes 集群，我们就可以使用 Kubernetes CLI[kubectl](http://kubernetes.io/docs/user-guide/kubectl-overview/)部署应用程序，但是我们很快发现，当我们想要自动化部署时，kubectl 是不够的。但是首先，我们有另一个问题要解决:如何从互联网访问部署的应用程序？

部署前面的服务有一个 IP 地址，但是这个地址只存在于 Kubernetes 集群中。这意味着这项服务在互联网上根本不可用！当运行在 Google Cloud Engine 上时，Kubernetes 可以自动配置一个负载平衡器来访问应用程序。如果您没有使用 GCE(像我们一样),您需要做一些额外的工作来实现负载平衡。

直接在主机端口上公开服务是可能的——很多人都是这样开始的——但是我们发现这使 Kubernetes 的很多好处都失效了。如果我们依赖主机中的端口，那么在部署多个应用程序时，我们将会陷入端口冲突。这也使得扩展集群或更换主机变得更加困难。

### 两步负载平衡器设置

我们发现一个更好的方法是在 Kubernetes 集群前配置一个负载均衡器，比如 HAProxy 或 NGINX。我们开始在 AWS 上的 VPN 内运行我们的 Kubernetes 集群，并使用 AWS 弹性负载平衡器将外部 web 流量路由到内部 HAProxy 集群。HAProxy 为每个 Kubernetes 服务配置了一个“后端”,它将流量代理到各个 pod。

这种两步负载平衡器设置主要是为了应对 AWS ELB 有限的配置选项。其中一个限制是它不能处理多个 vhosts。这也是我们使用 HAProxy 的原因。仅仅使用 HAProxy(没有 ELB)也可以工作，但是您必须在 DNS 级别上处理动态 AWS IP 地址。

![](../Images/225854ab978488d2a093f8585cf9fd8a.png)T2】

*图 1:我们负载平衡的两步流程图*

在任何情况下，当创建新的 Kubernetes 服务时，我们都需要一种机制来动态地重新配置负载平衡器(在我们的例子中是 HAProxy)。

Kubernetes 社区目前正在开发一个名为 [入口](http://kubernetes.io/docs/user-guide/ingress/) 的功能。 它可以直接从 Kubernetes 配置外部负载平衡器。目前，这个特性还不能真正使用，因为它还没有完成。去年，我们使用 API 和一个小型开源工具来配置负载平衡。

### 配置负载平衡

首先，我们需要一个存放负载平衡器配置的地方。它们可以存储在任何地方，但是因为我们已经有了[等](https://github.com/coreos/etcd)产品，我们决定将负载平衡器配置存储在那里。我们使用一个叫做[的工具来观察 etcd 中的配置变化，并基于一个模板生成一个新的 HAProxy 配置文件。当一个新的服务被添加到 Kubernetes 时，我们向 etcd 添加了一个新的配置，这将为 HAProxy 生成一个新的配置文件。](http://www.confd.io/)

### Kubernetes:以正确的方式成熟

Kubernetes 中仍有许多未解决的问题，就像负载平衡中普遍存在的问题一样。社区已经认识到了其中的许多问题，并且有一些设计文档讨论了可以解决其中一些问题的新特性。但是想出适用于所有人的解决方案需要时间，这意味着这些特性中的一些在发布之前可能需要相当长的时间。这是一件好事，因为从长远来看，在设计新功能时走捷径是有害的。

这并不意味着今天的 Kubernetes 是有限的。使用这个 API，如果你想现在就开始使用它，就有可能让 Kubernetes 做几乎所有你需要它做的事情。一旦更多的特性出现在 Kubernetes 中，我们就可以用标准的解决方案替换定制的解决方案。

在我们开发了负载平衡的定制解决方案之后，我们的下一个挑战是为我们实现一个基本的部署技术:[蓝绿色部署](http://martinfowler.com/bliki/BlueGreenDeployment.html)。

## Kubernetes 的蓝绿色部署

蓝绿色部署是一种没有任何停机时间的部署。与 滚动更新相反，蓝绿色部署通过启动 运行新版本的副本集群来工作，同时所有旧副本仍然服务于所有实时请求。只有当新的副本集完全启动并运行时，负载平衡器配置才会发生变化，以便将负载切换到新版本。这种方法的一个好处是应用程序总是只有一个版本在运行，降低了处理多个并发版本的复杂性。当副本数量相当少时，蓝绿色部署也能更好地工作。

![](../Images/0cc216dfc4c8785930caf42721e279c4.png)T2】

*图 2:我们与 Kubernetes 的蓝绿色部署*

图 2 显示了编排部署的组件“部署者”。这个组件可以很容易地由您自己的团队创建，因为我们[](https://bitbucket.org/amdatulabs/amdatu-kubernetes-deployer)我们的实现在 Apache 许可下作为[Amdatu](https://bitbucket.org/account/user/amdatulabs/projects/INFRA)保护伞项目的一部分。它还带有一个 web UI 来配置部署。

这种机制的一个重要方面是在重新配置负载平衡器之前对 pod 执行健康检查。我们希望部署的每个组件都能提供健康检查。现在，我们通常会在 HTTP 上为每个应用程序组件添加一个健康检查。

## 使部署自动化

随着 部署者 就位，我们能够将部署与构建管道挂钩。在成功构建之后，我们的构建服务器可以将新的 Docker 映像推送到 Docker Hub 等注册中心。然后，构建服务器可以调用部署器来自动将新版本部署到测试环境中。通过在生产环境中触发部署程序，可以将同一映像提升到生产环境中。

![](../Images/e574b194df80541329f5ce8153a17579.png)

*图 3:我们的自动化容器部署管道*

## 了解你的资源限制

了解我们的 [资源约束](http://kubernetes.io/docs/user-guide/compute-resources/) 在我们开始使用 Kubernetes 的时候是很关键的。您可以在每个 pod 上配置资源请求和 CPU/内存限制。您还可以控制资源保证和爆发限制。

这些设置对于高效运行多个容器非常重要。如果我们没有正确地设置这些设置，容器会经常崩溃，因为它们不能分配足够的内存。

**早点开始，设置和测试约束**。如果没有约束，一切都将运行良好，但是当您在其中一个容器上放置任何严重的负载时，您将会得到一个令人不快的大惊喜。

## 我们如何监控 Kubernetes

当我们建立了 Kubernetes 之后，我们很快意识到在这个新的动态环境中，监控和日志记录是至关重要的。当您处理大量副本和节点时，登录到服务器来查看日志文件不再有效。一旦您开始使用 Kubernetes，您还应该有一个建立集中式日志记录和监控的计划。

### 测井

有大量开源工具可用于日志记录。我们决定使用 [Graylog](https://www.graylog.org/) — 一个优秀的日志记录工具，以及 [Apache Kafka，一个消息系统](http://techbeacon.com/what-apache-kafka-why-it-so-popular-should-you-use-it)从我们的容器中收集和消化日志。容器将日志发送给 Kafka，Kafka 将它们交给 Graylog 进行索引。我们选择让应用程序组件自己向 Kafka 发送日志，这样我们就可以用一种易于索引的格式传输日志。[或者](https://www.loggly.com/blog/top-5-docker-logging-methods-to-fit-your-container-deployment-strategy/)，有一些工具可以从容器外部检索日志，并将它们转发给日志解决方案。

### 监控

出现错误时，Kubernetes 在恢复方面做得非常好。当 pod 由于任何原因崩溃时，Kubernetes 将重新启动它们。当 Kubernetes 运行 replicated 时，最终用户可能甚至不会注意到问题。Kubernetes 的恢复非常有效，以至于我们的容器会因为内存泄漏而在一天内崩溃多次，而没有人(包括我们自己)注意到这一点。

虽然从 Kubernetes 的角度来看这很好，但您可能仍然想知道何时出现了问题。我们使用定制的运行状况检查仪表板来监控 Kubernetes 节点、单个 pod(使用特定于应用程序的运行状况检查)和其他服务，如数据存储。为了实现这样的仪表板，Kubernetes API 再次证明了它的价值。

我们还认为测量负载、吞吐量、应用程序错误和其他统计数据很重要。同样，开源空间有很多优点。我们的应用程序组件将指标发送到一个 [InfluxDB](https://influxdata.com/) 时间序列存储中。我们还使用 [Heapster](https://github.com/kubernetes/heapster) 来收集 Kubernetes 指标。InfluxDB 中存储的指标在 [Grafana](http://grafana.org/) 中可视化，这是一个开源的仪表板工具。InfluxDB/Grafana 堆栈有很多替代方案，其中任何一个都将为跟踪事物如何运行提供很多价值。

## 数据存储和 Kubernetes

许多 Kubernetes 新用户问的一个问题是“我应该如何使用 Kubernetes 处理我的数据存储？”

运行 MongoDB 或 MySQL 之类的数据存储时，您很可能希望数据是持久的。开箱即用，容器在重启时会丢失数据。这对于无状态组件来说没问题，但对于持久性数据存储来说就不一样了。Kubernetes 有 [卷](http://kubernetes.io/docs/user-guide/volumes/) 的概念来处理持久数据。

卷可以通过多种实现方式进行备份，包括主机上的文件、AWS 弹性块存储(EBS)和 [nfs](https://en.wikipedia.org/wiki/Network_File_System) 。当我们研究持久数据的问题时，这提供了一个很好的答案，但它还不是我们运行数据存储的答案。

### 复制问题

在大多数部署中，数据存储也是复制运行的。Mongo 通常在副本集中运行，而 MySQL 可以在主/副本模式下运行。这带来了一些问题。首先，数据存储集群中的每个节点都由不同的 卷支持，这一点很重要。 写入同一个卷会导致数据损坏。另一个问题是，大多数数据存储需要精确的配置来启动和运行集群；节点的自动发现和配置并不常见。

与此同时，运行数据存储的机器通常会针对这种类型的工作负载进行专门调整。高 IOPS 可能是一个例子。对于大多数数据存储来说，扩展(添加/删除节点)也是一项昂贵的操作。所有这些都不太符合 Kubernetes 部署的动态特性。

### 决定不使用 Kubernetes 在生产中运行数据存储

这使我们发现在 Kubernetes 中运行数据存储的好处是有限的。Kubernetes 给我们的动力学真的不能用。设置也比大多数 Kubernetes 部署复杂得多。

因此，**我们没有在 Kubernetes** 内部运行我们的生产数据存储。相反，我们在不同的主机上手动设置这些集群，进行所有必要的调优来优化相关的数据存储。我们在 Kubernetes 中运行的应用程序只是像平常一样连接到数据存储集群。重要的教训是**一旦你有了 Kubernetes** ，你就不必在 Kubernetes 中运行所有的东西。除了数据存储和我们的 HAProxy 服务器，其他所有东西都在 Kubernetes 上运行，包括我们的监控和日志解决方案。

## 为什么我们对下一年与 Kubernetes 的合作感到兴奋

看看我们今天的部署，Kubernetes 绝对棒极了。Kubernetes API 是自动化部署管道的一个很好的工具。部署不仅更可靠，而且速度更快，因为我们不再需要处理虚拟机。我们的构建和部署变得更加可靠，因为测试和运输容器变得更加容易。

我们现在看到，这种新的部署方式是必要的，以跟上行业中其他开发团队的步伐，这些团队更加频繁地推出部署，并降低了他们这样做的开销。

### 成本计算

看看成本，这个故事有两个方面。要运行 Kubernetes，需要一个 etcd 集群和一个主节点。虽然运行这些组件不一定很昂贵，但对于非常小的部署来说，这种开销可能相对昂贵。对于这些类型的部署，最好使用托管解决方案，比如 Google 的容器服务。

对于大型部署，很容易节省大量服务器成本。在这些部署中，运行 etcd 和主节点的开销并不大。Kubernetes 使得在相同的主机上运行许多容器变得非常容易，从而最大限度地利用了可用资源。这减少了所需服务器的数量，直接为您节省了资金。当运行 Kubernetes 听起来很棒，但运行这样一个集群的运营方面似乎不太有吸引力时，有许多托管服务可以考虑，包括云 RTI，这是我的团队正在努力的。

## Kubernetes 的光明未来

在预发布版本中运行 Kubernetes 是一项挑战，有时几乎不可能跟上(突破性的)新版本。在过去的一年中，Kubernetes 的开发一直在以光速进行，该社区已经发展成为开发人才的合法发电站。很难相信在短短一年多的时间里取得了多大的进步。

#### 不断学习