# 人工智能的 UX-图书馆-谷歌设计

> 原文:[https://design.google/library/ux-ai/?utm_source=wanqu.co&UTM _ campaign = Wanqu+Daily&UTM _ medium =网站](https://design.google/library/ux-ai/?utm_source=wanqu.co&utm_campaign=Wanqu+Daily&utm_medium=website)

## 信任和自我效能

我们投资 Clips 的原因之一是因为向世界展示设备上和隐私保护机器学习的重要性是多么重要——更不用说它的非凡能力(例如，它使用更少的电力，这意味着设备不会变得很热，并且处理可以快速可靠地进行，而不需要互联网连接)。相机是一件非常私人的物品，我们努力确保它——硬件、智能和内容——最终属于您，而且只属于您一个人。这就是为什么一切——我是说一切——都留在相机上，直到用户说不。

**概念预算**

着眼于信任和自我效能，我们在 UI 设计上也非常用心。在项目开始的时候，这意味着我们需要完成一些有趣的假设，比如人工智能产品需要有多“出位”。

当我们在大脑中寻找未来技术的参考点时，许多设计师会跳转到像《少数派报告》和《银翼杀手》这样的电影中看到的沉浸式体验。但是想象一下，向用户解释类似于*少数派报告*中的用户界面是多么疯狂的事情:*在这里，伸出你的手臂，等待两秒钟，抓住稀薄的空气，然后在逆时针旋转你的手的同时疯狂地向右甩。很简单！*几乎每个科幻的 faux UI 都犯有类似的东西；好像交互模型的复杂性需要与它所驱动的系统的复杂性保持同步。但在我们早期的设计阶段，我们曾一度处于这种状态，我们成功了，主要有三个原因:

*   我们在一个明显模拟的环境中向人们展示虚假的内容，在那里他们与图像没有真正的联系。注意这个问题不是 AI 独有的；当你把人们带到可用性实验室时，这通常是一个令人困惑的因素。
*   我们每天都被说同一种语言的人包围着；对人工智能未来的深入思考。我们犯了一个错误，那就是与其他人会提出的参考点失去了联系。
*   我们认为我们的新设计超级酷，所以当人们没有立即理解时，我们给自己一个健康的宽恕。