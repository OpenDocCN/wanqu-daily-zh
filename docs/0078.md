# 扩展 Pinterest——两年内从每月 0 到 10 亿的页面浏览量——高可扩展性——

> 原文:[http://high scalability . com/blog/2013/4/15/scaling-Pinterest-from-0-to-10s-of-10 亿次页面浏览量-a.html？UTM _ source = Wanqu . co&UTM _ campaign = Wanqu+Daily&UTM _ medium = website](http://highscalability.com/blog/2013/4/15/scaling-pinterest-from-0-to-10s-of-billions-of-page-views-a.html?utm_source=wanqu.co&utm_campaign=Wanqu+Daily&utm_medium=website)

![](../Images/824ae269f3bd907a2a05b2053f990ad9.png)

Pinterest 一直处于指数增长曲线上，每个半月翻一番。他们在两年内从每月 0 到 10 亿的页面浏览量，从 2 个创始人和 1 个工程师到 40 多个工程师，从一个小型 MySQL 服务器到 180 个 Web 引擎，240 个 API 引擎，88 个 MySQL 数据库(cc2.8xlarge) + 1 个 slave，110 个 Redis 实例和 200 个 Memcache 实例。

惊人的增长。那么 Pinterest 的故事是什么呢？为了讲述他们的故事，我们请来了我们的吟游诗人，Pinterest 的 [【亚斯旺思】](http://www.linkedin.com/in/yashh) 和 [马蒂·韦纳](http://pinterest.com/martaaay/) ，他们在题为 [的演讲中讲述了 Pinterest 架构演变的戏剧性故事。这是一年半前他们希望听到的谈话，当时他们正在快速扩展，有许多选项可供选择。他们做了很多错误的选择。](http://www.infoq.com/presentations/Pinterest)

这是一次伟大的演讲。充满了惊人的细节。它也非常实用，脚踏实地，包含了几乎任何人都可以采用的策略。强烈推荐。

我最喜欢的两堂课是:

1.  当增长可以通过添加更多同样的东西来处理时，建筑就是在做正确的事情。你希望能够通过向一个问题投入资金来扩大规模，这意味着在你需要的时候向一个问题投入更多的盒子。如果你的建筑能做到这一点，那么你就是黄金。
2.  当你把某样东西推到极限时，所有的技术都会以自己特殊的方式失败。这导致他们在评估工具选择时更倾向于:成熟的；真的好简单；众所周知和喜欢的；支撑良好；一贯表现良好的员工；尽可能无故障；免费。根据这些标准，他们选择了 MySQL、Solr、Memcache 和 Redis。卡珊德拉和蒙戈被抛弃了。

这两个教训是相互关联的。遵循(2)中原则的工具可以通过添加更多的盒子来扩展。随着负载的增加，成熟的产品应该会有更少的问题。当你遇到问题时，你至少会有一个社区来帮助解决它们。当你的工具太复杂、太挑剔时，你会碰壁到爬不过去。

我认为这是整个演讲中最精彩的部分，讨论了为什么分片比集群更好，你会看到通过增加资源来增长的主题，很少的失败模式，成熟，简单，良好的支持，都实现了。请注意，他们选择的所有工具都是通过添加碎片来增长的，而不是通过集群。关于他们为什么喜欢分片以及如何分片的讨论非常有趣，可能会涉及到你以前从未考虑过的领域。

现在，让我们看看 Pinterest 是如何扩展的:

## 基础知识

*   图钉是一个包含其他信息的图片，它描述了什么对用户来说是重要的，并链接到他们找到它的地方。

*   Pinterest 是一个社交网络。可以跟人跟板。

*   数据库:他们有用户有板，板有 pins 关注和表达关系；认证信息。

## 【2010 年 3 月推出——发现自我的时代

在这一点上，你甚至不知道你要制造什么样的产品。你有想法，所以你在快速迭代和改变事物。因此，您最终会得到许多奇怪的 MySQL 小查询，而这些查询在现实生活中是绝对做不到的。

这个早期的数字:

*   2 位创始人

*   1 名工程师

*   Rackspace

*   1 个小型网络引擎

*   1 个小型 MySQL 数据库

## 【2011 年 1 月

仍处于秘密模式，产品正在根据用户反馈进行改进。数字:

*   亚马逊 EC2 + S3 + CloudFront

*   1 个 NGinX，4 个 Web 引擎(用于冗余，并非真正用于负载)

*   1 个 MySQL DB + 1 个读取从站(以防主站宕机)

*   1 个任务队列+ 2 个任务处理器

*   1 MongoDB(用于计数器)

*   2 名工程师

## 到 2011 年 9 月——实验的时代

开始了疯狂的奔跑，每个半月翻一番。疯狂的增长。

*   当你成长得如此之快时，每晚每星期都会有东西坏掉。

*   在这一点上，你会读到很多白皮书，说只需添加一个盒子，就大功告成了。所以他们开始加入很多技术。它们都坏掉了。

*   结果，你会得到一个非常复杂的画面:

    *   亚马逊 EC2 + S3 + CloudFront

    *   2NGinX，16 个 Web 引擎+ 2 个 API 引擎

    *   5 个功能分片的 MySQL DB + 9 个读取从站

    *   4 个卡桑德拉节点

    *   15 个成员节点(3 个独立的集群)

    *   8 个 Memcache 节点

    *   10 个中继节点

    *   3 个任务路由器+ 4 个任务处理器

    *   4 个弹性搜索节点

    *   3 个 Mongo 星团

    *   3 名工程师

*   5 种主要的数据库技术仅针对他们的数据。

*   发展如此之快，以至于 MySQL 炙手可热，所有其他技术都被推到了极限。

*   当你把某样东西推到极限时，所有这些技术都会以它们自己特殊的方式失败。

*   开始放弃技术，问自己真正想成为什么。对一切进行了大规模的重建。

## 【2012 年 1 月-成熟年龄

*   在一切都被重新构建之后，系统现在看起来像这样:

    *   亚马逊 EC2+S3+ELB 阿卡迈

    *   90 个 Web 引擎+ 50 个 API 引擎

    *   66 个 MySQL 数据库(m1.xlarge) +每个数据库 1 个从数据库

    *   59 个累犯

    *   51 个 Memcache 实例

    *   1 个 Redis 任务管理器+ 25 个任务处理器

    *   分片 Solr

    *   6 名工程师

*   现在在 MySQL、Redis、Memcache 和 Solr 上。就是这样。优势在于它非常简单，而且是成熟的技术

*   网络流量保持同样的速度增长，iPhone 流量也开始增加。

## 2012 年 10 月 12 日——回归时代

大约是一月份的 4 倍。

## 为什么选择亚马逊 EC2/S3？

*   相当好的可靠性。数据中心也会宕机。多租户增加了一些风险，但并不坏。

*   良好的报告和支持。他们有非常好的建筑师，他们知道问题所在

*   漂亮的外围设备，尤其是在你成长的时候。您可以在 App Engine 中运行，并与他们的托管缓存、负载平衡、map reduce、托管数据库以及所有其他您不必自己编写的部分进行交流。你可以在亚马逊的服务上进行引导，然后当你有了工程师之后再进行改进。

*   几秒钟内即可获得新实例。云的力量。尤其是有了两位工程师，您不必担心容量规划或等待两周才能获得 memcache。几分钟内可以添加 10 个内存缓存。

*   缺点:选择有限。直到最近，你可以得到固态硬盘，你不能得到大内存配置。

*   优点:选择有限。你不会得到很多不同配置的盒子。

## 为什么选择 MySQL？

*   真正成熟。

*   非常坚固。对他们来说，它从未停机，也从未丢失过数据。

*   你可以租用它。很多工程师都知道 MySQL。

*   对请求速率的响应时间线性增加。当请求率达到峰值时，一些技术不会很好地响应。

*   非常好的软件支持——xtra backup、Innotop、Maatkit

*   伟大的社区。得到问题的答案很容易。

*   来自 Percona 等公司的大力支持。

*   免费——当你最初没有任何资金时，这很重要。

## 为什么选择 Memcache？

*   非常成熟。

*   真简单。这是一个插有插座的散列表。

*   一贯良好的表现

*   著名的，受欢迎的。

*   一贯良好的表现。

*   从不崩溃。

*   免费

## 为什么要再说？

*   不成熟，但真的很好，也很简单。

*   提供了多种数据结构。

*   具有持久性和复制性，可以选择如何实现它们。如果你想要 MySQL 风格的持久性，你可以拥有它。如果你不想要坚持，你可以拥有它。或者如果你想要 3 小时的坚持，你可以做到。

    *   你的主页在 Redis 上，每 3 小时保存一次。没有 3 小时复制。他们每 3 小时备份一次。

    *   如果存储数据的盒子坏了，那么它们只能备份几个小时。它并不完全可靠，但更简单。不需要复杂的持久化和复制。这是一个更简单、更便宜的架构。

*   著名的，受欢迎的。

*   一贯良好的表现。

*   少数故障模式。您需要了解一些微妙的故障模式。这就是成熟的来源。学会它们，然后忘掉它。

*   免费

## Solr

*   一款非常棒的起床和出门型产品。安装它，几分钟后，你是索引。

*   不超过一个框。(最新版本并非如此)

*   尝试了弹性搜索，但在他们的规模下，它在处理大量小文档和大量查询时遇到了麻烦。

*   现在使用 Websolr。但是他们有一个搜索队，他们会自己搜索。

## 聚类与分片

*   在快速增长期间，他们意识到需要均匀分布数据，以应对不断增长的负载。

*   定义了一个范围来讨论这个问题，他们提出了一系列在聚类和分片之间的选择。

### 集群化——一切都是自动的:

*   示例:Cassandra、MemBase、HBase

*   结论:太可怕了，也许在未来，但现在它太复杂了，有太多的故障模式。

*   属性:

    *   数据自动分发

    *   数据可以移动

    *   重新平衡以分配容量

    *   节点相互通信。很多相声，八卦，谈判。

*   优点:

    *   自动扩展您的数据存储。至少白皮书是这么说的。

    *   易于设置。

    *   对您的数据进行空间分布和集中管理。您可以在不同的地区建立数据中心，由数据库来管理。

    *   高可用性

    *   负载均衡

    *   无单点故障

*   缺点(来自第一手经验):

    *   仍然相当年轻。

    *   从根本上复杂。一整束节点必须对称一致，这是生产中很难解决的问题。

    *   社区支持较少。社区中存在不同产品线的分裂，因此每个阵营中的支持都较少。

    *   具有工作知识的工程师越来越少。大概大部分工程师都没用过 Cassandra。

    *   艰难而恐怖的升级机制。可能与他们都使用 API 并相互交流有关，所以你不希望他们混淆。这导致复杂的升级路径。

    *   集群管理算法是一种 SPOF。如果有一个错误，它会影响每个节点。这让他们倒下了 4 次。

    *   集群管理器是复杂的代码，在具有以下故障模式的所有节点上复制:

        *   数据重新平衡中断。带来一个新的盒子，数据开始复制，然后就卡住了。你是做什么的？没有工具可以弄清楚到底发生了什么。没有社区帮助，所以他们被困住了。他们又回到了 MySQL。

        *   所有节点的数据损坏。如果有一个 bug 将坏消息散布到所有这些文件的写日志中，并且压缩或其他机制停止了，该怎么办？您的读取延迟会增加。你所有的数据都搞砸了，数据都没了。

        *   平衡不当，不容易解决。很常见。您有 10 个节点，您会注意到所有节点都在一个节点上。有一个手动过程，但它将负载重新分配回一个节点。

        *   数据权限失效。聚类方案非常聪明。在一个案例中，他们引入了一个新的次级。在大约 80%的情况下，辅助节点说它是主节点，主节点转到辅助节点，您已经丢失了 20%的数据。丢失 20%的数据比丢失所有数据更糟糕，因为您不知道自己丢失了什么。

### 分片-一切都是手动的:

### 什么时候切分？

*   如果你的项目有几 TBs 的数据，那么你应该尽快分片。

*   当 Pin 表达到 10 亿行时，索引耗尽了内存，它们被交换到磁盘。

*   他们挑选了最大的一张桌子，放入自己的数据库。

*   然后，他们用完了单一数据库上的空间。

*   然后他们不得不分开。

### 过渡到分片

*   以功能冻结开始过渡过程。

*   然后他们决定如何分割。希望执行最少的查询，使用最少的数据库来呈现单个页面。

*   移除所有 MySQL 联接。因为这些表可能被装载到单独的分区中，所以连接不起作用。

*   增加了一吨缓存。基本上每个查询都必须被缓存。

*   步骤如下:

    *   1 DB +外键+联接

    *   1 DB +反规格化+缓存

    *   1 DB +读取从设备+高速缓存

    *   几个功能分片的数据库+读从+缓存

    *   ID 分片数据库+备份从数据库+缓存

*   由于奴隶滞后，早期读取奴隶成为一个问题。一个读操作将进入从设备，而主设备还没有复制记录，所以看起来像是丢失了一个记录。避开所需缓存。

*   他们有后台脚本来复制数据库曾经做的事情。检查完整性约束和引用。

*   用户表未共享。他们只是使用一个大数据库，并对用户名和电子邮件有唯一性约束。如果用户不是唯一的，插入用户将会失败。然后，他们在他们的分片数据库中进行大量的写操作。

### 如何切分？

*   看了看卡珊德拉的戒指模型。看了看 Membase。看了看 Twitter 的鸡胗。

*   确定:你在节点间移动的数据越少，你的架构就越稳定。

*   Cassandra 有一个数据平衡和权限问题，因为节点不确定谁拥有哪部分数据。他们决定应用程序应该决定数据应该去哪里，这样就不会有问题。

*   预测他们未来五年的增长，并在头脑中预先存储容量计划。

*   最初创造了许多虚拟碎片。8 台物理服务器，每台 512 数据库。所有的数据库都有所有的表。

*   为了实现高可用性，它们总是以多主复制模式运行。每个主节点被分配到不同的可用性区域。出现故障时，切换到另一个主节点，并引入一个新的替换节点。

*   数据库负载增加时:

    *   查看代码提交，看看是否出现了新特性、缓存问题或其他问题。

    *   如果只是负载增加，他们会拆分数据库，并告诉应用程序在新的主机上查找数据。

    *   在分割数据库之前，他们为那些主服务器启动从服务器。然后，他们用新的数据库分配交换应用程序代码。在过渡期间的几分钟内，写入仍会写入旧节点，并复制到新节点。然后在节点之间切割管道。

### ID 结构

*   64 位:

    *   碎片 ID: 16 位

    *   类型:10 位-引脚、板卡、用户或任何其他对象类型

    *   本地 ID -表内 ID 的剩余位。使用 MySQL 自动增量。

*   Twitter 使用映射表将 id 映射到物理主机。这需要查找。由于 Pinterest 在 AWS 上运行，而 MySQL 查询需要大约 3 毫秒，他们认为这种额外的间接方式不起作用。他们把地点建在 ID 里。

*   新用户随机分布在各个碎片上。

*   一个用户的所有数据(引脚、电路板等)都集中在同一个碎片上。巨大的优势。例如，呈现用户配置文件不需要多次跨片查询。它很快。

*   每个电路板都与用户配置在一起，因此可以从一个数据库中渲染电路板。

*   足够 65536 个碎片的碎片 id，但他们一开始只打开了 4096 个，他们会横向扩展。当用户数据库变满时，他们将开放更多的碎片，并允许新用户访问新的碎片。

### 查找

*   例如，如果他们有 50 次查找，他们会拆分 id 并并行运行所有查询，因此延迟是最长的等待。

*   每个应用程序都有一个配置文件，将一个分片范围映射到一个物理主机。

    *   “sharddb001a”: : (1, 512)

    *   "sharddb001b": : (513，1024) -备份热主

*   如果你想查找一个 ID 属于 sharddb003a 的用户:

    *   将 ID 分解成各个部分

    *   在分片图中执行查找

    *   连接到 shard，去数据库找类型，用本地 ID 找到正确的用户，返回序列化的数据。

### 对象和映射

*   所有数据要么是一个对象(图钉、图板、用户、评论)，要么是一个映射(用户有图板，图钉有赞)。

*   对于对象，本地 ID 映射到 MySQL blob。blob 格式始于 JSON，但正在向 serialized thrift 发展。

*   对于映射，有一个映射表。您可以为用户请求所有的板。id 包含时间戳，因此您可以看到事件的顺序。

    *   有一个反向映射，多对多表，来回答“给我所有喜欢这个 pin 的用户”类型的查询。

    *   模式命名方案为名词 _ 动词 _ 名词:用户 _ 喜欢 _ 引脚，引脚 _ 喜欢 _ 用户。

*   查询是主键或索引查找(无连接)。

*   数据不会像集群那样在数据库间移动。例如，一旦用户登陆到 shard 20，并且所有的用户数据都被集中在一起，它就永远不会移动。64 位 ID 包含碎片 ID，因此无法移动。您可以将物理数据移动到另一个数据库，但是它仍然与同一个碎片相关联。

*   所有的表都存在于所有的碎片上。没有特殊的碎片，不包括用于检测用户名冲突的庞大用户表。

*   不需要改变模式，新的索引需要新的表。

    *   由于键值是一个 blob，您可以在不破坏模式的情况下添加字段。每个 blob 都有版本控制，因此应用程序将检测版本号，并将记录更改为新格式并写回。所有数据不需要立即更改，它们会在读取时升级。

    *   巨大的成功，因为修改一张桌子需要几个小时或几天的时间。如果你想要一个新的索引，你只需要创建一个新的表并开始填充它。当你不想要它的时候，就把它扔掉。(没有提到这些更新如何是交易安全的)。

### 呈现用户档案页面

*   从 URL 获取用户名。去单个巨大的数据库查找用户 ID。

*   获取用户 ID，并将其拆分成多个组成部分。

*   选择碎片并前往该碎片。

*   从用户中选择正文，其中 id = < local_user_id >

*   从用户标识= <用户标识> 的用户标识中选择板标识

*   从 id IN ( < boards_ids > ) 的板卡中选择 body

*   从 board_has_pins 中选择 pin_id，其中 board_id= < board_id >

*   从 id 在(pin_ids) 的引脚中选择车身

*   大多数调用都是由缓存(memcache 或 redis)提供的，所以实际上数据库查询并不多。

### 脚本

*   当迁移到分片架构时，您有两种不同的基础设施，一种是旧的非共享系统，另一种是新的分片系统。脚本就是将旧东西转换成新东西的所有代码。

*   他们移动了 5 亿个引脚和 16 亿个跟随行，等等

*   低估了项目的这一部分。他们认为将数据放入碎片需要 2 个月，实际上需要 4-5 个月。请记住，这是在功能冻结期间。

*   应用程序必须始终写入新旧基础架构。

*   一旦确信您的所有数据都在新的基础架构中，然后将您的读取指向新的基础架构，慢慢增加负载并测试您的后端。

*   建立了一个脚本农场。动员更多的工人更快地完成任务。他们会做一些任务，比如将这些表转移到新的基础设施上。

*   破解了 Pyres 的副本，这是 Github 的 Resque 队列的 Python 接口，Resque 队列建立在 redis 之上。支持优先级和重试。这是如此之好，他们用柴堆代替了芹菜和兔子。

*   过程中的许多错误。用户发现了诸如缺板之类的错误。不得不多次运行该过程，以确保没有暂时性错误阻止数据正确移动。

## 开发

*   最初试图给开发者一部分系统。每个人都有自己的 MySQL 服务器，等等，但事情变化太快，这不起作用。

*   去了脸书的模式，在那里每个人都可以访问任何东西。所以你必须非常小心。

## 未来方向

## 吸取的经验教训

*   它会失败的。保持简单。

*   保持乐趣。有很多新人加入这个团队。如果你只是给他们一个庞大复杂的系统，那就没什么意思了。保持架构简单是一大胜利。新工程师从第一周就开始贡献代码。

*   当你把某样东西推到极限时，所有这些技术都会以它们自己特殊的方式失败。

*   集群管理算法是一种 SPOF。如果有一个错误，它会影响每个节点。这让他们倒下了 4 次。

*   为了应对快速增长，您需要均匀分布数据，以应对不断增长的负载。

*   您在节点间移动的数据越少，您的架构就越稳定。这就是为什么他们选择了分片而不是集群。

*   面向服务的架构规则。它隔离功能，帮助减少连接，组织团队，组织支持，并提高安全性。

*   问问你自己，你真正想成为什么样的人。放弃符合这一愿景的技术，即使你不得不重新构建一切。

*   不要因为丢失了一点数据而惊慌失措。它们将用户数据保存在内存中，并定期将其写出。丢失意味着只有几个小时的数据丢失，但最终的系统更简单、更健壮，这才是最重要的。

## 相关文章