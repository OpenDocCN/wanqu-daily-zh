# 分割 Asana 数据库

> 原文：<https://eng.asana.com/2015/04/sharding-is-bitter-medicine/?utm_source=wanqu.co&utm_campaign=Wanqu+Daily&utm_medium=website>

[Percona](http://www.percona.com/blog/2009/08/06/why-you-dont-want-to-shard/) 几年前提到过这个，现在依然如此。分片通常不是一个好主意。在 Asana，我们将此推迟了多年，并从中获得了许多好处:

*   我们的应用程序逻辑更简单。
*   我们有更多的自由来改变我们的数据模型。
*   我们可以把更多的时间花在不太重要的事情上。

延迟分片对我们来说也很容易:我们使数据库模式更加紧凑，AWS 发布了更大的 [RDS](http://aws.amazon.com/rds/) 实例。如果我们坚持得足够久，我们可能会在 AWS 的新[极光](http://aws.amazon.com/rds/aurora/)上。

出于空间方面的考虑，我们最终被迫分开。我们的数据库是一个 3TB 的 RDS 实例，我们使用了一半的空间，并且增长强劲。单一实例也是痛苦的来源。负载是一个问题，备份需要很长时间，数据库是一个巨大的单点故障。

在这篇文章中，我将谈谈我们所做的一些与分片相关的工作。我将介绍我们预期的工作及其结果，一些为我们带来回报的最佳实践，以及一些我们一路走来遇到的惊喜。

### 已知作品

#### 决定如何切分

没有单一的“正确方法”来分割数据。相反，分割数据的正确方式取决于你的应用程序。在 Asana，我们决定我们切分的正确方式是“通过工作空间”。我们的读取和写入几乎总是被限制在单个工作区内，因此按工作区分片让我们继续使用单个事务进行大部分写入，并继续使用 mysql 查询进行大部分读取(而不是依赖于应用程序级连接)。这些特性——事务和丰富的查询——是我们最初使用关系数据库的原因，所以保留它们对我们来说很重要。此外，按工作空间分片意味着用户通常只与少数数据库交互，因此如果数据库出现问题，只会影响一小部分用户。

然而，按工作空间分片也有缺点。有些数据不适合工作空间，因此这些数据需要特殊处理。为此，我们创建了一个单独的“主碎片”。此外，按工作空间分片意味着我们的分片比按对象分片要大得多，所以如果工作空间变得太大，我们就需要改变分片行为来适应它。但总的来说，按工作空间分片似乎比我们的其他选择要好得多。

#### 更新应用程序

分片的主要部分是读、写和在数据库之间迁移分片的能力。其中，我们最担心的是读取，因为我们预计会有很多跨分片的查询，需要重写才能在客户端工作。相比之下，我们认为写操作很容易，因为我们只能提供一些跨分片写操作的例子。这些预期结果是相反的:实际上，读操作非常简单，写操作比预期的要差得多。

写作很难进入状态。由于跨分片写操作不能以事务方式完成，所以每个跨分片写操作都需要仔细检查，以确保它是等幂的。通常，这意味着重写应用程序的这一部分。这些重写中有许多又长又乱，以至于他们花了好几个星期才写好。

我们仍然没有达到我们希望的状态。我们偶尔会使用嵌套事务，在这种情况下，我们会在对碎片 a 执行事务的过程中对碎片 B 执行操作。这使得代码很难正确执行，并且我们会留下一些不直观且重构起来很危险的代码。例如，在如下代码块中

```
runInTransactionAgainstShard(user.shard()):
    user.addNewEmail(email)
    workspace = getWorkspaceForEmailDomain(email)
    runInTransactionAgainstShard(workspace.shard()):
        workspace.addUser(user)
    assert False
```

我们会将用户添加到工作区，但不会添加她的新电子邮件地址。

#### 迁移数据

对于从主数据库中迁移碎片，我们有几个目标。

*   不要丢失任何数据。
*   最大限度减少停机时间。
*   快速迁移数据。

这些目标通常不一致。例如，离线时快速安全地复制一个碎片要容易得多。最终，我们决定在副本碎片处于活动状态时使用它们，当我们过渡到使用副本时，它们会短暂地不可用。我们使用的基本方法很简单:我们启动一个进程来复制一个碎片，启动另一个进程来重新复制任何发生变化的对象。一旦复制完成，我们就更新一个 shard-to-database 记录，表明这个 shard 现在位于新的数据库中。在实践中，这个迁移过程甚至允许我们最大的碎片在几秒钟内不可用的情况下被移动。

这样做需要在应用程序层做一些簿记工作。首先，我们维护一个已修改对象的队列，这样我们就可以在迁移过程中重新复制任何被修改的对象。我们已经有了这样一个允许搜索索引的系统，所以这不需要额外的工作。其次，我们在每个数据库上维护一个“碎片锁”表。这个表保存了`shard_id, shard_is_on_this_database`的行，每当我们针对一个碎片启动一个事务时，我们就在这个行上获取一个共享锁，并确认`shard_is_on_this_database`为真。当我们切换保存实时碎片的数据库时，我们在原始数据库上将`shard_is_on_this_database`更新为 false。这解决了竞争情况，即在我们从旧数据库中转移出来之后，一个进程可能会写入旧数据库。

### 获得回报的最佳实践

#### 自动化测试

通过我们的[大型自动化测试套件](https://blog.asana.com/2014/12/testville-beyond-massive-parallel-testing-asana/)，分片的风险大大降低(因此也更容易)。我们的测试捕捉到了许多 bug，只漏掉了几个；被遗漏的 bug 通常出现在我们覆盖率低的地方。一般来说，发现错误的测试并不是针对特定分片的——它们只是测试应用程序特定行为的单元测试。

#### 喂狗

Asana 是一个中等规模的 Asana 客户，在我们将内部版本部署给其他客户之前，我们会不断地进行内部版本的工作。类似地，当迁移碎片时，我们迁移的第一个非测试碎片是 Asana 碎片。这种方法效果很好，因为即使在广泛的测试之后，第一次迁移也会导致轻微的数据损坏。问题是我们的迁移脚本复制了关联，但是没有删除它们。例如，如果在迁移过程中从列表中删除了某个任务，则该任务可能会在迁移完成后重新出现在列表中。由于我们是在 dogfooding 中发现这一点的，我们可以通过向同事道歉并要求他们重做少量工作来修复数据。****T3】****

 **### 意想不到的事

#### 数据转换

在分片的过程中，我们发现多年来我们积累了大量的数据欠账，现在需要偿还。我们发现这一点是因为我们可以通过多种途径来确定一个对象的碎片，但它们并不都一致。修复这种数据需要大量的修补工作。一些数据可以通过删除违规对象来保持一致，例如当这些对象本质上是临时的或者用户无法访问时。一些数据可以通过改变它所在的碎片来保持一致。我们经常会修正一种对象，却发现这只是移动了不一致性。

我们通过多种手段发现了这些数据问题。在应用程序中，我们有关于加载对象的断言。例如，如果我们查询碎片 A 上的对象，这些断言将检查每个返回的对象是否同意它在碎片 A 上。一旦断言出错，我们知道有问题，我们就编写离线查询来报告数据库中的每个碎片不一致。为了完整性，查询是必要的，但是断言对于首先检测问题并帮助确认我们实际上已经解决了问题是至关重要的。

#### 用户发现的错误

在产品中启用分片比 beta 测试更加多事，我们的用户发现了少量未经充分测试的代码路径，我们自己也没有发现。通常，当服务器进程在不合适的时间崩溃，并使数据处于我们无法自动恢复的状态时，这些错误就会出现。这些问题主要集中在用户注册或加入新工作区上——这是我们个人不经常做的两件事，因此仍未在我们的测试集群中进行测试。他们还要求产品在特定时间崩溃，然后重试一个动作——这是我们根本没有测试过的。

#### 数据丢失

迁移几周后，我们遇到了客户数据方面唯一已知的问题。计划脚本不如迁移脚本本身强大，它们设法为单个域计划两个同时进行的迁移。我们的迁移被安排为“将碎片 X 移动到数据库 Y”，特别是，无论碎片当时在哪个数据库上，它们总是从迁移*。这意味着，一旦第一次迁移完成，第二次迁移会尝试将 shard X 从数据库 Y 迁移到数据库 Y*

```
deleteRowsOnTargetDatabase()
readRowsFromSourceDatabase()
writeRowsToTargetDatabase()
```

令人欣慰的是，迁移以令人难以置信的速度从新数据库中删除了数据，碎片很快就不可用了。这意味着碎片上的用户不能输入新数据，所以当我们再次切换碎片来读取原始数据库时，这些用户只是丢失了他们最后几分钟的写操作。我们联系了工作区中的用户，让他们知道发生了什么，修复了我们的脚本以拒绝从数据库迁移到数据库本身，并重新开始迁移。

#### 燃烧率讽刺

随着我们继续迁移，我们密切关注主数据库的磁盘空间下降的速度。我们定期估计我们什么时候会用完空间，并在日历上标记出来。如果我们能让这个速率足够低，以至于耗尽空间的日期是在未来十年，我们就完成了。几周后，这一比率下降到开始时的一半，但随后就稳定下来了。

数据的长尾似乎比我们预期的要大得多，这意味着我们当前的数据迁移速度不够快。我们开发了更多的 EC2 实例，并开始更积极地进行迁移。当我们几天后检查数据库时，我们使用数据的速度比以前更快了。恐慌平息后，我们意识到迁移本身使用了大量的簿记空间，并且所有这些空间都在主数据库上使用。幸运的是，对于簿记应该在哪里没有要求。我们更新了我们的迁移，将它们的元数据保存在不同的数据库中，结果是我们的刻录率直线下降。

### 摘要

分片是一项繁重的工作，你应该尽可能的推迟。通过延迟分片，你可以花更多的时间在你的应用上，你积累了你可能永远不需要偿还的技术债务。即使您最终需要切分，这种权衡也是值得的。**