# 快速和慢速思考的机器。在过去的几年里，有… |伊泰·古拉里|司法

> 原文：<https://blog.judicata.com/machines-thinking-fast-and-slow-ec7db295b642?utm_source=wanqu.co&utm_campaign=Wanqu+Daily&utm_medium=website>

# 快速和慢速思考的机器

在过去的几年里，无论是在硅谷还是其他地方，都有越来越多的人认为人工智能正在接近人类的智能水平。

有些建议是含蓄的，比如将人形和类似计算机的图像融合在一起的图片:



其他人则直截了当，比如谷歌人工智能主管约翰·詹南德雷亚(John Giannandrea)将电脑比作人类的孩子(在接受《财富》杂志采访时):

> “电脑就像一个 4 岁的孩子。”

Giannandrea 后来收回了那句话:

> "它们远不像 4 岁儿童那样通用."

然而，信息是明确的:人工智能正在朝着(并接近)人类水平的智能发展(即使它仍然只是像孩子一样)。

但这真的是真的吗？

# 唐尼

考虑一个逻辑难题:

> 唐尼是总统。唐尼已经 71 岁了。总统多大了？

这不是一个难题。答案是 71。大多数 4 岁的孩子都能算出来。

然而对谷歌来说，答案是 56。(或者说，直到 2017 年 10 月 10 日。在[错误被公开](https://news.ycombinator.com/item?id=15423808)后，他们大概手动修改了它。





谷歌*似乎*知道两个谓词位的知识:唐纳德·特朗普是总统，唐纳德·特朗普已经 71 岁了。但是谷歌的答案是错误的。

为什么？

行为科学提示了原因。

# *思考，快与慢*

丹尼尔·卡内曼在《思考，快与慢》一书中描述了人类思维的两种不同模式:“系统 1”是快速的、自动的、潜意识的；“系统 2”更慢，更有计算能力，也更有逻辑性。

系统 1 — *思维敏捷* —可以做类似解“2+2=？”这样的事情吗？完成短语“战争和…”

系统 2 — *思考慢* —可以数一页纸的元音数，推理复杂的逻辑问题。

浓缩到他们的本质:思考快速识别，思考缓慢的原因。

像深度神经网络这样的机器学习算法——今天人工智能进步的主要驱动力——是系统 1 思维模式的模型。它们是认知的工具。他们被教导学习特定的输入，每当他们看到看起来像他们所学习的输入(或类似的东西)时，就会发出特定的输出。他们在快速思考。

这就是为什么谷歌聊天机器人告诉我们“2+2”是“4”，而“10 减 2”是“72”。这也有助于解释为什么谷歌告诉我们总统 56 岁——谷歌在回答“总统多大了”这个问题时依靠的是识别技术，而不是推理

因此，如果我们在人工智能方面取得的进步主要是识别和思维的快速变化，那么是什么推动了计算机正在接近人类智能的信念呢？

在基本层面上，似乎人们看到机器学习算法执行人类级别的任务，他们*推断*。

1.  他们假设机器学习算法得到答案的原因与人得到答案的原因相似。
2.  然后，他们假设机器学习算法在类似的任务上表现同样出色。
3.  他们最终认为，机器学习正在顺利完成只有人类才能完成的更复杂的任务。

虽然这种想法是合乎逻辑的，但潜在的假设是错误的。

# *类似原因*

让我们首先考虑这样一个假设，即机器学习算法得出它们的答案的原因与人们得出答案的原因相同。几个有趣的例子——一个是漫画，一个是关注——证明这是错误的。

去年，The Verge [报道了弗吉尼亚理工大学 Dhruv Batra 教授的两名学生 Abhishek Das 和 Harsh Agrawal 的研究:](https://www.theverge.com/2016/10/10/13224930/ai-deep-learning-limitations-drawbacks)

> 这两个人向两个人和两个专门研究物体识别问题的神经网络询问了关于某些图像的问题，然后观察他们在这些图像中的位置，以比较他们的决策过程。所以，当一个人和一台电脑被问到“这张图片中这个人的鞋子是什么颜色的？”你可能希望他们都看图片的底部，那里你最有可能看到鞋子。但是 Das 和 Agrawal 发现，情况并非总是如此。
> 
> 例如，在研究中的一个问题中，向人类和神经网络展示了一张卧室的照片，并问:“窗户上覆盖着什么？”(答案:“百叶窗。”)人类直视窗户来回答这个问题，但出于某种原因，机器却看着床。

Das 和 Agrawal 发表了一篇关于这项研究的论文，其中他们总结道:

> “总的来说，我们的实验表明，目前[视觉问答]中的注意力模型似乎没有像人类一样关注相同的区域。”

更令人担忧的是对一种机器学习算法的研究(此处总结为),该算法被训练为“预测肺炎患者的死亡概率(POD ),以便高风险患者可以被送入医院，而低风险患者作为门诊患者接受治疗。”

该软件了解到，哮喘患者的死亡概率较低，尽管事实恰恰相反。这是因为数据显示，与普通人群相比，死于肺炎的哮喘患者相对较少。

较低的死亡率是数据的准确反映，但学到的教训——这些患者的死亡概率较低，因此应作为门诊患者治疗——是错误的。原因是有哮喘病史的患者通常被直接送入重症监护室(ICU)，他们在 ICU 的治疗使他们的死亡风险低于普通人群。

因此，虽然该算法被训练来执行人类水平的任务，但它得到了错误的答案，因为它处理问题的方式非常不同。

# *类似任务*

第二个假设是，机器学习算法将在类似于它们被训练的任务上表现得一样好，这也是错误的。

在一篇很棒的博客文章中，Artem Khurshudov 详细描述了他对训练区分豹子、美洲虎和猎豹的软件的研究。虽然机器学习算法擅长区分这些猫，但它们被豹皮沙发难住了——特别是当它被翻向一边时:



当然，如果这些算法是在豹皮沙发和旋转图像上训练的，它们会表现得更好。但重点是一个人打折的东西作为小变异(我只是把头侧过来！)对于机器来说是一个显著的区别。

反之亦然:对一个人来说意义重大的变化对机器来说可能是微不足道的。几年前，研究人员[向一个经过训练的深度神经网络输入图像，这些图像对人类来说看起来像静态的或模式](http://www.evolvingai.org/files/DNNsEasilyFooled_cvpr15.pdf)。软件使用以下标签识别图像:



公平地说，输入敏感性不仅仅是机器学习算法的限制——所有软件都有问题——但这些例子尤其令人沮丧。虽然机器学习算法很棒，因为在处理输入变化时，它们往往比其他软件更好地执行*,但它们可能会以非常奇怪的方式犯错误。*

# **人类水平的智力**

*第三个假设——因为计算机在一些人类水平的任务上做得很好，它们正在做只有人类才能做的更复杂的事情——也是错误的。*

*(我说的“顺利上路”，是指沿着讨论人工智能取代律师和医生、[成为我们的霸主](https://en.wikipedia.org/wiki/AI_takeover)，或者实现[奇点](https://en.wikipedia.org/wiki/Technological_singularity)的道路前进。)*

*这种说法可能有争议，但这里的问题是，计算机显示出巨大进步的许多任务并不代表独特的人类智能。*

*最大的两个进步领域是语音和图像识别。这些领域的进步刺激了无人驾驶汽车、人脸识别以及苹果 Siri、亚马逊 Echo 和谷歌 Home 的语音界面的进步。*

*然而，图像和语音识别并不是人类的专属领域。如果我们停下来环顾四周，看看还有哪些生物具有识别语音和图像的能力，我们会看到像我的狗南瓜这样的动物:*



*南瓜有眼睛和耳朵。她能追踪和识别物体和声音。她当然认识我和我的家人和朋友。她能识别语言。*

*诚然，南瓜的词汇是贫乏的。但是我们在这里讨论的不是她理解多少语言，而是她如何学习。正是机器学习算法的*学习能力*的进步推动了对它们的大肆宣传。然而，这些算法需要比狗多几个数量级的标记数据来学习，更不用说人了。*

*南瓜也不例外。其他哺乳动物和鸟类可以学习识别图像和声音。甚至爬行动物、鱼和昆虫都有眼睛和耳朵。人们已经研究了蜜蜂执行视觉联想学习任务的能力。*

*非常清楚的是:我们最近取得的进展，以及围绕它的大肆宣传，是为了实现哺乳动物、鸟类、爬行动物、鱼类和昆虫几百万年来一直能够做到的事情——远在人类表现出难以置信的智能水平之前，我们理应处于翻译成代码的尖端。*

*这就是为什么认为因为深度学习正在推动语音和图像识别的进步，我们已经接近达到人类水平的智能是错误的(除非我们自己的智能与其他生物的智能之间只有微小的差异)。*

*值得注意的是，我们正在游戏、语言翻译和其他只有人类才能完成的任务上看到巨大的进步。但其中涉及的机器学习算法仍然只专注于识别，而不是推理，因此底层分析没有改变。*

# **思维迟钝**

*人类智力的特别之处在于我们的推理能力——慢思考能力。*

*尽管最近人工智能的大部分焦点都集中在提高系统 1 的识别能力上，但该领域在研究系统 2 的推理能力方面确实有很长的历史。*

*几十年前，专家系统更是大张旗鼓地完成了这项工作。来自[维基百科](https://en.wikipedia.org/wiki/Expert_system):*

> *在人工智能中，专家系统是模拟人类专家决策能力的计算机系统。专家系统旨在通过对知识的推理来解决复杂的问题，主要表现为“如果-那么”规则，而不是通过传统的程序代码。第一个专家系统创建于 20 世纪 70 年代，然后在 20 世纪 80 年代激增。专家系统是第一批真正成功的人工智能(AI)软件。*

*但是专家系统不再流行了。有一种观点认为，如果你用大量的逻辑和规则而不是神经网络来构建，你就做错了。不仅如此，你显然落后于时代，甚至可能是勒德分子或技术无知。*

*那是一种耻辱。*

*首先，因为这意味着对如何开发能够像人类一样缓慢推理和思考的软件(包括新型机器学习)的研究减少了。*

*第二，因为不真实。今天正在开发的最智能的系统通过结合先进的系统 1 和系统 2 的能力来实现其人类水平的性能。*

*例如，考虑一下 Waymo(谷歌的无人驾驶汽车衍生产品)。Waymo 使用大量知识和逻辑来驾驶他们的汽车。他们已经建立了非常详细的数字地图，突出道路特征，如人行横道的长度、交通灯的高度和转弯的曲线。*



*Waymo 依赖这些详细的地图，因为识别软件本身不够准确。想想看，如果他们的识别软件准确率达到 99.9%，这对机器学习算法来说是一个令人难以置信的高准确率，那仍然会转化为每遇到 1000 个红灯就有一个闯红灯。在世界各地，这将意味着每天有数百万个红灯亮起，结果可能造成数万或数十万人伤亡。*

*因此，Waymo *会告诉*汽车在哪里寻找红灯。Waymo *告诉*汽车遇到红灯时停下来。它没有受过做这些工作的训练。*

*尽管如此，识别软件仍然是一个重要的组成部分——它是汽车确定红灯、黄灯或绿灯的方式。*

# **现在都在一起了**

*必然的结论是，高度智能的软件需要同时具备快速思考*和慢速思考*的能力，以及极其详细的知识库。这是在最苛刻的智力水平上构建智能和可靠软件的唯一方法。*

*挑战在于，我们还没有想出如何让系统 2 的进步具有足够的通用性。为 Waymo 提供动力的思维缓慢逻辑与为我的公司 Julia 提供动力的思维缓慢逻辑截然不同。我们需要一种方法把它们联系起来。*

*人类已经发展出一种跨越领域的推理能力，所以肯定有一个解决方案等着我们去寻找。*













