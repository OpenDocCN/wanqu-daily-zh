# 千万不要自己写数据库。注意:我最初是由特里·克劳利写的这篇文章

> 原文:[https://medium . com/@ terry Crowley/never-write-your-own-database-736 f 704 c 780？UTM _ source = Wanqu . co&UTM _ campaign = Wanqu+Daily&UTM _ medium = website](https://medium.com/@terrycrowley/never-write-your-own-database-736f704c780?utm_source=wanqu.co&utm_campaign=Wanqu+Daily&utm_medium=website)

# 永远不要编写自己的数据库

*注意:我最初在微软与 Vincent Lascaux(主要负责 OneNote 工作的工程师)一起撰写了这篇文章，并决定在此论坛重新发布，因为该版本似乎不再可用。感谢文森特提供的所有详细信息和反馈！*

软件工程中有一句古老的格言——“永远不要编写自己的数据库”。那么，为什么 OneNote 团队要编写一个作为升级 OneNote 本地缓存实现的一部分呢？

首先，可能有必要更仔细地定义我在这个上下文中所说的“数据库”是什么意思。

大多数有趣的应用程序需要能够将它们的应用程序状态以及它们创建和管理的用户内容持久化到持久存储中。应用程序可以使用自己的定制逻辑来实现持久性，也可以使用一些预先存在的数据库管理软件(DBMS)来处理数据存储。预先存在的 DBMS 可能是某种关系存储(例如 SQLLite、ESENT)或更简单的键值存储(或者经常是用作键值存储的关系存储)。

如果你开始探索这些技术，并不需要花太多时间浏览维基百科的页面来了解建立一个数据库的复杂性。在通读该描述时，您几乎可以对最初的核心功能和随着时间的推移开发的附加功能进行考古分析，这些功能显然是由不断发展的客户需求(聚集索引、稀疏索引、覆盖索引、版本化列等)驱动的。等等。).它给人一种清晰的感觉，这是一个经受住了时间考验的组件，是一些关键产品的基础，也是它们在市场上如何发展的基础。

在评估是否使用这样一个健壮且功能强大的组件时，有两种相反的反应。第一反应是“天哪，我不可能聪明到复制那种技术”！这是一个好的和正义的反应！"如果我看得那么远，那只是因为我站在巨人的肩膀上……"

另一种反应是:“哇，那里有很多我不需要的东西。我想知道我为此付出了多少？”工程学的一个关键原则是 TANSTAAFL——“天下没有免费的午餐”。最终，当您深入了解时，这些额外的功能是通过额外的代码、IO、内存和 CPU 实现的，就像您自己实现的一样。有时候(很少！)这完全是付费游戏，你只需在使用那些额外功能时支付费用。其他时候，组件的实现者已经构建了某些假设和权衡，这些特性可能会约束未来的发展，或者对如何将组件集成到更大的系统中施加约束。即使您理解了组件的核心设计特征，分析这一点的复杂性也常常导致构建一个完整的功能原型来验证您自己的模拟(或实际)负载模式下的特定性能需求。

让我们回到持久化应用程序状态的问题。

一些应用程序以相对简单的方式对存储进行操作。磁盘上的文件被完全读入内存中的数据结构，进行修改，然后整个文件被写回磁盘。一个简单的技巧是用单独的名称写新文件，然后重命名新文件，仅在成功写入旧文件后才替换旧文件，这提供了防止存储损坏的安全性。

下一种方法是使用磁盘上的多个文件来表示应用程序的状态；复杂性的提升惊人的快。一个重要的挑战是，文件之间通常存在相互依赖关系(例如某种索引)，并且文件系统通常不提供任何事务保证(或者在使用它们所提供的支持方面的权衡太大)。面对故障(肯定会大规模发生)，不同文件的状态可能会变得不一致。这意味着应用程序必须内置识别和修复这种不一致的“损坏”状态的技术。其他应用程序和服务可以通过文件系统独立访问这些文件，这一事实也使得这种不一致性成为一种需要设计的状态。然而，与任何单个文件的交互仍然相对简单——只需打开并完全重写它。总体而言，根据利用文件系统的规模，可能还会有其他挑战(例如，如果需要管理数十个、数百个、数千个文件，并且可能需要跨目录进行拆分，以优化随着每个目录中文件数量的增加而扩展的文件系统性能特征)。当文件是独立一致的，并且典型的文件大小足够大，存储空间效率不是一个特别关注的问题(由于文件系统元数据和页面大小造成的碎片或空间浪费)时，这种使用独立文件的方法可以很好地工作。满足这些要求的一个示例是将电子邮件附件作为独立文件存储在磁盘上，而不是存储在单个邮件缓存文件中。存储大型独立 blobs 是文件系统已经调优的一个问题，因此这种卸载可以缩小单个文件数据库需要针对的设计点的范围。

我在这里使用的数据库中的关键区别方法是，单个文件只被部分读入内存，并且只被增量重写。例如，OneNote 在可能非常大的笔记本空间(数十 GB)上提供虚拟化体验。它们不能完全加载到内存中，但是应用程序希望提供一种错觉，即所有数据都可以随时浏览和编辑。应用程序希望快速引导到工作状态(也就是说，在启动时只做少量的 IO)。修改通常只涉及一小部分数据，应用程序希望快速、低成本地将这些更改写入磁盘。当我浏览数据模型的新部分时，我想快速将该数据加入(例如，导航到 OneNote 中的新分区)。一个额外的要求是，虽然大多数写入是小的和增量的，但同步新内容的特殊情况需要非常快速和高效地进行批量传输。

即使有了这个相当简单的需求描述，我们已经有了一些相互冲突的约束(这是工程的本质！).我们希望将数据打包在一起，这样我们可以减少 io 的总数和大小，但我们希望在将更改保存到该数据的一小部分时，避免将所有数据重新打包在一起。如果我们只写入更改过的数据，随着时间的推移，我们的数据最终会变得越来越零碎，而如果我们总是重新打包，我们最终会做更多的 IO，本质上是不得不重写未更改的数据，以便获得更好的打包。在从桌面交流供电的机器向电池供电(即电源受限)的移动设备转移的过程中，我们看到的一个根本变化是，我们不再认为我们可以通过零星的高成本维护流程(例如，“在凌晨 3 点”运行整个文件压缩或碎片整理流程)来处理其中的一些权衡。相反，稳态性能是重点，成本需要在一段时间内摊销。甚至在智能手机出现之前，我们对自己在这些时候运行代码的能力的假设就已经是可疑的了(电池受限的笔记本电脑从 2000 年代中期开始占据主导地位；“绿色”交流供电的机器在夜间会自动关闭；由于磁盘容量呈爆炸式增长，但每秒 IO 数却没有，仅重写所有数据就可能需要很长时间，以至于无法在任何可用的维护窗口内完成)。

我们还需要考虑如何实现核心数据库 ACID 属性(原子的、一致的、隔离的、持久的)。虽然这里的方法和技术有很长的技术历史，但它们通常嵌入在特定的实现中，而不是作为一组简单的 API 来调用。尝试滚动意味着加入一个神秘的巫师小集团，熟悉文件系统的奥秘，包括什么时候是真正的刷新，病毒检查程序可以做什么奇怪的事情，IO 请求何时何地可以重新排序，备份系统如何真正工作，同步引擎如何工作，这在不同的操作系统类型之间如何变化，等等。

滚动自己的优势是，你可以在一个水平上优化和控制事情，这在通过复杂的外部组件工作时是不可能的。在某种意义上，这是永恒的组件依赖问题。什么时候外部组件比你自己更能解决难题？确定“更好”通常是一个困难的问题，包括性能、功能和开发时间/成本等方面，以及“随着时间的推移更好”的重要元素。随着时间的推移，您自己的需求将会改变，您对优化这一层对您的产品的重要性的看法将会改变，底层的技术前景将会改变，组件本身也将会改变(或者经常是，**而不是**改变，这在处于不断变化的技术前景之上时是有问题的)。

好吧，那只是背景。让我们深入了解 OneNote 工作的细节。

一段时间以来，OneNote 已经发展成为一个纯粹的云连接应用程序，数据存储在云中，而不是对存储在本地磁盘上的文件进行操作。这项工作的重点是优化 OneNote“缓存”，这是一组在本地存储云笔记本的缓存副本的文件，以支持离线使用和快速响应的读写。最初的 OneNote 永久格式将每个分区存储在单独的文件中(其中每个分区包含一组页面)。笔记本表示为包含分区文件和其他嵌套文件夹的文件夹层次结构。目录文件存储了关于文件夹本身的某些元数据。OneNote 的原始缓存格式将所有缓存的笔记本合并到磁盘上的单个文件中。节文件是一个“数据库”,我们在这里使用它(它被设计为部分读取和增量重写),缓存文件构建在用于读取和写入节文件的核心文件和对象管理原语之上。

缓存重写工作有一些明确的目标和一个重要的约束。正如我上面提到的，OneNote 的缓存文件被设计为定期运行大规模清理过程，这在移动资源更加有限的世界中是不合适的。因此，一个重要的目标是消除任何定期维护的需要，以便在实际使用中，缓存将使用更少的存储，需要更少的内存和 CPU(因为对于许多设备来说，维护实际上从未成功运行)。另一个目标是解决与 OneNote 基于修订版的存储模型相关的长期低效问题。OneNote 支持“无保存”模式，在这种模式下，所有更改都会自动保存到存储中。为了有效地做到这一点，它向只包含更改内容的页面追加一个新的修订。对于大量编辑的页面(一个很小但非常有价值的子集)，这些修订链可能会变得很长，导致页面加载更慢，需要更多的内存和 CPU。一个重要的目标是确保加载页面的成本符合呈现给用户的页面的实际复杂性，而不是与其编辑历史成比例。

最大的限制是这项工作应该局限于存储层本身，而不需要大量重写整个应用程序。这最终推动了许多需求。当处理大型复杂系统时，一个关键的问题是如何发展架构，而不是把一切都抛在空中，希望它按时着陆。在我们这个持续工程和交付的世界里，这种方法已经成为过去。事实上，即使在过去，它也是有问题的，因为它推迟了许多最棘手和耗时的集成任务，并且是许多晚期项目的来源。

在 OneNote 的例子中，这种增量方法推动了大量的需求:

*   新系统应该在现有解决方案的性能(内存、CPU、存储)上达到或超过现有解决方案(这才是项目的重点)。
*   它需要支持对页面进行快照的能力(同时继续允许同时创建新的页面版本)。同步基础设施以及版本控制、索引和其他功能依赖于廉价地创建页面快照的能力，以便这些功能可以在用户编辑页面的同时对页面进行操作。以高效的方式存储包含几十到几万个节点的图形的多个版本被证明是一项棘手的工作。这个需求是一个很好的例子，说明一个复杂的系统依赖于一些高效的关键操作。随着系统的发展，维护这些隐含的性能保证是非常重要的。Word 也有类似的要求，它要求“克隆”一个文档的成本非常低。对于新功能来说，保持这种特性是一个重要的约束。
*   版本间变更的有效计算。同步引擎依靠快速更改计算将用户更改上传到服务器。
*   多个并发作者。同步与编辑同时发生，并且需要同一页面的多个作者的能力。
*   其他微妙的奇怪要求。现有的代码要求数据可以在短时间内不被引用而不被删除。它还要求嵌入式文件作为真实文件公开，同时仍然维护 ACID 契约。在实践中，在软件系统中重新设计复杂组件或层的主要挑战之一甚至是识别这些微妙的需求，因为它们通常隐含在组件的使用方式中，而不是 API 契约的显式部分。

该团队仔细研究了现有的数据库解决方案(还记得那句关于永远不要编写自己的数据库的古老格言吗？).最终，是上面列出的集成需求驱使他们编写自己的数据库，而不是围绕原始性能或健壮性的分析结果。众所周知，这种评估非常棘手，因为您可能会在两个方向上都失败——您可能会低估在真实机器和真实使用模式的世界中稳定您自己的低级代码的成本，或者您可能会低估在具有自己的设计点和约束的现有复杂组件上交付您的完整解决方案的成本，特别是如果您不是从零开始，而是试图将这些组件约束与您自己的应用程序的现有约束相匹配。事实上，该团队正在建立他们在这一领域的专业知识，这给了他们信心，他们很好地理解了在哪里建立自己的熊陷阱。

他们最早做出的决定之一是将缓存分成每页一个单独的文件(用一个主索引文件)。分配给已删除页面和已删除内容或已关闭笔记本的垃圾收集空间一直是单文件缓存设计的主要问题。通过分离页面，这个垃圾收集问题被转移到文件系统上，文件系统被高度优化来处理这个问题。此外，单个页面的典型大小相对较小(尽管符合文件系统调整的大小),这为其他简化提供了机会。还有其他好处—它还避免了因缓存文件过大(> 4GB)而产生的问题。幸运的是，它还使与企业数据保护 API(Windows 10 的一项新功能)的集成变得更加简单，因为每个页面都可以根据该内容的适当策略单独加密。我说的是“偶然”，但实际上这是一个很好的例子，一个更符合用户内容高层模型的低层设计最终避免了与交付价值不一致的内部实现复杂性。这是一种“偶然的复杂性”,随着时间的推移，它会减慢大型代码库的开发速度。

正如上面提到的，这确实给多文件一致性带来了单独的挑战。这个团队在这里采用了一种有趣的方法。索引文件指向每个页面缓存文件中页面图和空闲空间映射的根位置。当持久化多文件事务时，所有页面缓存文件在索引文件之前被刷新到磁盘。每个页面文件现在都有两个**图根(和它们相关的自由空间图)旧图和新图(它们通常共享许多子图)。这两者是完全一致的，并且在文件中可用，这取决于您从哪里开始查找。然后索引文件被刷新到磁盘，指向新的图根和新的自由图。创建和删除页面的事务一致性需要额外的小改动。索引文件中的数据结构(作为事务的一部分刷新到磁盘)描述了要删除的文件和创建的文件。新文件在单独的文件夹中创建，然后在事务完成后移动到主缓存文件夹中。重启时，这些数据结构被处理，以确保上次运行时没有完全完成的任何操作都被完成。删除是幂等的(删除多次会得到相同的结果)，所以相当简单。完成创建事务也是幂等的(不再在子文件夹中的任何文件已经被成功地移动到主文件夹中)，并且存在于子文件夹中但是没有在创建列表中被引用的文件与未完成的新页面事务相关，并且可以被安全地删除(或者作为“丢失页面”恢复特征的一部分而变得可用)。**

为了解决长修订链的问题，他们对页面级数据结构进行了根本性的改变。页面仍然被定义为修订链，但是每个修订现在存储了该修订引用的所有对象的查找表(现在是 BTree)。旧版本仅引用修订中已更改的对象，并且需要明确地遍历修订链，以找到该修订中未更改的任何对象。

其结果是，加载页面版本(尤其是当前版本)的成本现在反映了页面的复杂性，而不是其编辑历史。这种变化确实使修订之间的变化计算不同。如上所述，这是系统认为速度很快的操作之一。该团队花了相当多的时间重新设计差异算法(包括构建一组广泛的单元和组件测试)，以确保它具有系统其余部分所需的可靠性和性能特征，尤其是在一组广泛的用例中。这是另一个很好的例子，说明在一个特定的特性上投入了大量的精力(以及相关的工程基础设施，以确保该特性随着产品的发展而得到维护)——计算两个页面版本之间的差异——以便系统的其余部分可以被编写为假定它是可靠和快速的。事实上，通过将差异算法编写为比较任何两个修订的通用功能，而不是假设链接关系，它为其他用途打开了特性(例如，不通过简单的修订链接而是通过更复杂的分支相关的页面版本的用户级比较)。

快速页面快照是新实现所需的另一个特性。要求页面图的多个实例同时有效的事务一致性机制也可以支持健壮的快照机制(简单地通过在事务范围期间继续保持修改的页面图的两个实例)。通过构建整个缓存事务机制，它还将快照功能从旧系统中的单个页面扩展到允许整个笔记本的快照。这不是当前正在使用的机制，但在规划的早期阶段，有多个功能正在考虑利用这一更全面的功能。

对多个写入者的支持允许两个事务独立进行，但在提交时合并成一个事务。这依赖于利用 OneNote 强大的合并功能，包括在内容模型中直接表示冲突编辑的功能。在一些情况下，内容模型不能被合并，在这种情况下，事务被取消。合并写事务的结果是，长时间运行的事务可能会延迟其他事务的提交，因此需要注意高级进程(如 sync)如何使用这种机制。

他们采用的最小化内存的关键方法之一是对页面缓存文件使用内存映射，并最小化为了在内存中表示页面而需要分配和维护的额外数据结构的数量。因此，该存储层需要更少的内存和更少的 CPU，因为可以直接引用存储数据结构，而无需额外的分配和数据复制。然后，OneNote 通常会根据存储结构构建内存中的图表，以便于整体操作。该团队现在正在寻找更多机会，在这些机会中，某些处理(尤其是具有非常具体的功能要求的批量操作，如同步和索引)可以直接在存储层上实施，而不需要对图形进行“水合”。经验表明，像这样的优化会非常有效。

从长远来看，围绕灵活线程模型和高效处理模型的这些变化为 OneNote 在拥有低级存储层方面的投资奠定了基础。对于 OneNote 团队来说，至少在这种情况下，这句古老的格言显然是错误的。