# 在你的 AWS 账户中发现一百万美元| Twilio Segment 博客

> 原文:[https://segment . com/blog/spotting-a-million-dollars-in-your-AWS-account/？UTM _ source = Wanqu . co&UTM _ campaign = Wanqu+Daily&UTM _ medium = website](https://segment.com/blog/spotting-a-million-dollars-in-your-aws-account/?utm_source=wanqu.co&utm_campaign=Wanqu+Daily&utm_medium=website)

最近，我们分享了每年在 AWS 账单上节省 100 多万美元的技术。当我们详细讨论各种问题和解决方案时，我们听到的最常见的问题是:“我知道我在 AWS 上花了很多钱，但是我实际上如何将它分成可以理解的几部分呢？”

从表面上看，这听起来是一个相当简单的问题。

您可以轻松地按 AWS 服务拆分每月支出，然后就到此为止。一万块钱 EC2，一千到 S3，五百块钱网络流量等等。但是仍然缺少的是对哪些产品和工程团队主导了你的成本的综合分析。

然后，考虑到您可能有数百个实例和数百万个容器来来去去。很快，开始时简单的分析问题迅速变得难以想象的复杂。

在这篇后续文章中，我们想分享一下我们使用的工具包的细节。我们的希望是提供一些想法来帮助你分析你的 AWS 花费，不管你运行的是少量的实例，还是成千上万的实例。

# 按“产品领域”分组

如果你正在大规模运营 AWS 很可能你遇到了两个主要问题。

首先，很难注意到工程团队的某个部分是否突然开始比以前花费更多。

我们的 AWS 账单是每月六位数，而且每个 AWS 组件的费用变化很快。在给定的一周内，我们可能会部署五个新服务，优化我们的 DynamoDB 吞吐量，并添加数百个客户。在这种环境下，很容易忽略一个团队本月在 EC2 上比上月多花了 20，000 美元。

其次，很难预测新客户的成本。

作为背景，Segment 提供单个 API，可以将分析数据发送到任意数量的第三方工具、数据仓库、S3 或内部数据管道。

虽然客户擅长预测他们将有多少流量和他们想要使用的产品，但我们在将这些使用信息转换成美元数字方面一直存在困难。理想情况下，我们希望能够说“一百万个新的 API 调用将花费我们$X，所以我们应该确保我们至少收取$Y。”

我们对这些问题的解决方案是将我们的基础设施分成我们称之为“产品区”的区域。在我们的案例中，这些产品领域大致定义为:

1.  **集成**(将数据从细分市场发送到各种分析提供商的代码)

2.  **API** (接收客户库发送给细分市场的数据的服务)

3.  **仓库**(将 [中的段数据](https://segment.com/warehouses)[加载到客户数据仓库](https://segment.com/warehouses)的流水线)

4.  **网站** **和 CDN**

5.  **内部**(上述四者的共享支持逻辑)

在确定项目范围的过程中，我们意识到测量所有的东西几乎是不可能的。因此，我们决定将账单中的成本百分比定为目标，比如说 80%，并尝试进行端到端的测量。

交付商业价值分析 80%的账单比追求 100%要好，陷入收集阶段，永远不会交付任何结果。追求 80%的完整性(愿意说“这已经足够好了”)最终让我们一次又一次免于陷入对我们的花费没有意义的分析。

# 收集，然后分析

为了按产品领域分解成本，我们需要为计费系统收集数据，我们必须收集这些数据，然后再将它们结合在一起:

1.  **AWS 计费 CSV-**AWS 生成的 CSV，用于提供完整的计费行项目

2.  **标记的 AWS 资源—**可以在计费 CSV 中标记的资源

3.  **未标记的资源—**像 EBS 和 ECS 这样的服务需要定制管道来标记“产品领域”的使用

一旦我们计算出这些数据的乘积面积，我们就可以将它们加载到 Redshift 中进行分析。

# 1.AWS 计费 CSV

开始了解您的支出的地方是 AWS 账单 CSV。[您可以在账单门户中启用一项设置，亚马逊将每天向 S3 发送一个包含详细账单信息的](https://docs.aws.amazon.com/awsaccountbilling/latest/aboutv2/billing-reports.html)[CSV。](https://docs.aws.amazon.com/awsaccountbilling/latest/aboutv2/billing-reports.html)

我说的详细是指非常详细。下面是一个典型的账单行:

2 月 7 日凌晨 3 点至 4 点之间，DynamoDB 在一张桌子上的存储费用高达 0.00000001 美元，相当于一美分的百万分之一。典型的一个月，我们的计费 CSV 中大约有 600 万行。不幸的是，大多数价格超过百万分之一便士。)

我们使用 [Heroku 的](https://github.com/heroku/awsdetailedbilling)[awsdeedlebilling](https://github.com/heroku/awsdetailedbilling)[工具](https://github.com/heroku/awsdetailedbilling)将计费数据从 S3 复制到红移。这是很好的第一步，但是我们没有很好的方法将特定的 AWS 成本与我们自己的产品领域相关联(例如，给定的实例小时是用于集成还是仓库产品领域)。

更何况 60%左右的账单都是 EC2 消费的。尽管成本占了很大一部分，但是利用计费 CSV 提供的数据，理解给定 EC2 实例如何映射到产品区域是不可能的。

有一个很好的理由说明为什么我们不能仅仅使用实例名来确定产品领域。我们大量使用 [ECS](https://aws.amazon.com/ecs/) [(](https://aws.amazon.com/ecs/) [弹性容器服务)](https://aws.amazon.com/ecs/)，在一台主机上堆叠*数百个*容器，实现更高的利用率，而不是在每台主机上运行一个单独的进程。

![Zoom with margin](../Images/06ff882ab72741c343cc0f8fb8ef6195.png "asset_fOZR3Egv.png")

不幸的是，Amazon 只对 EC2 实例成本的*计费，所以我们对运行在一个实例上的容器的成本一无所知:我们在一个典型的时间运行了多少容器，我们使用了多少池，以及我们使用了多少 CPU 和内存单元。*

更糟糕的是，关于容器自动缩放的信息没有在计费 CSV 的任何地方得到反映。为了获取这些数据进行分析，我们必须编写自己的工具来收集并处理这些数据。我将在接下来的小节中介绍这个管道是如何工作的。

不过，AWS 计费 CSV 将提供非常精细的使用数据，这些数据将成为我们分析的基础。我们只需要将这些数据与我们的产品领域联系起来。

注意:这个问题也不会消失。按小时计费将成为一个越来越大的问题，从“我把钱花在什么上？”因为越来越多的公司使用 ECS、Kubernetes 和 Mesos 等工具在一组实例中运行集装箱船队。具有讽刺意味的是，Amazon 多年来一直存在这个问题——每个 EC2 实例都是一个 Xen 虚拟机管理程序，与其他实例运行在同一个裸机上。

# 2.来自标记的 AWS 资源的成本数据

最重要和最容易获得的数据来自“标记的”AWS 资源。

现成的 AWS 计费 CSV 在其分析中不包括任何标签。因此，不可能辨别一个 EC2 实例或 bucket 如何与另一个 EC2 实例或 bucket 一起使用。

但是，您可以使用[成本分配标签](http://docs.aws.amazon.com/awsaccountbilling/latest/aboutv2/cost-alloc-tags.html)让某些标签出现在您的行项目成本旁边**。**

许多 AWS 资源、S3 桶、DynamoDB 表等都正式支持这些标签。您可以在 AWS 计费控制台中切换设置，使成本分配标签显示在 CSV 中。大约一天后，您选择的标签(我们选择了 product_area)将开始在详细的账单 CSV 中的相关资源旁边显示为一个新列。

如果您没有做其他事情，可以从使用成本分配标签来标记您的基础设施开始。它本质上是“免费的”,运行时不需要任何基础设施。

启用成本分配标记后，我们面临两个挑战:1)标记所有现有基础架构，2)确保任何新资源都将自动拥有标记。

**标记您现有的基础设施**

标记您现有的基础设施非常容易:对于给定的 AWS 产品，查询成本最高的资源的红移，在 Slack 中干扰人们，直到他们告诉您应该如何标记这些资源，当您已经标记了 90%或更多的资源成本时停止。

然而，强制*新*资源*保持*标记需要一些自动化和工具。

为此，我们使用 [Terraform](https://www.terraform.io/) 。在大多数情况下，Terraform 的配置支持添加与您可以通过 AWS 控制台添加的相同的成本分配标记。以下是 S3 铲斗的地形配置示例:

虽然 Terraform 提供了基本配置，但我们希望验证每次有人将资源“aws_s3_bucket”写入 Terraform 文件时，他们是否包含了 product_area 标记。

幸运的是，Terraform 配置是用 [HCL](https://github.com/hashicorp/hcl) (Hashicorp 配置语言)编写的，[附带了一个注释保存](https://kev.inburke.com/kevin/more-comment-preserving-configuration-parsers/) [配置解析器](https://kev.inburke.com/kevin/more-comment-preserving-configuration-parsers/)。因此，我们编写了一个检查器，它遍历每个 Terraform 文件，寻找缺少 product_area 标记的可标记资源。

我们为 repo 设置了与 Terraform 配置的持续集成，然后添加了这些检查，因此如果有人试图签入没有用产品区域标记的可标记资源，测试将会失败。

这并不完美——测试很挑剔，人们仍然可以在 AWS 控制台中直接创建未标记的资源，但目前已经足够好了——提供新基础设施的最简单方法是通过 Terraform。

![Zoom with margin](../Images/4e06fe3576f959b6916010fe8c6d0c60.png "asset_a4XvwMvY.png")

**汇总成本分配标签数据**

一旦你标记了资源，计算它们就相当简单了。

1.  找到每个资源的 product_area 标记，这样就有了一个 resource id => product area 标记的映射。

2.  合计每个资源的未混合成本

3.  按产品区域合计这些成本，并将结果写入汇总表。

    SELECT sum(un blended _ cost)FROM AWS billing . line _ items 其中 statement_month = $1，product _ name = ' Amazon DynamoDB

您可能还想按 AWS 产品分类数据——我们有两个单独的表，一个用于细分产品领域，另一个用于 AWS 产品。

使用传统的成本分配标签，我们可以占到账单的 35%。

**分析保留的实例**

这种方法非常适合带标签的按需实例。但在某些情况下，可能会提前向 AWS 支付“预订”费用。预订保证了一定的容量，以较低的固定费率换取预先付款。

在我们的案例中，这意味着 2016 年 12 月账单 CSV 中显示的几笔大额费用需要在一年中的每个月进行摊销。

为了正确计算这些成本，我们希望使用在期望的时间段内发生的*未混合成本*。该查询如下所示:

订阅成本以“DynamoDB 的 X0000 美元”的形式出现，因此它们不可能归因于单个资源或产品领域。

相反，我们按产品领域合计每个资源的成本，然后根据百分比摊销订阅成本。如果仓库管道使用了 60%的 EC2 计算成本，我们假设它也使用了 60%的预留。

这并不完美。如果你的账单有很大一部分是预先预留的，那么这种分期偿还策略将会被随需应变成本的微小变化所扭曲。在这种情况下，您会希望根据每种资源的使用情况进行摊销，这比成本更难求和。

# 3.来自未标记 AWS 资源的成本数据

虽然标记实例和 DynamoDB 表很棒，但是其他 AWS 资源*不支持*成本分配标记。这些资源要求我们构建一个 Rube Goldberg-ian 风格的工作流，以成功地将成本数据导入 Redshift。

我们必须处理的两个最大的未标记资源组是 ECS 和 EBS。

**ECS**

ECS 根据给定服务所需的容器数量不断扩大和缩小我们的服务。它还负责在各个实例之间重新平衡和装箱容器。

ECS 基于“CPU 和内存预留”在主机上启动容器。给定的服务表明它需要多少 CPU 份额，ECS 要么将新容器放在有容量的主机上，要么扩大实例数量以添加更多容量。

这些 ECS 操作都没有直接反映在我们的 AWS 计费 CSV 中，但是 ECS 仍然负责触发我们每个实例的自动调整。

简而言之，我们希望了解给定容器正在使用的每台机器的“部分”,但是计费 CSV 仅向我们提供了按实例细分的“整体单位”。

为了确定给定服务的成本，我们构建了自己的管道，该管道利用了以下部分:

1.  每当 ECS 任务开始或停止时，设置 [Cloudwatch 订阅](http://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/Subscriptions.html)。

2.  将事件中的相关数据(服务名、CPU/内存使用、启动或停止、EC2 实例 ID)推送到 Kinesis Firehose(聚合单个事件)。

3.  将 Kinesis Firehose 的数据推送到红移。

一旦所有的任务开始/停止/大小数据都处于红移状态，我们将一个给定的 ECS 任务运行的时间量(比如 120 秒)乘以它在该机器上使用的 CPU 单元数(最大为 4096——该信息可在[任务定义](http://docs.aws.amazon.com/AmazonECS/latest/developerguide/task_definitions.html)中获得),以获得在该实例上运行的每个服务的 CPU 秒数。

然后，实例的总账单根据每个服务使用的 CPU 秒数在服务之间进行划分。

这不是一个完美的方法。EC2 实例并不总是以 100%的容量运行，超出的容量目前被实例上运行的服务所分配，这可能是也可能不是造成开销的罪魁祸首。但是(你可能认为这是这篇文章的一个常见主题)，这已经足够好了。

![Zoom with margin](../Images/86713486bbcfd0448e05cfc8f657f701.png "asset_z2mf6nq4.png")

此外，我们希望为每项 ECS 服务找到合适的产品领域。然而，我们不能在 AWS 中标记这些服务，因为 ECS *不支持成本分配标记。*

相反，我们为每个 ECS 服务在 Terraform 模块中添加了一个 product_area 键。这个键不会导致任何元数据被发送到 AWS，但是它会填充一个脚本，该脚本读取每个服务的 product_area 键。

然后，该脚本在每次推送到主分支时将服务名=编码的产品区域映射发布到 DynamoDB。

![Zoom with margin](../Images/30e7f066962255bc798d9c89481045d3.png "asset_QHeVL6VV.png")

最后，我们的测试会验证每个新服务都被贴上了产品区域的标签。

**EBS**

弹性块存储(EBS)也是我们账单的重要组成部分。EBS 卷通常附加到 EC2 实例，出于会计目的，将 EBS 卷成本与 EC2 实例一起计算是有意义的。然而，AWS 计费 CSV 不会向您显示哪个 EBS 卷连接到了哪个实例的*。*

![Zoom with margin](../Images/4627d5fc6c3b8b9f31056d0e6e8a9068.png "asset_jufV8FIz.png")

为此我们再次使用了 Cloudwatch 我们订阅任何“volume attached”或“volume unattached”事件，然后在 DynamoDB 表中记录 EBS => EC2 映射。

然后，在计算 ECS 成本之前，我们可以将 EBS 体积成本添加到相关的 EC2 实例中。

# 合并跨帐户的数据

到目前为止，我们已经在单个 AWS 帐户的上下文中讨论了我们的所有成本。然而，这实际上并没有反映我们的 AWS 设置，它分布在不同的物理 AWS 帐户上。

![Zoom with margin](../Images/7d62fe974cc2e3f368ff415c68ae1eb4.png "asset_DP4G0ZmC.png")

我们不仅使用 ops 帐户进行整合的跨帐户计费，还帮助工程师提供单一访问点来进行生产变更。我们将登台与生产分开，以确保 API 调用(比如说，删除 DynamoDB 表)可以通过适当的检查安全运行。

在这些客户中，prod 在成本中占主导地位，但我们的分期成本在整个 AWS 账单中仍占很大比例。

当我们需要将阶段领域中关于 ECS 服务的数据写入生产红移集群时，这就变得棘手了。

为了实现编写“交叉帐户”，我们需要允许 Cloudwatch 订阅处理程序在生产中承担一个角色，该角色可以写入 Firehose(对于 ECS)或 DynamoDB(对于 EBS)。这很难设置，因为您必须在临时帐户(sts)中为正确的角色添加正确的权限。AssumeRole)和生产帐户中，任何错误都会导致令人困惑的权限错误。

![Zoom with margin](../Images/bf0b8a767fec9ecda2ce9cf6b250597f.png "asset_jwOEbVGa.png")

对我们来说，这意味着我们没有会计代码的暂存领域，因为暂存中的会计代码正在写入生产数据库。

虽然可以在 stage 中添加第二个服务，该服务订阅相同的数据但不写入数据，但我们决定可以忍受 stage 记帐代码偶尔出现的问题。

# 汇总统计数据

最后，我们拥有了进行正确分析所需的所有要素:

1.  AWS 开单 CSV 中标记的资源

2.  关于每个 ECS 事件开始和停止时间的数据

3.  ECS 服务名称和相关产品领域之间的映射

4.  EBS 卷和它们所连接的实例之间的映射

为了给分析团队总结所有这些，我按 AWS 产品进行了分析。对于每个 AWS 产品，我合计了该 AWS 产品的细分产品领域及其成本。

数据汇总到三个不同的表中:

1.  给定 ECS 服务在给定月份的总成本

2.  给定月份给定产品领域的总成本

3.  给定月份中(AWS 产品、细分产品领域)的总成本。例如，“仓库产品区域上个月使用了价值 1000 美元的 DynamoDB。”

给定产品领域的总成本如下所示:

AWS 产品结合细分产品领域的成本如下所示:

对于这些表中的每一个，我们都有一个包含每个月的最终数字的最终表，以及一个汇总的仅追加表，该表在每天更新时写入一个月的新数据。汇总表中的唯一标识符标识给定的运行，因此您可以通过查找给定运行中的所有行来合计 AWS 账单。

最终数据有效地成为我们用于顶级指标和董事会报告的黄金“事实来源”。汇总表格用于监控我们一个月的支出。

*注意:AWS 直到月末几天后才会“最终确定”你的账单，所以当月末来临时，任何将账单记录标记为完整的逻辑都是不正确的*[](https://github.com/heroku/awsdetailedbilling/pull/8)**。您可以检测账单何时成为“最终”账单，因为账单 CSV 中的发票* *_* *id 字段将是一个整数，而不是单词“估计”。**

# *最后几个问题*

*在结束之前，我们意识到在一些地方，一点点的准备和知识可以为我们节省大量的时间。排名不分先后，分别是:*

*   *聚合数据或将其从一个地方复制到另一个地方的脚本很少被触及，并且经常受到监控。例如，我们有一个脚本将 Amazon billing CSV 从一个 S3 存储桶复制到另一个存储桶，但是它在每个月的 27-28 号失败，因为随着 CSV 变大，执行复制的 Lambda 处理程序耗尽了内存。注意到这一点需要一段时间，因为红移数据库有大量的数据和每个月的正确数字。此后，我们为 Lambda 函数添加了监控功能，以确保它运行时不会出错。*

*   *确保这些脚本被很好地记录，特别是关于它们如何部署以及它们需要什么配置的信息。链接到引用源代码的其他地方——例如，从 S3 桶中取出数据的任何地方，链接到将数据放入桶中的脚本。还可以考虑将一个自述文件放在 S3 的 bucket root 中。*

*   *如果没有优化，红移查询会非常慢。在 Redshift 中创建新表之前，请咨询您公司的红移专家，并考虑您需要的查询。在我们的例子中，我们在计费 CSV 表上缺少正确的 sortkey。在创建表之后，你不能添加排序键，所以如果你没有提前做，你必须创建第二个有正确键的表，向那个表发送写操作，然后复制所有数据。*

*   *使用正确的排序键将汇总运行的查询部分从大约 7 分钟缩短到 10-30 秒。*

*   *最初我们计划按计划运行汇总脚本——cloud watch 每天会触发几次 AWS Lambda 函数。然而，运行长度是可变的(特别是当它涉及到将数据写入红移时),并且超过了最大 Lambda 超时，所以我们将其转移到 ECS 服务。*

*   *我们最初选择 Javascript 作为汇总代码，因为它运行在 Lambda 上，而公司的大多数其他脚本都是 Javascript。如果我意识到我需要将其切换到 ECS，我会选择一种更好地支持 64 位整数加法、并行化和工作取消的语言。*

*   *每当您开始向 Redshift 写入新数据时，Redshift 中的数据会发生变化(例如，添加了新的列)，或者您在分析数据的过程中修复了完整性错误，请在自述文件中添加一条注释，注明发生变化的日期和信息。这对你的数据分析团队会有极大的帮助。*

*   *混合成本对这种类型的分析没有用——坚持使用未混合成本，它显示了 AWS 对给定资源实际收取的费用。*

*   *账单 CSV 中有 8 或 9 行没有附加 Amazon 产品名称。这些表示总发票金额，但排除了任何试图对给定月份的未混合成本求和的情况。在计算成本之前，请务必排除这些因素。*

# *底线*

*正如您可能想象的那样，获得 AWS 账单的可见性需要大量的工作——包括定制工具和识别 AWS 中昂贵的资源。*

*我们发现最大的成功来自于使持续估算你的花费变得容易，而不是偶尔的“一次性分析”。*

*为此，我们自动化了所有的数据收集，在 Terraform 和我们的 CI 中实施了标记，并培训了整个工程团队如何正确标记他们的基础设施。*

*我们所有的数据都在红移中不断更新，而不是坐在 PDF 中。如果我们想要回答新问题或生成新报告，我们可以通过新的 SQL 查询立即获得结果。*

*此外，我们已经将数据导出到 Excel 模型中，这样我们就可以准确估计新客户的成本。此外，我们还可以了解某项服务或某个产品领域的成本是否突然大幅增加，以免对我们的底线造成太大冲击。*

*虽然它可能不完全反映您的基础架构，但希望此案例研究将有助于您更好地了解您的成本，并在您扩展时管理它们！*